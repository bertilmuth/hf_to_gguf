{"cells":[{"cell_type":"markdown","metadata":{"id":"1oHFCsV0z-Jw"},"source":["# Finetune Llama-3 with LLaMA Factory\n","\n","Please use a **free** Tesla T4 Colab GPU to run this!\n","\n","Project homepage: https://github.com/hiyouga/LLaMA-Factory"]},{"cell_type":"markdown","metadata":{"id":"55MFt9F12aIx"},"source":["### Configuration"]},{"cell_type":"markdown","metadata":{"id":"IIuQljeJZhP2"},"source":[]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":537,"status":"ok","timestamp":1716068133825,"user":{"displayName":"Bertil Muth","userId":"02558266373806387996"},"user_tz":-120},"id":"GLYa6ODY2UvG"},"outputs":[],"source":["# The dataset used in finetuning\n","finetuning_data_url = \"https://raw.githubusercontent.com/bertilmuth/hf_to_gguf/main/finetuning_dataset/FinetuningData_ALL_llamafactory_clean.json\"\n","\n","# The model that is finetuned with the dataset\n","hf_base_model_id=\"microsoft/Phi-3-mini-128k-instruct\"\n","\n","# The llamafactory prompt template, dependent on the base model\n","llamafactory_template_name=\"phi\"\n","\n","# Epochs of finetuning\n","epochs = 15\n","\n","# The model id on Hugging Face\n","# IMPORTANT: You need to set a Google Collab secret called HF_WRITE_TOKEN to a write token of Hugging Face for this to work!\n","hf_finetuned_model_id = \"bertilmuth/phi-3-mini-128k-15gen\"\n","\n"]},{"cell_type":"markdown","metadata":{"id":"YLXUrEeiQtdF"},"source":["### Mount Google Drive\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22120,"status":"ok","timestamp":1716068174250,"user":{"displayName":"Bertil Muth","userId":"02558266373806387996"},"user_tz":-120},"id":"4WlSmQyDQx5l","outputId":"bf6fc5b3-6cc4-4cbd-cb26-60f01c2688ed"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"H9RXn_YQnn9f"},"source":["### Check GPU environment"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"ZkN-ktlsnrdU","executionInfo":{"status":"ok","timestamp":1716056972051,"user_tz":-120,"elapsed":417,"user":{"displayName":"Bertil Muth","userId":"02558266373806387996"}}},"outputs":[],"source":["import torch\n","try:\n","  assert torch.cuda.is_available() is True\n","except AssertionError:\n","  print(\"Please set up a GPU before using LLaMA Factory: https://medium.com/mlearning-ai/training-yolov4-on-google-colab-316f8fff99c6\")"]},{"cell_type":"markdown","metadata":{"id":"2i4Z4qw8aAzI"},"source":["### Install Dependencies & Setup"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":51860,"status":"ok","timestamp":1716068643786,"user":{"displayName":"Bertil Muth","userId":"02558266373806387996"},"user_tz":-120},"id":"giM74oK1rRIH","outputId":"f0c773af-a48a-4ced-fb9e-a5bd8ae929ff"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","Cloning into 'LLaMA-Factory'...\n","remote: Enumerating objects: 11876, done.\u001b[K\n","remote: Counting objects: 100% (667/667), done.\u001b[K\n","remote: Compressing objects: 100% (330/330), done.\u001b[K\n","remote: Total 11876 (delta 399), reused 550 (delta 323), pack-reused 11209\u001b[K\n","Receiving objects: 100% (11876/11876), 218.07 MiB | 27.02 MiB/s, done.\n","Resolving deltas: 100% (8639/8639), done.\n","/content/LLaMA-Factory\n","\u001b[0m\u001b[01;34massets\u001b[0m/       docker-compose.yml  \u001b[01;34mexamples\u001b[0m/  pyproject.toml  requirements.txt  \u001b[01;34msrc\u001b[0m/\n","CITATION.cff  Dockerfile          LICENSE    README.md       \u001b[01;34mscripts\u001b[0m/          \u001b[01;34mtests\u001b[0m/\n","\u001b[01;34mdata\u001b[0m/         \u001b[01;34mevaluation\u001b[0m/         Makefile   README_zh.md    setup.py\n","Collecting unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git\n","  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-f1o77s4m/unsloth_1cc16bca4f094b8c85538cf7caa06736\n","  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-f1o77s4m/unsloth_1cc16bca4f094b8c85538cf7caa06736\n","  Resolved https://github.com/unslothai/unsloth.git to commit 2f2b478868f63b66aaaa93db66ab3d811cddc95e\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tyro in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.8.4)\n","Requirement already satisfied: transformers>=4.38.2 in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.40.2)\n","Requirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.19.1)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.99)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.66.4)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (5.9.5)\n","Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.43.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.25.2)\n","Requirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.20.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.14.0)\n","Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.6)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.0.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.31.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.70.16)\n","Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.9.5)\n","Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.23.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.38.2->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2023.12.25)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.38.2->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.38.2->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.4.3)\n","Requirement already satisfied: docstring-parser>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.16)\n","Requirement already satisfied: typing-extensions>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.11.0)\n","Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (13.7.1)\n","Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.7.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.0.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.2.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.16.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.16.0)\n","Requirement already satisfied: xformers==0.0.25 in /usr/local/lib/python3.10/dist-packages (0.0.25)\n","Processing /content/LLaMA-Factory\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: transformers>=4.37.2 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (4.40.2)\n","Requirement already satisfied: datasets>=2.14.3 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (2.19.1)\n","Requirement already satisfied: accelerate>=0.27.2 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (0.30.1)\n","Requirement already satisfied: peft>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (0.11.1)\n","Requirement already satisfied: trl>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (0.8.6)\n","Requirement already satisfied: gradio>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (4.31.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (1.11.4)\n","Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (0.8.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (0.1.99)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (3.20.3)\n","Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (0.29.0)\n","Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (2.7.1)\n","Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (0.111.0)\n","Requirement already satisfied: sse-starlette in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (2.1.0)\n","Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (3.7.1)\n","Requirement already satisfied: fire in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (0.6.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (24.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (6.0.1)\n","Requirement already satisfied: bitsandbytes>=0.39.0 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (0.43.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.27.2->llamafactory==0.7.2.dev0) (1.25.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.27.2->llamafactory==0.7.2.dev0) (5.9.5)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.27.2->llamafactory==0.7.2.dev0) (2.2.1+cu121)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.27.2->llamafactory==0.7.2.dev0) (0.23.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.27.2->llamafactory==0.7.2.dev0) (0.4.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.3->llamafactory==0.7.2.dev0) (3.14.0)\n","Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.3->llamafactory==0.7.2.dev0) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.3->llamafactory==0.7.2.dev0) (0.6)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.3->llamafactory==0.7.2.dev0) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.3->llamafactory==0.7.2.dev0) (2.0.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.3->llamafactory==0.7.2.dev0) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.3->llamafactory==0.7.2.dev0) (4.66.4)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.3->llamafactory==0.7.2.dev0) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.3->llamafactory==0.7.2.dev0) (0.70.16)\n","Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.3->llamafactory==0.7.2.dev0) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.3->llamafactory==0.7.2.dev0) (3.9.5)\n","Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.7.2.dev0) (23.2.1)\n","Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.7.2.dev0) (4.2.2)\n","Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.7.2.dev0) (0.3.2)\n","Requirement already satisfied: gradio-client==0.16.4 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.7.2.dev0) (0.16.4)\n","Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.7.2.dev0) (0.27.0)\n","Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.7.2.dev0) (6.4.0)\n","Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.7.2.dev0) (3.1.4)\n","Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.7.2.dev0) (2.1.5)\n","Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.7.2.dev0) (3.10.3)\n","Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.7.2.dev0) (9.4.0)\n","Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.7.2.dev0) (0.25.1)\n","Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.7.2.dev0) (0.0.9)\n","Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.7.2.dev0) (0.4.4)\n","Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.7.2.dev0) (2.10.0)\n","Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.7.2.dev0) (0.12.0)\n","Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.7.2.dev0) (0.12.3)\n","Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.7.2.dev0) (4.11.0)\n","Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.7.2.dev0) (2.0.7)\n","Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.16.4->gradio>=4.0.0->llamafactory==0.7.2.dev0) (11.0.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.7.2.dev0) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.7.2.dev0) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.7.2.dev0) (4.51.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.7.2.dev0) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.7.2.dev0) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.7.2.dev0) (2.8.2)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->llamafactory==0.7.2.dev0) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic->llamafactory==0.7.2.dev0) (2.18.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.37.2->llamafactory==0.7.2.dev0) (2023.12.25)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.37.2->llamafactory==0.7.2.dev0) (0.19.1)\n","Requirement already satisfied: tyro>=0.5.11 in /usr/local/lib/python3.10/dist-packages (from trl>=0.8.1->llamafactory==0.7.2.dev0) (0.8.4)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn->llamafactory==0.7.2.dev0) (8.1.7)\n","Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn->llamafactory==0.7.2.dev0) (0.14.0)\n","Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->llamafactory==0.7.2.dev0) (0.37.2)\n","Requirement already satisfied: fastapi-cli>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->llamafactory==0.7.2.dev0) (0.0.3)\n","Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->llamafactory==0.7.2.dev0) (5.10.0)\n","Requirement already satisfied: email_validator>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->llamafactory==0.7.2.dev0) (2.1.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->llamafactory==0.7.2.dev0) (1.16.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->llamafactory==0.7.2.dev0) (2.4.0)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from sse-starlette->llamafactory==0.7.2.dev0) (3.7.1)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio>=4.0.0->llamafactory==0.7.2.dev0) (0.4)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio>=4.0.0->llamafactory==0.7.2.dev0) (4.19.2)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio>=4.0.0->llamafactory==0.7.2.dev0) (0.12.1)\n","Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi->llamafactory==0.7.2.dev0) (2.6.1)\n","Requirement already satisfied: idna>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi->llamafactory==0.7.2.dev0) (3.7)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.3->llamafactory==0.7.2.dev0) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.3->llamafactory==0.7.2.dev0) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.3->llamafactory==0.7.2.dev0) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.3->llamafactory==0.7.2.dev0) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.3->llamafactory==0.7.2.dev0) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.3->llamafactory==0.7.2.dev0) (4.0.3)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio>=4.0.0->llamafactory==0.7.2.dev0) (2024.2.2)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio>=4.0.0->llamafactory==0.7.2.dev0) (1.0.5)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio>=4.0.0->llamafactory==0.7.2.dev0) (1.3.1)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.14.3->llamafactory==0.7.2.dev0) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.14.3->llamafactory==0.7.2.dev0) (2024.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.14.3->llamafactory==0.7.2.dev0) (3.3.2)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->sse-starlette->llamafactory==0.7.2.dev0) (1.2.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.27.2->llamafactory==0.7.2.dev0) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.27.2->llamafactory==0.7.2.dev0) (3.3)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.27.2->llamafactory==0.7.2.dev0) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.27.2->llamafactory==0.7.2.dev0) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.27.2->llamafactory==0.7.2.dev0) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.27.2->llamafactory==0.7.2.dev0) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.27.2->llamafactory==0.7.2.dev0) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.27.2->llamafactory==0.7.2.dev0) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.27.2->llamafactory==0.7.2.dev0) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.27.2->llamafactory==0.7.2.dev0) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.27.2->llamafactory==0.7.2.dev0) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.27.2->llamafactory==0.7.2.dev0) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.27.2->llamafactory==0.7.2.dev0) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.27.2->llamafactory==0.7.2.dev0) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate>=0.27.2->llamafactory==0.7.2.dev0) (12.4.127)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.7.2.dev0) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.7.2.dev0) (13.7.1)\n","Requirement already satisfied: docstring-parser>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl>=0.8.1->llamafactory==0.7.2.dev0) (0.16)\n","Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl>=0.8.1->llamafactory==0.7.2.dev0) (1.7.1)\n","Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn->llamafactory==0.7.2.dev0) (0.6.1)\n","Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn->llamafactory==0.7.2.dev0) (1.0.1)\n","Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn->llamafactory==0.7.2.dev0) (0.19.0)\n","Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn->llamafactory==0.7.2.dev0) (0.21.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio>=4.0.0->llamafactory==0.7.2.dev0) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio>=4.0.0->llamafactory==0.7.2.dev0) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio>=4.0.0->llamafactory==0.7.2.dev0) (0.18.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.7.2.dev0) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.7.2.dev0) (2.16.1)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate>=0.27.2->llamafactory==0.7.2.dev0) (1.3.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.7.2.dev0) (0.1.2)\n","Building wheels for collected packages: llamafactory\n","  Building wheel for llamafactory (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for llamafactory: filename=llamafactory-0.7.2.dev0-py3-none-any.whl size=169888 sha256=d7d82884b8185a4eecae158d926825066cf3e1ba2a90e61978ddd63187dd8f6f\n","  Stored in directory: /root/.cache/pip/wheels/de/aa/c5/27b5682c5592b7c0eecc3e208f176dedf6b11a61cf2a910b85\n","Successfully built llamafactory\n","Installing collected packages: llamafactory\n","  Attempting uninstall: llamafactory\n","    Found existing installation: llamafactory 0.7.2.dev0\n","    Uninstalling llamafactory-0.7.2.dev0:\n","      Successfully uninstalled llamafactory-0.7.2.dev0\n","Successfully installed llamafactory-0.7.2.dev0\n","The content has been successfully written to identity.json.\n"]}],"source":["# Set paths where to store the output\n","adapter_name = llamafactory_template_name + \"_lora\"\n","saved_merged_model_path = adapter_name + \"_merged\"\n","\n","# Install dependencies\n","%cd /content/\n","%rm -rf LLaMA-Factory\n","!git clone https://github.com/hiyouga/LLaMA-Factory.git\n","%cd LLaMA-Factory\n","%ls\n","!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n","!pip install --no-deps xformers==0.0.25\n","!pip install .[bitsandbytes]\n","\n","import os, requests\n","\n","# Download the finetuning data using requests\n","response = requests.get(finetuning_data_url)\n","\n","# Check if the request was successful\n","if response.status_code == 200:\n","    # Extract the text content from the response\n","    text_content = response.text\n","\n","    # Write the text content to the file identity.json\n","    with open(\"/content/LLaMA-Factory/data/identity.json\", \"w\", encoding=\"utf-8\") as file:\n","        file.write(text_content)\n","    print(\"The content has been successfully written to identity.json.\")\n","else:\n","    print(f\"Error: Failed to retrieve the file from {finetuning_data_url}. Status code: {response.status_code}\")\n"]},{"cell_type":"markdown","metadata":{"id":"rgR3UFhB0Ifq"},"source":["### Fine-tune model\n"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4198097,"status":"ok","timestamp":1716067672636,"user":{"displayName":"Bertil Muth","userId":"02558266373806387996"},"user_tz":-120},"id":"CS0Qk5OR0i4Q","outputId":"d62c0d13-7c78-43fa-fb37-5d3905e938eb"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/LLaMA-Factory\n","2024-05-18 18:33:56.282136: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-05-18 18:33:56.282195: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-05-18 18:33:56.284042: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-05-18 18:33:57.556365: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","05/18/2024 18:34:01 - WARNING - llamafactory.hparams.parser - We recommend enable `upcast_layernorm` in quantized training.\n","05/18/2024 18:34:01 - INFO - llamafactory.hparams.parser - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, compute dtype: torch.float16\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","[INFO|tokenization_utils_base.py:2087] 2024-05-18 18:34:01,614 >> loading file tokenizer.model from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-128k-instruct/snapshots/8a362e755d2faf8cec2bf98850ce2216023d178a/tokenizer.model\n","[INFO|tokenization_utils_base.py:2087] 2024-05-18 18:34:01,614 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-128k-instruct/snapshots/8a362e755d2faf8cec2bf98850ce2216023d178a/tokenizer.json\n","[INFO|tokenization_utils_base.py:2087] 2024-05-18 18:34:01,615 >> loading file added_tokens.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-128k-instruct/snapshots/8a362e755d2faf8cec2bf98850ce2216023d178a/added_tokens.json\n","[INFO|tokenization_utils_base.py:2087] 2024-05-18 18:34:01,615 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-128k-instruct/snapshots/8a362e755d2faf8cec2bf98850ce2216023d178a/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2087] 2024-05-18 18:34:01,615 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-128k-instruct/snapshots/8a362e755d2faf8cec2bf98850ce2216023d178a/tokenizer_config.json\n","[WARNING|logging.py:314] 2024-05-18 18:34:01,685 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","05/18/2024 18:34:01 - INFO - llamafactory.data.template - Replace eos token: <|end|>\n","05/18/2024 18:34:01 - WARNING - llamafactory.data.template - New tokens have been added, make sure `resize_vocab` is True.\n","05/18/2024 18:34:01 - INFO - llamafactory.data.loader - Loading dataset identity.json...\n","Generating train split: 2180 examples [00:00, 20159.59 examples/s]\n","Converting format of dataset: 100% 2180/2180 [00:00<00:00, 49367.93 examples/s]\n","Running tokenizer on dataset: 100% 2180/2180 [00:05<00:00, 421.28 examples/s]\n","input_ids:\n","[1, 32006, 887, 526, 263, 8444, 319, 29902, 20255, 29889, 32007, 29871, 13, 32010, 6204, 263, 1904, 3577, 525, 12636, 442, 6710, 29915, 426, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 5215, 16117, 26841, 6678, 29879, 1057, 275, 29928, 3864, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12715, 822, 9206, 2951, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12715, 822, 9206, 6880, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12715, 822, 853, 908, 11357, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12715, 822, 18199, 11357, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12715, 822, 512, 11506, 5594, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12715, 822, 2796, 5594, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12715, 822, 7370, 2052, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12715, 822, 23186, 2052, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 1595, 9206, 27107, 29912, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 3859, 9206, 2792, 29912, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 3859, 5947, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 3859, 1551, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 8269, 3158, 2069, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 20543, 2069, 769, 5947, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 20543, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 4102, 5947, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 16044, 9206, 2951, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 6098, 1551, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 20543, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 4102, 1551, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 16044, 9206, 6880, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 6098, 5947, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 29913, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 29913, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 1595, 22666, 29912, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 3859, 22666, 2792, 29912, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 3859, 18199, 287, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 3859, 853, 29113, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 8269, 3158, 2069, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 20543, 2069, 769, 18199, 287, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 20543, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 4102, 18199, 287, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 16044, 853, 908, 11357, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 6098, 853, 29113, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 20543, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 4102, 853, 29113, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 16044, 18199, 11357, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 6098, 18199, 287, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 29913, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 29913, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 1595, 8251, 3260, 29912, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 3859, 8251, 2792, 29912, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 3859, 5163, 280, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 3859, 512, 5594, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 8269, 3158, 2069, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 20543, 2069, 769, 5163, 280, 29936, 12]\n","inputs:\n","<s><|system|> You are a helpful AI assistant.<|end|> \n","<|user|> Create a model package 'Smartphone' {\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\timport OccurrenceFunctions::isDuring;\t\t\t\t\t\t\t\t\t\t\n","\tattribute def PowerOn;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\tattribute def PowerOff;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\tattribute def UnlockScreen;\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\tattribute def LockScreen;\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\tattribute def IncomingCall;\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\tattribute def EndCall;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\tattribute def StartApp;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\tattribute def CloseApp;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\tpart PowerManagement{\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\tstate PowerState{\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\tstate Off;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\tstate On;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\tentry action init;\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\ttransition init then Off;\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\ttransition\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\t\tfirst Off\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\t\taccept PowerOn\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\t\tthen On;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\ttransition\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\t\tfirst On\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\t\taccept PowerOff\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\t\tthen Off;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t}\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t}\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\tpart Screen{\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\tstate ScreenState{\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\tstate Locked;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\tstate Unlocked;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\tentry action init;\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\ttransition init then Locked;\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\ttransition\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\t\tfirst Locked\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\t\taccept UnlockScreen\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\t\tthen Unlocked;\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\ttransition\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\t\tfirst Unlocked\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\t\taccept LockScreen\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\t\tthen Locked;\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t}\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t}\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\tpart CallManager{\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\tstate CallState{\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\tstate Idle;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\tstate InCall;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\tentry action init;\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\ttransition init then Idle;\t\n","label_ids:\n","[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 3577, 525, 12636, 442, 6710, 29915, 426, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 5215, 16117, 26841, 6678, 29879, 1057, 275, 29928, 3864, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12715, 822, 9206, 2951, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12715, 822, 9206, 6880, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12715, 822, 853, 908, 11357, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12715, 822, 18199, 11357, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12715, 822, 512, 11506, 5594, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12715, 822, 2796, 5594, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12715, 822, 7370, 2052, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12715, 822, 23186, 2052, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 1595, 9206, 27107, 29912, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 3859, 9206, 2792, 29912, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 3859, 5947, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 3859, 1551, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 8269, 3158, 2069, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 20543, 2069, 769, 5947, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 20543, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 4102, 5947, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 16044, 9206, 2951, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 6098, 1551, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 20543, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 4102, 1551, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 16044, 9206, 6880, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 6098, 5947, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 29913, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 29913, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 1595, 22666, 29912, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 3859, 22666, 2792, 29912, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 3859, 18199, 287, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 3859, 853, 29113, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 8269, 3158, 2069, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 20543, 2069, 769, 18199, 287, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 20543, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 4102, 18199, 287, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 16044, 853, 908, 11357, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 6098, 853, 29113, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 20543, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 4102, 853, 29113, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 16044, 18199, 11357, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 6098, 18199, 287, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 29913, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 29913, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 1595, 8251, 3260, 29912, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 3859, 8251, 2792, 29912, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 3859, 5163, 280, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 3859, 512, 5594, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 8269, 3158, 2069, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 20543, 2069, 769, 5163, 280, 29936, 12]\n","labels:\n","package 'Smartphone' {\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\timport OccurrenceFunctions::isDuring;\t\t\t\t\t\t\t\t\t\t\n","\tattribute def PowerOn;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\tattribute def PowerOff;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\tattribute def UnlockScreen;\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\tattribute def LockScreen;\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\tattribute def IncomingCall;\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\tattribute def EndCall;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\tattribute def StartApp;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\tattribute def CloseApp;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\tpart PowerManagement{\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\tstate PowerState{\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\tstate Off;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\tstate On;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\tentry action init;\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\ttransition init then Off;\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\ttransition\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\t\tfirst Off\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\t\taccept PowerOn\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\t\tthen On;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\ttransition\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\t\tfirst On\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\t\taccept PowerOff\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\t\tthen Off;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t}\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t}\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\tpart Screen{\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\tstate ScreenState{\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\tstate Locked;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\tstate Unlocked;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\tentry action init;\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\ttransition init then Locked;\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\ttransition\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\t\tfirst Locked\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\t\taccept UnlockScreen\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\t\tthen Unlocked;\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\ttransition\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\t\tfirst Unlocked\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\t\taccept LockScreen\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\t\tthen Locked;\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t}\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t}\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\tpart CallManager{\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\tstate CallState{\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\tstate Idle;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\tstate InCall;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\tentry action init;\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\ttransition init then Idle;\t\n","[INFO|configuration_utils.py:726] 2024-05-18 18:34:08,062 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-128k-instruct/snapshots/8a362e755d2faf8cec2bf98850ce2216023d178a/config.json\n","[INFO|configuration_utils.py:726] 2024-05-18 18:34:08,577 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-128k-instruct/snapshots/8a362e755d2faf8cec2bf98850ce2216023d178a/config.json\n","[INFO|configuration_utils.py:789] 2024-05-18 18:34:08,579 >> Model config Phi3Config {\n","  \"_name_or_path\": \"microsoft/Phi-3-mini-128k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"microsoft/Phi-3-mini-128k-instruct--configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-128k-instruct--modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 131072,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": {\n","    \"long_factor\": [\n","      1.0299999713897705,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0799999237060547,\n","      1.2299998998641968,\n","      1.2299998998641968,\n","      1.2999999523162842,\n","      1.4499999284744263,\n","      1.5999999046325684,\n","      1.6499998569488525,\n","      1.8999998569488525,\n","      2.859999895095825,\n","      3.68999981880188,\n","      5.419999599456787,\n","      5.489999771118164,\n","      5.489999771118164,\n","      9.09000015258789,\n","      11.579999923706055,\n","      15.65999984741211,\n","      15.769999504089355,\n","      15.789999961853027,\n","      18.360000610351562,\n","      21.989999771118164,\n","      23.079999923706055,\n","      30.009998321533203,\n","      32.35000228881836,\n","      32.590003967285156,\n","      35.56000518798828,\n","      39.95000457763672,\n","      53.840003967285156,\n","      56.20000457763672,\n","      57.95000457763672,\n","      59.29000473022461,\n","      59.77000427246094,\n","      59.920005798339844,\n","      61.190006256103516,\n","      61.96000671386719,\n","      62.50000762939453,\n","      63.3700065612793,\n","      63.48000717163086,\n","      63.48000717163086,\n","      63.66000747680664,\n","      63.850006103515625,\n","      64.08000946044922,\n","      64.760009765625,\n","      64.80001068115234,\n","      64.81001281738281,\n","      64.81001281738281\n","    ],\n","    \"short_factor\": [\n","      1.05,\n","      1.05,\n","      1.05,\n","      1.1,\n","      1.1,\n","      1.1500000000000001,\n","      1.2000000000000002,\n","      1.2500000000000002,\n","      1.3000000000000003,\n","      1.3500000000000003,\n","      1.5000000000000004,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.0500000000000007,\n","      2.0500000000000007,\n","      2.0500000000000007,\n","      2.1000000000000005,\n","      2.1000000000000005,\n","      2.1000000000000005,\n","      2.1500000000000004,\n","      2.1500000000000004,\n","      2.3499999999999996,\n","      2.549999999999999,\n","      2.5999999999999988,\n","      2.5999999999999988,\n","      2.7499999999999982,\n","      2.849999999999998,\n","      2.849999999999998,\n","      2.9499999999999975\n","    ],\n","    \"type\": \"su\"\n","  },\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 262144,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.40.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","05/18/2024 18:34:08 - INFO - llamafactory.model.utils.quantization - Quantizing model to 4 bit.\n"," Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","[INFO|configuration_utils.py:726] 2024-05-18 18:34:09,604 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-128k-instruct/snapshots/8a362e755d2faf8cec2bf98850ce2216023d178a/config.json\n","The repository for microsoft/Phi-3-mini-128k-instruct contains custom code which must be executed to correctly load the model. You can inspect the repository content at https://hf.co/microsoft/Phi-3-mini-128k-instruct.\n","You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n","\n","Do you wish to run the custom code? [y/N] y\n","[INFO|configuration_utils.py:726] 2024-05-18 18:34:14,692 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-128k-instruct/snapshots/8a362e755d2faf8cec2bf98850ce2216023d178a/config.json\n","[INFO|configuration_utils.py:789] 2024-05-18 18:34:14,693 >> Model config Phi3Config {\n","  \"_name_or_path\": \"microsoft/Phi-3-mini-128k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"microsoft/Phi-3-mini-128k-instruct--configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-128k-instruct--modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 131072,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": {\n","    \"long_factor\": [\n","      1.0299999713897705,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0799999237060547,\n","      1.2299998998641968,\n","      1.2299998998641968,\n","      1.2999999523162842,\n","      1.4499999284744263,\n","      1.5999999046325684,\n","      1.6499998569488525,\n","      1.8999998569488525,\n","      2.859999895095825,\n","      3.68999981880188,\n","      5.419999599456787,\n","      5.489999771118164,\n","      5.489999771118164,\n","      9.09000015258789,\n","      11.579999923706055,\n","      15.65999984741211,\n","      15.769999504089355,\n","      15.789999961853027,\n","      18.360000610351562,\n","      21.989999771118164,\n","      23.079999923706055,\n","      30.009998321533203,\n","      32.35000228881836,\n","      32.590003967285156,\n","      35.56000518798828,\n","      39.95000457763672,\n","      53.840003967285156,\n","      56.20000457763672,\n","      57.95000457763672,\n","      59.29000473022461,\n","      59.77000427246094,\n","      59.920005798339844,\n","      61.190006256103516,\n","      61.96000671386719,\n","      62.50000762939453,\n","      63.3700065612793,\n","      63.48000717163086,\n","      63.48000717163086,\n","      63.66000747680664,\n","      63.850006103515625,\n","      64.08000946044922,\n","      64.760009765625,\n","      64.80001068115234,\n","      64.81001281738281,\n","      64.81001281738281\n","    ],\n","    \"short_factor\": [\n","      1.05,\n","      1.05,\n","      1.05,\n","      1.1,\n","      1.1,\n","      1.1500000000000001,\n","      1.2000000000000002,\n","      1.2500000000000002,\n","      1.3000000000000003,\n","      1.3500000000000003,\n","      1.5000000000000004,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.0500000000000007,\n","      2.0500000000000007,\n","      2.0500000000000007,\n","      2.1000000000000005,\n","      2.1000000000000005,\n","      2.1000000000000005,\n","      2.1500000000000004,\n","      2.1500000000000004,\n","      2.3499999999999996,\n","      2.549999999999999,\n","      2.5999999999999988,\n","      2.5999999999999988,\n","      2.7499999999999982,\n","      2.849999999999998,\n","      2.849999999999998,\n","      2.9499999999999975\n","    ],\n","    \"type\": \"su\"\n","  },\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 262144,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.40.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","05/18/2024 18:34:14 - WARNING - llamafactory.model.utils.unsloth - Unsloth does not support model type phi3.\n","modeling_phi3.py: 100% 73.8k/73.8k [00:00<00:00, 21.7MB/s]\n","`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n","Current `flash-attenton` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n","model.safetensors.index.json: 100% 16.3k/16.3k [00:00<00:00, 56.6MB/s]\n","[INFO|modeling_utils.py:3429] 2024-05-18 18:34:16,080 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-128k-instruct/snapshots/8a362e755d2faf8cec2bf98850ce2216023d178a/model.safetensors.index.json\n","Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n","model-00001-of-00002.safetensors:   0% 0.00/4.97G [00:00<?, ?B/s]\u001b[A\n","model-00001-of-00002.safetensors:   1% 31.5M/4.97G [00:00<00:16, 305MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   1% 73.4M/4.97G [00:00<00:13, 371MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   3% 126M/4.97G [00:00<00:11, 426MB/s] \u001b[A\n","model-00001-of-00002.safetensors:   4% 178M/4.97G [00:00<00:11, 430MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   5% 231M/4.97G [00:00<00:10, 432MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   6% 283M/4.97G [00:00<00:11, 414MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   7% 346M/4.97G [00:00<00:10, 451MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   8% 409M/4.97G [00:00<00:09, 476MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   9% 472M/4.97G [00:01<00:09, 494MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  11% 524M/4.97G [00:01<00:09, 476MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  12% 587M/4.97G [00:01<00:08, 496MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  13% 640M/4.97G [00:01<00:09, 462MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  14% 692M/4.97G [00:01<00:09, 436MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  15% 744M/4.97G [00:01<00:09, 433MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  16% 797M/4.97G [00:01<00:09, 444MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  17% 849M/4.97G [00:01<00:09, 442MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  18% 902M/4.97G [00:02<00:09, 426MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  19% 954M/4.97G [00:02<00:09, 412MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  20% 996M/4.97G [00:02<00:09, 407MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  21% 1.04G/4.97G [00:02<00:10, 388MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  22% 1.08G/4.97G [00:02<00:10, 379MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  23% 1.12G/4.97G [00:02<00:10, 357MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  23% 1.16G/4.97G [00:02<00:10, 362MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  24% 1.22G/4.97G [00:02<00:09, 384MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  26% 1.27G/4.97G [00:03<00:09, 395MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  26% 1.31G/4.97G [00:03<00:10, 349MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  27% 1.36G/4.97G [00:03<00:09, 370MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  28% 1.42G/4.97G [00:03<00:08, 397MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  30% 1.47G/4.97G [00:03<00:08, 414MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  31% 1.52G/4.97G [00:03<00:08, 417MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  32% 1.57G/4.97G [00:03<00:08, 420MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  33% 1.63G/4.97G [00:03<00:07, 441MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  34% 1.68G/4.97G [00:04<00:08, 385MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  35% 1.72G/4.97G [00:04<00:08, 385MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  36% 1.77G/4.97G [00:04<00:07, 404MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  37% 1.82G/4.97G [00:04<00:07, 428MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  38% 1.88G/4.97G [00:04<00:07, 401MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  39% 1.92G/4.97G [00:04<00:07, 390MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  39% 1.96G/4.97G [00:04<00:07, 381MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  40% 2.01G/4.97G [00:04<00:07, 397MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  42% 2.07G/4.97G [00:04<00:06, 417MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  43% 2.12G/4.97G [00:05<00:06, 408MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  43% 2.16G/4.97G [00:05<00:06, 411MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  44% 2.21G/4.97G [00:05<00:06, 432MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  46% 2.26G/4.97G [00:05<00:06, 426MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  47% 2.32G/4.97G [00:05<00:06, 401MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  48% 2.37G/4.97G [00:05<00:06, 412MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  49% 2.41G/4.97G [00:05<00:06, 408MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  49% 2.45G/4.97G [00:05<00:06, 394MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  50% 2.50G/4.97G [00:06<00:06, 390MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  51% 2.55G/4.97G [00:06<00:05, 419MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  52% 2.60G/4.97G [00:06<00:05, 437MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  53% 2.65G/4.97G [00:06<00:05, 452MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  54% 2.71G/4.97G [00:06<00:04, 458MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  55% 2.76G/4.97G [00:06<00:04, 468MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  57% 2.81G/4.97G [00:06<00:04, 475MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  58% 2.86G/4.97G [00:06<00:04, 476MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  59% 2.92G/4.97G [00:06<00:04, 480MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  60% 2.97G/4.97G [00:07<00:04, 478MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  61% 3.02G/4.97G [00:07<00:04, 459MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  62% 3.07G/4.97G [00:07<00:04, 462MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  63% 3.12G/4.97G [00:07<00:03, 470MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  64% 3.18G/4.97G [00:07<00:03, 474MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  65% 3.23G/4.97G [00:07<00:03, 477MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  66% 3.28G/4.97G [00:07<00:03, 474MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  67% 3.33G/4.97G [00:07<00:03, 462MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  68% 3.39G/4.97G [00:07<00:03, 466MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  69% 3.44G/4.97G [00:08<00:03, 463MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  70% 3.49G/4.97G [00:08<00:03, 460MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  71% 3.54G/4.97G [00:08<00:03, 460MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  72% 3.60G/4.97G [00:08<00:03, 457MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  73% 3.65G/4.97G [00:08<00:03, 416MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  74% 3.70G/4.97G [00:08<00:03, 369MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  75% 3.75G/4.97G [00:08<00:03, 393MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  76% 3.80G/4.97G [00:08<00:03, 372MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  77% 3.84G/4.97G [00:09<00:03, 371MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  78% 3.88G/4.97G [00:09<00:03, 356MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  79% 3.92G/4.97G [00:09<00:02, 364MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  80% 3.97G/4.97G [00:09<00:02, 386MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  81% 4.02G/4.97G [00:09<00:02, 392MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  82% 4.06G/4.97G [00:09<00:02, 380MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  82% 4.10G/4.97G [00:09<00:02, 356MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  84% 4.15G/4.97G [00:09<00:02, 385MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  85% 4.20G/4.97G [00:10<00:01, 418MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  86% 4.26G/4.97G [00:10<00:01, 440MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  87% 4.31G/4.97G [00:10<00:01, 441MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  88% 4.36G/4.97G [00:10<00:02, 292MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  89% 4.41G/4.97G [00:10<00:01, 326MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  90% 4.47G/4.97G [00:10<00:01, 358MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  91% 4.52G/4.97G [00:10<00:01, 392MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  92% 4.57G/4.97G [00:11<00:00, 415MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  93% 4.62G/4.97G [00:11<00:00, 436MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  94% 4.68G/4.97G [00:11<00:00, 449MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  95% 4.73G/4.97G [00:11<00:00, 453MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  96% 4.78G/4.97G [00:11<00:00, 461MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  97% 4.83G/4.97G [00:11<00:00, 468MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  98% 4.89G/4.97G [00:11<00:00, 469MB/s]\u001b[A\n","model-00001-of-00002.safetensors: 100% 4.97G/4.97G [00:11<00:00, 419MB/s]\n","Downloading shards:  50% 1/2 [00:12<00:12, 12.22s/it]\n","model-00002-of-00002.safetensors:   0% 0.00/2.67G [00:00<?, ?B/s]\u001b[A\n","model-00002-of-00002.safetensors:   2% 52.4M/2.67G [00:00<00:05, 477MB/s]\u001b[A\n","model-00002-of-00002.safetensors:   4% 105M/2.67G [00:00<00:05, 486MB/s] \u001b[A\n","model-00002-of-00002.safetensors:   6% 157M/2.67G [00:00<00:05, 489MB/s]\u001b[A\n","model-00002-of-00002.safetensors:   8% 210M/2.67G [00:00<00:05, 489MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  10% 262M/2.67G [00:00<00:04, 488MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  12% 315M/2.67G [00:00<00:04, 492MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  14% 367M/2.67G [00:00<00:04, 487MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  16% 419M/2.67G [00:00<00:04, 483MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  18% 472M/2.67G [00:00<00:04, 489MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  20% 524M/2.67G [00:01<00:04, 490MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  22% 577M/2.67G [00:01<00:04, 495MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  24% 629M/2.67G [00:01<00:04, 497MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  26% 682M/2.67G [00:01<00:03, 498MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  27% 734M/2.67G [00:01<00:03, 498MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  29% 786M/2.67G [00:01<00:03, 496MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  31% 839M/2.67G [00:01<00:03, 494MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  33% 891M/2.67G [00:01<00:03, 495MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  35% 944M/2.67G [00:01<00:03, 496MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  37% 996M/2.67G [00:02<00:03, 497MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  39% 1.05G/2.67G [00:02<00:03, 499MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  41% 1.10G/2.67G [00:02<00:03, 501MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  43% 1.15G/2.67G [00:02<00:03, 503MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  45% 1.21G/2.67G [00:02<00:02, 504MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  47% 1.26G/2.67G [00:02<00:02, 507MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  49% 1.31G/2.67G [00:02<00:02, 510MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  51% 1.36G/2.67G [00:02<00:02, 439MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  53% 1.42G/2.67G [00:02<00:02, 421MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  55% 1.47G/2.67G [00:03<00:02, 412MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  57% 1.52G/2.67G [00:03<00:02, 396MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  59% 1.56G/2.67G [00:03<00:02, 390MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  60% 1.60G/2.67G [00:03<00:02, 387MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  62% 1.65G/2.67G [00:03<00:02, 390MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  63% 1.69G/2.67G [00:03<00:02, 380MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  65% 1.73G/2.67G [00:03<00:02, 379MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  66% 1.77G/2.67G [00:03<00:02, 380MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  68% 1.81G/2.67G [00:03<00:02, 374MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  70% 1.86G/2.67G [00:04<00:02, 385MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  71% 1.90G/2.67G [00:04<00:01, 390MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  73% 1.94G/2.67G [00:04<00:02, 339MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  74% 1.98G/2.67G [00:04<00:01, 352MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  76% 2.03G/2.67G [00:04<00:01, 373MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  78% 2.09G/2.67G [00:04<00:01, 389MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  80% 2.13G/2.67G [00:04<00:01, 382MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  81% 2.17G/2.67G [00:04<00:01, 378MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  83% 2.21G/2.67G [00:05<00:01, 376MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  84% 2.25G/2.67G [00:05<00:01, 381MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  86% 2.30G/2.67G [00:05<00:00, 381MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  88% 2.34G/2.67G [00:07<00:05, 58.1MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  89% 2.37G/2.67G [00:07<00:04, 68.9MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  90% 2.41G/2.67G [00:07<00:02, 92.4MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  92% 2.46G/2.67G [00:07<00:01, 129MB/s] \u001b[A\n","model-00002-of-00002.safetensors:  94% 2.52G/2.67G [00:07<00:00, 171MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  96% 2.57G/2.67G [00:08<00:00, 213MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  98% 2.62G/2.67G [00:08<00:00, 257MB/s]\u001b[A\n","model-00002-of-00002.safetensors: 100% 2.67G/2.67G [00:08<00:00, 320MB/s]\n","Downloading shards: 100% 2/2 [00:21<00:00, 10.57s/it]\n","[INFO|modeling_utils.py:1494] 2024-05-18 18:34:37,220 >> Instantiating Phi3ForCausalLM model under default dtype torch.float16.\n","[INFO|configuration_utils.py:928] 2024-05-18 18:34:37,222 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 1,\n","  \"eos_token_id\": 32000,\n","  \"pad_token_id\": 32000\n","}\n","\n","Loading checkpoint shards: 100% 2/2 [00:04<00:00,  2.50s/it]\n","[INFO|modeling_utils.py:4170] 2024-05-18 18:34:42,431 >> All model checkpoint weights were used when initializing Phi3ForCausalLM.\n","\n","[INFO|modeling_utils.py:4178] 2024-05-18 18:34:42,431 >> All the weights of Phi3ForCausalLM were initialized from the model checkpoint at microsoft/Phi-3-mini-128k-instruct.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use Phi3ForCausalLM for predictions without further training.\n","generation_config.json: 100% 172/172 [00:00<00:00, 1.25MB/s]\n","[INFO|configuration_utils.py:883] 2024-05-18 18:34:43,034 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-128k-instruct/snapshots/8a362e755d2faf8cec2bf98850ce2216023d178a/generation_config.json\n","[INFO|configuration_utils.py:928] 2024-05-18 18:34:43,035 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 1,\n","  \"eos_token_id\": [\n","    32000,\n","    32001,\n","    32007\n","  ],\n","  \"pad_token_id\": 32000\n","}\n","\n","05/18/2024 18:34:43 - INFO - llamafactory.model.utils.checkpointing - Gradient checkpointing enabled.\n","05/18/2024 18:34:43 - INFO - llamafactory.model.utils.attention - Using vanilla attention implementation.\n","05/18/2024 18:34:43 - INFO - llamafactory.model.adapter - Upcasting trainable params to float32.\n","05/18/2024 18:34:43 - INFO - llamafactory.model.adapter - Fine-tuning method: LoRA\n","05/18/2024 18:34:43 - INFO - llamafactory.model.utils.misc - Found linear modules: gate_up_proj,o_proj,qkv_proj,down_proj\n","05/18/2024 18:34:43 - INFO - llamafactory.model.loader - trainable params: 12582912 || all params: 3833662464 || trainable%: 0.3282\n","[INFO|trainer.py:626] 2024-05-18 18:34:43,474 >> Using auto half precision backend\n","05/18/2024 18:34:43 - INFO - llamafactory.train.utils - Using LoRA+ optimizer with loraplus lr ratio 16.00.\n","[INFO|trainer.py:2048] 2024-05-18 18:34:43,807 >> ***** Running training *****\n","[INFO|trainer.py:2049] 2024-05-18 18:34:43,807 >>   Num examples = 2,180\n","[INFO|trainer.py:2050] 2024-05-18 18:34:43,807 >>   Num Epochs = 15\n","[INFO|trainer.py:2051] 2024-05-18 18:34:43,807 >>   Instantaneous batch size per device = 4\n","[INFO|trainer.py:2054] 2024-05-18 18:34:43,807 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n","[INFO|trainer.py:2055] 2024-05-18 18:34:43,807 >>   Gradient Accumulation steps = 4\n","[INFO|trainer.py:2056] 2024-05-18 18:34:43,807 >>   Total optimization steps = 2,040\n","[INFO|trainer.py:2057] 2024-05-18 18:34:43,810 >>   Number of trainable parameters = 12,582,912\n","  0% 0/2040 [00:00<?, ?it/s]You are not running the flash-attention implementation, expect numerical differences.\n","{'loss': 0.5409, 'grad_norm': 0.19472745060920715, 'learning_rate': 2.450980392156863e-06, 'epoch': 0.07}\n","{'loss': 0.4873, 'grad_norm': 0.19343888759613037, 'learning_rate': 4.901960784313726e-06, 'epoch': 0.15}\n","{'loss': 0.4129, 'grad_norm': 0.22295348346233368, 'learning_rate': 7.3529411764705884e-06, 'epoch': 0.22}\n","  2% 34/2040 [02:54<2:49:55,  5.08s/it]y\n","{'loss': 0.2924, 'grad_norm': 0.18483656644821167, 'learning_rate': 9.803921568627451e-06, 'epoch': 0.29}\n","{'loss': 0.1965, 'grad_norm': 0.10790540277957916, 'learning_rate': 1.2254901960784313e-05, 'epoch': 0.37}\n","{'loss': 0.1451, 'grad_norm': 0.08600161224603653, 'learning_rate': 1.4705882352941177e-05, 'epoch': 0.44}\n","{'loss': 0.1269, 'grad_norm': 0.07580756396055222, 'learning_rate': 1.715686274509804e-05, 'epoch': 0.51}\n","{'loss': 0.1144, 'grad_norm': 0.0769948810338974, 'learning_rate': 1.9607843137254903e-05, 'epoch': 0.59}\n","{'loss': 0.1074, 'grad_norm': 0.06372390687465668, 'learning_rate': 2.2058823529411766e-05, 'epoch': 0.66}\n","{'loss': 0.1056, 'grad_norm': 0.09459303319454193, 'learning_rate': 2.4509803921568626e-05, 'epoch': 0.73}\n","{'loss': 0.0996, 'grad_norm': 0.08177962899208069, 'learning_rate': 2.696078431372549e-05, 'epoch': 0.81}\n","{'loss': 0.0949, 'grad_norm': 0.07900092750787735, 'learning_rate': 2.9411764705882354e-05, 'epoch': 0.88}\n","{'loss': 0.0933, 'grad_norm': 0.0813346803188324, 'learning_rate': 3.186274509803922e-05, 'epoch': 0.95}\n","{'loss': 0.0943, 'grad_norm': 0.05884437635540962, 'learning_rate': 3.431372549019608e-05, 'epoch': 1.03}\n","{'loss': 0.0888, 'grad_norm': 0.07132357358932495, 'learning_rate': 3.6764705882352945e-05, 'epoch': 1.1}\n","{'loss': 0.0873, 'grad_norm': 0.05776849761605263, 'learning_rate': 3.9215686274509805e-05, 'epoch': 1.17}\n","{'loss': 0.0847, 'grad_norm': 0.055392585694789886, 'learning_rate': 4.166666666666667e-05, 'epoch': 1.25}\n","{'loss': 0.0861, 'grad_norm': 0.08436684310436249, 'learning_rate': 4.411764705882353e-05, 'epoch': 1.32}\n","{'loss': 0.0862, 'grad_norm': 0.06359413266181946, 'learning_rate': 4.656862745098039e-05, 'epoch': 1.39}\n","{'loss': 0.0885, 'grad_norm': 0.1287875473499298, 'learning_rate': 4.901960784313725e-05, 'epoch': 1.47}\n","{'loss': 0.0831, 'grad_norm': 0.07150784879922867, 'learning_rate': 4.999868246217933e-05, 'epoch': 1.54}\n","{'loss': 0.0841, 'grad_norm': 0.052757807075977325, 'learning_rate': 4.999063134507127e-05, 'epoch': 1.61}\n","{'loss': 0.0832, 'grad_norm': 0.07214917987585068, 'learning_rate': 4.997526343067262e-05, 'epoch': 1.69}\n","{'loss': 0.0797, 'grad_norm': 0.06584497541189194, 'learning_rate': 4.995258321842611e-05, 'epoch': 1.76}\n","{'loss': 0.084, 'grad_norm': 0.06675074249505997, 'learning_rate': 4.992259734868079e-05, 'epoch': 1.83}\n","{'loss': 0.0804, 'grad_norm': 0.058759160339832306, 'learning_rate': 4.988531460074791e-05, 'epoch': 1.91}\n","{'loss': 0.0761, 'grad_norm': 0.09009014815092087, 'learning_rate': 4.984074589033044e-05, 'epoch': 1.98}\n","{'loss': 0.068, 'grad_norm': 0.07644961774349213, 'learning_rate': 4.978890426632721e-05, 'epoch': 2.06}\n","{'loss': 0.0669, 'grad_norm': 0.08544550091028214, 'learning_rate': 4.972980490701236e-05, 'epoch': 2.13}\n","{'loss': 0.0697, 'grad_norm': 0.06866227090358734, 'learning_rate': 4.966346511559149e-05, 'epoch': 2.2}\n","{'loss': 0.068, 'grad_norm': 0.09227237105369568, 'learning_rate': 4.9589904315135574e-05, 'epoch': 2.28}\n","{'loss': 0.0692, 'grad_norm': 0.06529771536588669, 'learning_rate': 4.9509144042894227e-05, 'epoch': 2.35}\n","{'loss': 0.0684, 'grad_norm': 0.05918300151824951, 'learning_rate': 4.942120794399002e-05, 'epoch': 2.42}\n","{'loss': 0.0703, 'grad_norm': 0.06716974079608917, 'learning_rate': 4.9326121764495596e-05, 'epoch': 2.5}\n","{'loss': 0.0694, 'grad_norm': 0.0675671175122261, 'learning_rate': 4.922391334389572e-05, 'epoch': 2.57}\n","{'loss': 0.0688, 'grad_norm': 0.13545286655426025, 'learning_rate': 4.911461260693638e-05, 'epoch': 2.64}\n","{'loss': 0.0671, 'grad_norm': 0.07480926811695099, 'learning_rate': 4.899825155486335e-05, 'epoch': 2.72}\n","{'loss': 0.0685, 'grad_norm': 0.07330543547868729, 'learning_rate': 4.887486425605286e-05, 'epoch': 2.79}\n","{'loss': 0.068, 'grad_norm': 0.0738406702876091, 'learning_rate': 4.874448683603695e-05, 'epoch': 2.86}\n","{'loss': 0.0677, 'grad_norm': 0.06912361830472946, 'learning_rate': 4.8607157466926614e-05, 'epoch': 2.94}\n","{'loss': 0.0687, 'grad_norm': 0.07438573986291885, 'learning_rate': 4.84629163562357e-05, 'epoch': 3.01}\n","{'loss': 0.0542, 'grad_norm': 0.1034432128071785, 'learning_rate': 4.8311805735108894e-05, 'epoch': 3.08}\n","{'loss': 0.0534, 'grad_norm': 0.06740161031484604, 'learning_rate': 4.81538698459572e-05, 'epoch': 3.16}\n","{'loss': 0.0551, 'grad_norm': 0.07649628072977066, 'learning_rate': 4.7989154929504566e-05, 'epoch': 3.23}\n","{'loss': 0.0556, 'grad_norm': 0.08867441117763519, 'learning_rate': 4.7817709211249515e-05, 'epoch': 3.3}\n","{'loss': 0.0535, 'grad_norm': 0.07896983623504639, 'learning_rate': 4.7639582887345516e-05, 'epoch': 3.38}\n","{'loss': 0.0557, 'grad_norm': 0.07066554576158524, 'learning_rate': 4.745482810990456e-05, 'epoch': 3.45}\n","{'loss': 0.0537, 'grad_norm': 0.08809082210063934, 'learning_rate': 4.726349897172791e-05, 'epoch': 3.52}\n","{'loss': 0.0588, 'grad_norm': 0.06971407681703568, 'learning_rate': 4.706565149046876e-05, 'epoch': 3.6}\n","{'loss': 0.0561, 'grad_norm': 0.10552092641592026, 'learning_rate': 4.686134359223129e-05, 'epoch': 3.67}\n","{'loss': 0.0574, 'grad_norm': 0.06976664811372757, 'learning_rate': 4.665063509461097e-05, 'epoch': 3.74}\n","{'loss': 0.0556, 'grad_norm': 0.07724350690841675, 'learning_rate': 4.643358768918106e-05, 'epoch': 3.82}\n","{'loss': 0.0567, 'grad_norm': 0.07683397829532623, 'learning_rate': 4.6210264923430456e-05, 'epoch': 3.89}\n","{'loss': 0.0572, 'grad_norm': 0.07064370810985565, 'learning_rate': 4.598073218215817e-05, 'epoch': 3.96}\n","{'loss': 0.0468, 'grad_norm': 0.07479912042617798, 'learning_rate': 4.574505666832982e-05, 'epoch': 4.04}\n","{'loss': 0.0413, 'grad_norm': 0.12631088495254517, 'learning_rate': 4.5503307383401896e-05, 'epoch': 4.11}\n","{'loss': 0.0407, 'grad_norm': 0.09780369699001312, 'learning_rate': 4.525555510711934e-05, 'epoch': 4.18}\n","{'loss': 0.0428, 'grad_norm': 0.08766882866621017, 'learning_rate': 4.5001872376792595e-05, 'epoch': 4.26}\n","{'loss': 0.0418, 'grad_norm': 0.10683010518550873, 'learning_rate': 4.4742333466059995e-05, 'epoch': 4.33}\n","{'loss': 0.0443, 'grad_norm': 0.09547168016433716, 'learning_rate': 4.447701436314176e-05, 'epoch': 4.4}\n","{'loss': 0.042, 'grad_norm': 0.11438450217247009, 'learning_rate': 4.420599274859215e-05, 'epoch': 4.48}\n","{'loss': 0.0442, 'grad_norm': 0.10342156887054443, 'learning_rate': 4.392934797255591e-05, 'epoch': 4.55}\n","{'loss': 0.0444, 'grad_norm': 0.10632410645484924, 'learning_rate': 4.3647161031536085e-05, 'epoch': 4.62}\n","{'loss': 0.0434, 'grad_norm': 0.07117083668708801, 'learning_rate': 4.3359514544679714e-05, 'epoch': 4.7}\n","{'loss': 0.0449, 'grad_norm': 0.08633608371019363, 'learning_rate': 4.3066492729588444e-05, 'epoch': 4.77}\n","{'loss': 0.0427, 'grad_norm': 0.07223782688379288, 'learning_rate': 4.276818137766118e-05, 'epoch': 4.84}\n","{'loss': 0.0442, 'grad_norm': 0.0831761360168457, 'learning_rate': 4.2464667828975956e-05, 'epoch': 4.92}\n","{'loss': 0.0455, 'grad_norm': 0.09900876879692078, 'learning_rate': 4.215604094671835e-05, 'epoch': 4.99}\n","{'loss': 0.0327, 'grad_norm': 0.1087234616279602, 'learning_rate': 4.184239109116393e-05, 'epoch': 5.06}\n","{'loss': 0.0292, 'grad_norm': 0.10913817584514618, 'learning_rate': 4.1523810093222547e-05, 'epoch': 5.14}\n","{'loss': 0.0293, 'grad_norm': 0.10363654792308807, 'learning_rate': 4.120039122755182e-05, 'epoch': 5.21}\n","{'loss': 0.029, 'grad_norm': 0.10136428475379944, 'learning_rate': 4.0872229185248075e-05, 'epoch': 5.28}\n","{'loss': 0.0316, 'grad_norm': 0.11234885454177856, 'learning_rate': 4.053942004612253e-05, 'epoch': 5.36}\n","{'loss': 0.0303, 'grad_norm': 0.08706757426261902, 'learning_rate': 4.020206125057092e-05, 'epoch': 5.43}\n","{'loss': 0.0316, 'grad_norm': 0.08467065542936325, 'learning_rate': 3.986025157104467e-05, 'epoch': 5.5}\n","{'loss': 0.0311, 'grad_norm': 0.10317544639110565, 'learning_rate': 3.951409108313223e-05, 'epoch': 5.58}\n","{'loss': 0.0319, 'grad_norm': 0.11906951665878296, 'learning_rate': 3.916368113625871e-05, 'epoch': 5.65}\n","{'loss': 0.0321, 'grad_norm': 0.09623459726572037, 'learning_rate': 3.880912432401265e-05, 'epoch': 5.72}\n","{'loss': 0.0324, 'grad_norm': 0.08500459045171738, 'learning_rate': 3.8450524454108525e-05, 'epoch': 5.8}\n","{'loss': 0.0324, 'grad_norm': 0.09228375554084778, 'learning_rate': 3.808798651799377e-05, 'epoch': 5.87}\n","{'loss': 0.0335, 'grad_norm': 0.14543455839157104, 'learning_rate': 3.7721616660109125e-05, 'epoch': 5.94}\n","{'loss': 0.0315, 'grad_norm': 0.08472573757171631, 'learning_rate': 3.73515221468116e-05, 'epoch': 6.02}\n","{'loss': 0.0218, 'grad_norm': 0.10553640127182007, 'learning_rate': 3.697781133496882e-05, 'epoch': 6.09}\n","{'loss': 0.0214, 'grad_norm': 0.09826711565256119, 'learning_rate': 3.6600593640234086e-05, 'epoch': 6.17}\n","{'loss': 0.0211, 'grad_norm': 0.07392006367444992, 'learning_rate': 3.621997950501156e-05, 'epoch': 6.24}\n","{'loss': 0.0209, 'grad_norm': 0.0976925939321518, 'learning_rate': 3.583608036612068e-05, 'epoch': 6.31}\n","{'loss': 0.0222, 'grad_norm': 0.08186012506484985, 'learning_rate': 3.544900862216959e-05, 'epoch': 6.39}\n","{'loss': 0.022, 'grad_norm': 0.11573442071676254, 'learning_rate': 3.505887760064681e-05, 'epoch': 6.46}\n","{'loss': 0.0212, 'grad_norm': 0.10533308982849121, 'learning_rate': 3.466580152474112e-05, 'epoch': 6.53}\n","{'loss': 0.0219, 'grad_norm': 0.10127203911542892, 'learning_rate': 3.426989547989902e-05, 'epoch': 6.61}\n","{'loss': 0.0235, 'grad_norm': 0.0714397057890892, 'learning_rate': 3.387127538012991e-05, 'epoch': 6.68}\n","{'loss': 0.0238, 'grad_norm': 0.13179929554462433, 'learning_rate': 3.3470057934068536e-05, 'epoch': 6.75}\n","{'loss': 0.0222, 'grad_norm': 0.12231472134590149, 'learning_rate': 3.3066360610804874e-05, 'epoch': 6.83}\n","{'loss': 0.0224, 'grad_norm': 0.09272583574056625, 'learning_rate': 3.266030160549137e-05, 'epoch': 6.9}\n","{'loss': 0.0226, 'grad_norm': 0.10959695279598236, 'learning_rate': 3.225199980473751e-05, 'epoch': 6.97}\n","{'loss': 0.0204, 'grad_norm': 0.09616719186306, 'learning_rate': 3.1841574751802076e-05, 'epoch': 7.05}\n","{'loss': 0.0162, 'grad_norm': 0.11096230894327164, 'learning_rate': 3.1429146611593e-05, 'epoch': 7.12}\n","{'loss': 0.0159, 'grad_norm': 0.09526754170656204, 'learning_rate': 3.1014836135485365e-05, 'epoch': 7.19}\n","{'loss': 0.015, 'grad_norm': 0.16745084524154663, 'learning_rate': 3.059876462596758e-05, 'epoch': 7.27}\n","{'loss': 0.0155, 'grad_norm': 0.09040184319019318, 'learning_rate': 3.0181053901126243e-05, 'epoch': 7.34}\n"," 49% 1000/2040 [1:24:50<1:28:10,  5.09s/it][INFO|trainer.py:3305] 2024-05-18 19:59:33,839 >> Saving model checkpoint to phi_lora/checkpoint-1000\n","[INFO|configuration_utils.py:726] 2024-05-18 19:59:34,447 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-128k-instruct/snapshots/8a362e755d2faf8cec2bf98850ce2216023d178a/config.json\n","[INFO|configuration_utils.py:789] 2024-05-18 19:59:34,448 >> Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-128k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"microsoft/Phi-3-mini-128k-instruct--configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-128k-instruct--modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 131072,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": {\n","    \"long_factor\": [\n","      1.0299999713897705,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0799999237060547,\n","      1.2299998998641968,\n","      1.2299998998641968,\n","      1.2999999523162842,\n","      1.4499999284744263,\n","      1.5999999046325684,\n","      1.6499998569488525,\n","      1.8999998569488525,\n","      2.859999895095825,\n","      3.68999981880188,\n","      5.419999599456787,\n","      5.489999771118164,\n","      5.489999771118164,\n","      9.09000015258789,\n","      11.579999923706055,\n","      15.65999984741211,\n","      15.769999504089355,\n","      15.789999961853027,\n","      18.360000610351562,\n","      21.989999771118164,\n","      23.079999923706055,\n","      30.009998321533203,\n","      32.35000228881836,\n","      32.590003967285156,\n","      35.56000518798828,\n","      39.95000457763672,\n","      53.840003967285156,\n","      56.20000457763672,\n","      57.95000457763672,\n","      59.29000473022461,\n","      59.77000427246094,\n","      59.920005798339844,\n","      61.190006256103516,\n","      61.96000671386719,\n","      62.50000762939453,\n","      63.3700065612793,\n","      63.48000717163086,\n","      63.48000717163086,\n","      63.66000747680664,\n","      63.850006103515625,\n","      64.08000946044922,\n","      64.760009765625,\n","      64.80001068115234,\n","      64.81001281738281,\n","      64.81001281738281\n","    ],\n","    \"short_factor\": [\n","      1.05,\n","      1.05,\n","      1.05,\n","      1.1,\n","      1.1,\n","      1.1500000000000001,\n","      1.2000000000000002,\n","      1.2500000000000002,\n","      1.3000000000000003,\n","      1.3500000000000003,\n","      1.5000000000000004,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.0500000000000007,\n","      2.0500000000000007,\n","      2.0500000000000007,\n","      2.1000000000000005,\n","      2.1000000000000005,\n","      2.1000000000000005,\n","      2.1500000000000004,\n","      2.1500000000000004,\n","      2.3499999999999996,\n","      2.549999999999999,\n","      2.5999999999999988,\n","      2.5999999999999988,\n","      2.7499999999999982,\n","      2.849999999999998,\n","      2.849999999999998,\n","      2.9499999999999975\n","    ],\n","    \"type\": \"su\"\n","  },\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 262144,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.40.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","[INFO|tokenization_utils_base.py:2488] 2024-05-18 19:59:34,554 >> tokenizer config file saved in phi_lora/checkpoint-1000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2497] 2024-05-18 19:59:34,555 >> Special tokens file saved in phi_lora/checkpoint-1000/special_tokens_map.json\n","{'loss': 0.0159, 'grad_norm': 0.08753272145986557, 'learning_rate': 2.9761826258980074e-05, 'epoch': 7.41}\n","{'loss': 0.0158, 'grad_norm': 0.06774313747882843, 'learning_rate': 2.9341204441673266e-05, 'epoch': 7.49}\n","{'loss': 0.0164, 'grad_norm': 0.11212066560983658, 'learning_rate': 2.891931159953886e-05, 'epoch': 7.56}\n","{'loss': 0.0161, 'grad_norm': 0.08794789016246796, 'learning_rate': 2.8496271255042617e-05, 'epoch': 7.63}\n","{'loss': 0.0162, 'grad_norm': 0.0920705497264862, 'learning_rate': 2.8072207266617855e-05, 'epoch': 7.71}\n","{'loss': 0.0166, 'grad_norm': 0.07504705339670181, 'learning_rate': 2.764724379240204e-05, 'epoch': 7.78}\n","{'loss': 0.0157, 'grad_norm': 0.12194538116455078, 'learning_rate': 2.7221505253885506e-05, 'epoch': 7.85}\n","{'loss': 0.0154, 'grad_norm': 0.08982151001691818, 'learning_rate': 2.679511629948319e-05, 'epoch': 7.93}\n","{'loss': 0.0164, 'grad_norm': 0.0942939817905426, 'learning_rate': 2.6368201768039826e-05, 'epoch': 8.0}\n","{'loss': 0.012, 'grad_norm': 0.15708205103874207, 'learning_rate': 2.5940886652279428e-05, 'epoch': 8.07}\n","{'loss': 0.0116, 'grad_norm': 0.15090197324752808, 'learning_rate': 2.5513296062209763e-05, 'epoch': 8.15}\n","{'loss': 0.0116, 'grad_norm': 0.10676000267267227, 'learning_rate': 2.5085555188492382e-05, 'epoch': 8.22}\n","{'loss': 0.0121, 'grad_norm': 0.11764708906412125, 'learning_rate': 2.465778926578913e-05, 'epoch': 8.29}\n","{'loss': 0.0119, 'grad_norm': 0.1059175357222557, 'learning_rate': 2.4230123536095748e-05, 'epoch': 8.37}\n","{'loss': 0.0123, 'grad_norm': 0.07890208065509796, 'learning_rate': 2.3802683212073287e-05, 'epoch': 8.44}\n","{'loss': 0.0116, 'grad_norm': 0.06983264535665512, 'learning_rate': 2.337559344038817e-05, 'epoch': 8.51}\n","{'loss': 0.0124, 'grad_norm': 0.06480997800827026, 'learning_rate': 2.2948979265071564e-05, 'epoch': 8.59}\n","{'loss': 0.012, 'grad_norm': 0.09060128033161163, 'learning_rate': 2.2522965590908726e-05, 'epoch': 8.66}\n","{'loss': 0.012, 'grad_norm': 0.06626962870359421, 'learning_rate': 2.2097677146869242e-05, 'epoch': 8.73}\n","{'loss': 0.0118, 'grad_norm': 0.09944728761911392, 'learning_rate': 2.1673238449588668e-05, 'epoch': 8.81}\n","{'loss': 0.0119, 'grad_norm': 0.06529423594474792, 'learning_rate': 2.1249773766912284e-05, 'epoch': 8.88}\n","{'loss': 0.0129, 'grad_norm': 0.09362320601940155, 'learning_rate': 2.0827407081511867e-05, 'epoch': 8.95}\n","{'loss': 0.0119, 'grad_norm': 0.0894518494606018, 'learning_rate': 2.0406262054585738e-05, 'epoch': 9.03}\n","{'loss': 0.0095, 'grad_norm': 0.07227911055088043, 'learning_rate': 1.9986461989653122e-05, 'epoch': 9.1}\n","{'loss': 0.0084, 'grad_norm': 0.07452443242073059, 'learning_rate': 1.9568129796453065e-05, 'epoch': 9.17}\n","{'loss': 0.0089, 'grad_norm': 0.11622748523950577, 'learning_rate': 1.9151387954958794e-05, 'epoch': 9.25}\n","{'loss': 0.0093, 'grad_norm': 0.11338257044553757, 'learning_rate': 1.873635847951778e-05, 'epoch': 9.32}\n","{'loss': 0.009, 'grad_norm': 0.07136064022779465, 'learning_rate': 1.8323162883128213e-05, 'epoch': 9.39}\n","{'loss': 0.0098, 'grad_norm': 0.11265535652637482, 'learning_rate': 1.791192214186223e-05, 'epoch': 9.47}\n","{'loss': 0.0091, 'grad_norm': 0.09509285539388657, 'learning_rate': 1.750275665944633e-05, 'epoch': 9.54}\n","{'loss': 0.0091, 'grad_norm': 0.09201169013977051, 'learning_rate': 1.7095786232009377e-05, 'epoch': 9.61}\n","{'loss': 0.0094, 'grad_norm': 0.1008414775133133, 'learning_rate': 1.6691130013008514e-05, 'epoch': 9.69}\n","{'loss': 0.0096, 'grad_norm': 0.07404377311468124, 'learning_rate': 1.6288906478343197e-05, 'epoch': 9.76}\n","{'loss': 0.0097, 'grad_norm': 0.09421619027853012, 'learning_rate': 1.5889233391667663e-05, 'epoch': 9.83}\n","{'loss': 0.0089, 'grad_norm': 0.08002711087465286, 'learning_rate': 1.549222776991186e-05, 'epoch': 9.91}\n","{'loss': 0.0098, 'grad_norm': 0.07369664311408997, 'learning_rate': 1.509800584902108e-05, 'epoch': 9.98}\n","{'loss': 0.0083, 'grad_norm': 0.06948469579219818, 'learning_rate': 1.4706683049924182e-05, 'epoch': 10.06}\n","{'loss': 0.0073, 'grad_norm': 0.08023255318403244, 'learning_rate': 1.4318373944740484e-05, 'epoch': 10.13}\n","{'loss': 0.0065, 'grad_norm': 0.09279939532279968, 'learning_rate': 1.3933192223235125e-05, 'epoch': 10.2}\n","{'loss': 0.0069, 'grad_norm': 0.06157713383436203, 'learning_rate': 1.3551250659532852e-05, 'epoch': 10.28}\n","{'loss': 0.0076, 'grad_norm': 0.08529762923717499, 'learning_rate': 1.3172661079099752e-05, 'epoch': 10.35}\n","{'loss': 0.0072, 'grad_norm': 0.09556382149457932, 'learning_rate': 1.279753432600288e-05, 'epoch': 10.42}\n","{'loss': 0.0075, 'grad_norm': 0.07656551152467728, 'learning_rate': 1.2425980230457132e-05, 'epoch': 10.5}\n","{'loss': 0.007, 'grad_norm': 0.07508532702922821, 'learning_rate': 1.205810757666894e-05, 'epoch': 10.57}\n","{'loss': 0.0076, 'grad_norm': 0.12899762392044067, 'learning_rate': 1.1694024070986324e-05, 'epoch': 10.64}\n","{'loss': 0.0073, 'grad_norm': 0.05959108844399452, 'learning_rate': 1.133383631036439e-05, 'epoch': 10.72}\n","{'loss': 0.0087, 'grad_norm': 0.10172431170940399, 'learning_rate': 1.097764975115576e-05, 'epoch': 10.79}\n","{'loss': 0.008, 'grad_norm': 0.0803808644413948, 'learning_rate': 1.0625568678234837e-05, 'epoch': 10.86}\n","{'loss': 0.0078, 'grad_norm': 0.06314589083194733, 'learning_rate': 1.0277696174465154e-05, 'epoch': 10.94}\n","{'loss': 0.0074, 'grad_norm': 0.058383405208587646, 'learning_rate': 9.934134090518593e-06, 'epoch': 11.01}\n","{'loss': 0.0059, 'grad_norm': 0.060513440519571304, 'learning_rate': 9.594983015055364e-06, 'epoch': 11.08}\n","{'loss': 0.0056, 'grad_norm': 0.07599630951881409, 'learning_rate': 9.260342245273506e-06, 'epoch': 11.16}\n","{'loss': 0.0059, 'grad_norm': 0.06301651895046234, 'learning_rate': 8.930309757836517e-06, 'epoch': 11.23}\n","{'loss': 0.0064, 'grad_norm': 0.08615141361951828, 'learning_rate': 8.604982180187568e-06, 'epoch': 11.3}\n","{'loss': 0.0062, 'grad_norm': 0.08055200427770615, 'learning_rate': 8.28445476225874e-06, 'epoch': 11.38}\n","{'loss': 0.0053, 'grad_norm': 0.06305351853370667, 'learning_rate': 7.968821348583644e-06, 'epoch': 11.45}\n","{'loss': 0.0063, 'grad_norm': 0.05862561985850334, 'learning_rate': 7.658174350821448e-06, 'epoch': 11.52}\n","{'loss': 0.0061, 'grad_norm': 0.08607785403728485, 'learning_rate': 7.352604720700421e-06, 'epoch': 11.6}\n","{'loss': 0.0059, 'grad_norm': 0.07494068890810013, 'learning_rate': 7.0522019233889545e-06, 'epoch': 11.67}\n","{'loss': 0.0058, 'grad_norm': 0.07185260206460953, 'learning_rate': 6.75705391130183e-06, 'epoch': 11.74}\n","{'loss': 0.0064, 'grad_norm': 0.06763629615306854, 'learning_rate': 6.4672470983493436e-06, 'epoch': 11.82}\n","{'loss': 0.0059, 'grad_norm': 0.0732569769024849, 'learning_rate': 6.182866334636889e-06, 'epoch': 11.89}\n","{'loss': 0.0059, 'grad_norm': 0.057214196771383286, 'learning_rate': 5.903994881622443e-06, 'epoch': 11.96}\n","{'loss': 0.0061, 'grad_norm': 0.0688413754105568, 'learning_rate': 5.63071438773913e-06, 'epoch': 12.04}\n","{'loss': 0.0047, 'grad_norm': 0.04545754939317703, 'learning_rate': 5.363104864490034e-06, 'epoch': 12.11}\n","{'loss': 0.0048, 'grad_norm': 0.07382660359144211, 'learning_rate': 5.101244663022331e-06, 'epoch': 12.18}\n","{'loss': 0.0052, 'grad_norm': 0.040166374295949936, 'learning_rate': 4.845210451187515e-06, 'epoch': 12.26}\n","{'loss': 0.0049, 'grad_norm': 0.0900212973356247, 'learning_rate': 4.5950771910944605e-06, 'epoch': 12.33}\n","{'loss': 0.005, 'grad_norm': 0.07847398519515991, 'learning_rate': 4.350918117161859e-06, 'epoch': 12.4}\n","{'loss': 0.0048, 'grad_norm': 0.046382129192352295, 'learning_rate': 4.112804714676594e-06, 'epoch': 12.48}\n","{'loss': 0.0057, 'grad_norm': 0.036735571920871735, 'learning_rate': 3.880806698864087e-06, 'epoch': 12.55}\n","{'loss': 0.0052, 'grad_norm': 0.05493186041712761, 'learning_rate': 3.654991994477039e-06, 'epoch': 12.62}\n","{'loss': 0.0049, 'grad_norm': 0.04568544030189514, 'learning_rate': 3.4354267159082436e-06, 'epoch': 12.7}\n","{'loss': 0.0055, 'grad_norm': 0.06002156436443329, 'learning_rate': 3.222175147833556e-06, 'epoch': 12.77}\n","{'loss': 0.005, 'grad_norm': 0.06367852538824081, 'learning_rate': 3.015299726390511e-06, 'epoch': 12.84}\n","{'loss': 0.0051, 'grad_norm': 0.04440469667315483, 'learning_rate': 2.8148610208981463e-06, 'epoch': 12.92}\n","{'loss': 0.005, 'grad_norm': 0.07498333603143692, 'learning_rate': 2.6209177161234445e-06, 'epoch': 12.99}\n","{'loss': 0.0045, 'grad_norm': 0.029629141092300415, 'learning_rate': 2.4335265950995057e-06, 'epoch': 13.06}\n","{'loss': 0.0042, 'grad_norm': 0.04699331149458885, 'learning_rate': 2.2527425225005337e-06, 'epoch': 13.14}\n","{'loss': 0.004, 'grad_norm': 0.04430656135082245, 'learning_rate': 2.0786184285784297e-06, 'epoch': 13.21}\n","{'loss': 0.0044, 'grad_norm': 0.0421738401055336, 'learning_rate': 1.911205293665827e-06, 'epoch': 13.28}\n","{'loss': 0.0045, 'grad_norm': 0.05965325981378555, 'learning_rate': 1.750552133249983e-06, 'epoch': 13.36}\n","{'loss': 0.0046, 'grad_norm': 0.0616183802485466, 'learning_rate': 1.5967059836219044e-06, 'epoch': 13.43}\n","{'loss': 0.0044, 'grad_norm': 0.05667576566338539, 'learning_rate': 1.4497118881050458e-06, 'epoch': 13.5}\n","{'loss': 0.0046, 'grad_norm': 0.04311918467283249, 'learning_rate': 1.3096128838674142e-06, 'epoch': 13.58}\n","{'loss': 0.0045, 'grad_norm': 0.036948926746845245, 'learning_rate': 1.1764499893210878e-06, 'epoch': 13.65}\n","{'loss': 0.0045, 'grad_norm': 0.04081619903445244, 'learning_rate': 1.0502621921127776e-06, 'epoch': 13.72}\n","{'loss': 0.0049, 'grad_norm': 0.04358289763331413, 'learning_rate': 9.310864377089695e-07, 'epoch': 13.8}\n","{'loss': 0.0045, 'grad_norm': 0.05197311192750931, 'learning_rate': 8.189576185789638e-07, 'epoch': 13.87}\n","{'loss': 0.0048, 'grad_norm': 0.03939071670174599, 'learning_rate': 7.139085639789878e-07, 'epoch': 13.94}\n","{'loss': 0.0045, 'grad_norm': 0.03566942363977432, 'learning_rate': 6.159700303404292e-07, 'epoch': 14.02}\n","{'loss': 0.0043, 'grad_norm': 0.0359012670814991, 'learning_rate': 5.25170692264887e-07, 'epoch': 14.09}\n","{'loss': 0.0045, 'grad_norm': 0.0348169207572937, 'learning_rate': 4.415371341287888e-07, 'epoch': 14.17}\n","{'loss': 0.0041, 'grad_norm': 0.03059326857328415, 'learning_rate': 3.6509384229996836e-07, 'epoch': 14.24}\n","{'loss': 0.0044, 'grad_norm': 0.03540067747235298, 'learning_rate': 2.958631979685156e-07, 'epoch': 14.31}\n","{'loss': 0.0041, 'grad_norm': 0.03983905538916588, 'learning_rate': 2.3386547059396636e-07, 'epoch': 14.39}\n","{'loss': 0.004, 'grad_norm': 0.04531942680478096, 'learning_rate': 1.7911881197078261e-07, 'epoch': 14.46}\n","{'loss': 0.0043, 'grad_norm': 0.04472516104578972, 'learning_rate': 1.3163925091384533e-07, 'epoch': 14.53}\n","{'loss': 0.0041, 'grad_norm': 0.04878713935613632, 'learning_rate': 9.144068856550004e-08, 'epoch': 14.61}\n","{'loss': 0.0041, 'grad_norm': 0.028631286695599556, 'learning_rate': 5.853489432556536e-08, 'epoch': 14.68}\n"," 98% 2000/2040 [2:49:41<03:23,  5.09s/it][INFO|trainer.py:3305] 2024-05-18 21:24:25,089 >> Saving model checkpoint to phi_lora/checkpoint-2000\n","[INFO|configuration_utils.py:726] 2024-05-18 21:24:25,695 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-128k-instruct/snapshots/8a362e755d2faf8cec2bf98850ce2216023d178a/config.json\n","[INFO|configuration_utils.py:789] 2024-05-18 21:24:25,697 >> Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-128k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"microsoft/Phi-3-mini-128k-instruct--configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-128k-instruct--modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 131072,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": {\n","    \"long_factor\": [\n","      1.0299999713897705,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0799999237060547,\n","      1.2299998998641968,\n","      1.2299998998641968,\n","      1.2999999523162842,\n","      1.4499999284744263,\n","      1.5999999046325684,\n","      1.6499998569488525,\n","      1.8999998569488525,\n","      2.859999895095825,\n","      3.68999981880188,\n","      5.419999599456787,\n","      5.489999771118164,\n","      5.489999771118164,\n","      9.09000015258789,\n","      11.579999923706055,\n","      15.65999984741211,\n","      15.769999504089355,\n","      15.789999961853027,\n","      18.360000610351562,\n","      21.989999771118164,\n","      23.079999923706055,\n","      30.009998321533203,\n","      32.35000228881836,\n","      32.590003967285156,\n","      35.56000518798828,\n","      39.95000457763672,\n","      53.840003967285156,\n","      56.20000457763672,\n","      57.95000457763672,\n","      59.29000473022461,\n","      59.77000427246094,\n","      59.920005798339844,\n","      61.190006256103516,\n","      61.96000671386719,\n","      62.50000762939453,\n","      63.3700065612793,\n","      63.48000717163086,\n","      63.48000717163086,\n","      63.66000747680664,\n","      63.850006103515625,\n","      64.08000946044922,\n","      64.760009765625,\n","      64.80001068115234,\n","      64.81001281738281,\n","      64.81001281738281\n","    ],\n","    \"short_factor\": [\n","      1.05,\n","      1.05,\n","      1.05,\n","      1.1,\n","      1.1,\n","      1.1500000000000001,\n","      1.2000000000000002,\n","      1.2500000000000002,\n","      1.3000000000000003,\n","      1.3500000000000003,\n","      1.5000000000000004,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.0500000000000007,\n","      2.0500000000000007,\n","      2.0500000000000007,\n","      2.1000000000000005,\n","      2.1000000000000005,\n","      2.1000000000000005,\n","      2.1500000000000004,\n","      2.1500000000000004,\n","      2.3499999999999996,\n","      2.549999999999999,\n","      2.5999999999999988,\n","      2.5999999999999988,\n","      2.7499999999999982,\n","      2.849999999999998,\n","      2.849999999999998,\n","      2.9499999999999975\n","    ],\n","    \"type\": \"su\"\n","  },\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 262144,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.40.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","[INFO|tokenization_utils_base.py:2488] 2024-05-18 21:24:25,784 >> tokenizer config file saved in phi_lora/checkpoint-2000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2497] 2024-05-18 21:24:25,785 >> Special tokens file saved in phi_lora/checkpoint-2000/special_tokens_map.json\n","{'loss': 0.0043, 'grad_norm': 0.026092784479260445, 'learning_rate': 3.293150240547549e-08, 'epoch': 14.75}\n","{'loss': 0.0044, 'grad_norm': 0.0491611585021019, 'learning_rate': 1.4638009007544861e-08, 'epoch': 14.83}\n","{'loss': 0.0044, 'grad_norm': 0.04008297994732857, 'learning_rate': 3.6597701302348854e-09, 'epoch': 14.9}\n","{'loss': 0.0043, 'grad_norm': 0.02962990291416645, 'learning_rate': 0.0, 'epoch': 14.97}\n","100% 2040/2040 [2:53:05<00:00,  5.09s/it][INFO|trainer.py:2316] 2024-05-18 21:27:49,614 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","{'train_runtime': 10385.8042, 'train_samples_per_second': 3.149, 'train_steps_per_second': 0.196, 'train_loss': 0.038768775850607486, 'epoch': 14.97}\n","100% 2040/2040 [2:53:05<00:00,  5.09s/it]\n","[INFO|trainer.py:3305] 2024-05-18 21:27:49,617 >> Saving model checkpoint to phi_lora\n","[INFO|configuration_utils.py:726] 2024-05-18 21:27:50,168 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-128k-instruct/snapshots/8a362e755d2faf8cec2bf98850ce2216023d178a/config.json\n","[INFO|configuration_utils.py:789] 2024-05-18 21:27:50,169 >> Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-128k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"microsoft/Phi-3-mini-128k-instruct--configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-128k-instruct--modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 131072,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": {\n","    \"long_factor\": [\n","      1.0299999713897705,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0799999237060547,\n","      1.2299998998641968,\n","      1.2299998998641968,\n","      1.2999999523162842,\n","      1.4499999284744263,\n","      1.5999999046325684,\n","      1.6499998569488525,\n","      1.8999998569488525,\n","      2.859999895095825,\n","      3.68999981880188,\n","      5.419999599456787,\n","      5.489999771118164,\n","      5.489999771118164,\n","      9.09000015258789,\n","      11.579999923706055,\n","      15.65999984741211,\n","      15.769999504089355,\n","      15.789999961853027,\n","      18.360000610351562,\n","      21.989999771118164,\n","      23.079999923706055,\n","      30.009998321533203,\n","      32.35000228881836,\n","      32.590003967285156,\n","      35.56000518798828,\n","      39.95000457763672,\n","      53.840003967285156,\n","      56.20000457763672,\n","      57.95000457763672,\n","      59.29000473022461,\n","      59.77000427246094,\n","      59.920005798339844,\n","      61.190006256103516,\n","      61.96000671386719,\n","      62.50000762939453,\n","      63.3700065612793,\n","      63.48000717163086,\n","      63.48000717163086,\n","      63.66000747680664,\n","      63.850006103515625,\n","      64.08000946044922,\n","      64.760009765625,\n","      64.80001068115234,\n","      64.81001281738281,\n","      64.81001281738281\n","    ],\n","    \"short_factor\": [\n","      1.05,\n","      1.05,\n","      1.05,\n","      1.1,\n","      1.1,\n","      1.1500000000000001,\n","      1.2000000000000002,\n","      1.2500000000000002,\n","      1.3000000000000003,\n","      1.3500000000000003,\n","      1.5000000000000004,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.0500000000000007,\n","      2.0500000000000007,\n","      2.0500000000000007,\n","      2.1000000000000005,\n","      2.1000000000000005,\n","      2.1000000000000005,\n","      2.1500000000000004,\n","      2.1500000000000004,\n","      2.3499999999999996,\n","      2.549999999999999,\n","      2.5999999999999988,\n","      2.5999999999999988,\n","      2.7499999999999982,\n","      2.849999999999998,\n","      2.849999999999998,\n","      2.9499999999999975\n","    ],\n","    \"type\": \"su\"\n","  },\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 262144,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.40.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","[INFO|tokenization_utils_base.py:2488] 2024-05-18 21:27:50,257 >> tokenizer config file saved in phi_lora/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2497] 2024-05-18 21:27:50,257 >> Special tokens file saved in phi_lora/special_tokens_map.json\n","***** train metrics *****\n","  epoch                    =     14.9725\n","  total_flos               = 697607133GF\n","  train_loss               =      0.0388\n","  train_runtime            =  2:53:05.80\n","  train_samples_per_second =       3.149\n","  train_steps_per_second   =       0.196\n","[INFO|modelcard.py:450] 2024-05-18 21:27:50,292 >> Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}\n"]}],"source":["import json\n","\n","args = dict(\n","  stage=\"sft\",                        # do supervised fine-tuning\n","  do_train=True,\n","  model_name_or_path=hf_base_model_id, # model name specified in Configuration\n","  dataset=\"identity\",             # use identity dataset\n","  template=llamafactory_template_name,       # prompt template specified in Configuration\n","  finetuning_type=\"lora\",                   # use LoRA adapters to save memory\n","  lora_target=\"all\",                     # attach LoRA adapters to all linear layers\n","  output_dir=adapter_name,                  # the path to save LoRA adapters\n","  per_device_train_batch_size=4,               # the batch size\n","  gradient_accumulation_steps=4,               # the gradient accumulation steps\n","  lr_scheduler_type=\"cosine\",                 # use cosine learning rate scheduler\n","  logging_steps=10,                      # log every 10 steps\n","  warmup_ratio=0.1,                      # use warmup scheduler\n","  save_steps=1000,                      # save checkpoint every 1000 steps\n","  learning_rate=5e-5,                     # the learning rate\n","  num_train_epochs=epochs,                    # the epochs of training\n","  max_samples=2500,                      # use 500 examples in each dataset\n","  max_grad_norm=1.0,                     # clip gradient norm to 1.0\n","  quantization_bit=4,                     # use 4-bit QLoRA\n","  loraplus_lr_ratio=16.0,                   # use LoRA+ algorithm with lambda=16.0\n","  use_unsloth=True,                      # use UnslothAI's LoRA optimization for 2x faster training\n","  fp16=True,                         # use float16 mixed precision training\n","  overwrite_output_dir=True\n",")\n","\n","json.dump(args, open(\"train.json\", \"w\", encoding=\"utf-8\"), indent=2)\n","\n","%cd /content/LLaMA-Factory/\n","\n","!llamafactory-cli train train.json"]},{"cell_type":"markdown","metadata":{"id":"m2FTc1pqbpyS"},"source":["### Save the finetuned model"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":206951,"status":"ok","timestamp":1716067889382,"user":{"displayName":"Bertil Muth","userId":"02558266373806387996"},"user_tz":-120},"id":"EnNKyRhybvsL","outputId":"3193d911-811b-49e2-d72f-f95f9d5ab404"},"outputs":[{"output_type":"stream","name":"stdout","text":["The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n","Token is valid (permission: write).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n","/content/LLaMA-Factory\n","2024-05-18 21:28:08.983227: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-05-18 21:28:08.983285: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-05-18 21:28:08.984910: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-05-18 21:28:10.294315: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","[INFO|tokenization_utils_base.py:2087] 2024-05-18 21:28:14,299 >> loading file tokenizer.model from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-128k-instruct/snapshots/8a362e755d2faf8cec2bf98850ce2216023d178a/tokenizer.model\n","[INFO|tokenization_utils_base.py:2087] 2024-05-18 21:28:14,299 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-128k-instruct/snapshots/8a362e755d2faf8cec2bf98850ce2216023d178a/tokenizer.json\n","[INFO|tokenization_utils_base.py:2087] 2024-05-18 21:28:14,299 >> loading file added_tokens.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-128k-instruct/snapshots/8a362e755d2faf8cec2bf98850ce2216023d178a/added_tokens.json\n","[INFO|tokenization_utils_base.py:2087] 2024-05-18 21:28:14,299 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-128k-instruct/snapshots/8a362e755d2faf8cec2bf98850ce2216023d178a/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2087] 2024-05-18 21:28:14,299 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-128k-instruct/snapshots/8a362e755d2faf8cec2bf98850ce2216023d178a/tokenizer_config.json\n","[WARNING|logging.py:314] 2024-05-18 21:28:14,369 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","05/18/2024 21:28:14 - INFO - llamafactory.data.template - Replace eos token: <|end|>\n","05/18/2024 21:28:14 - WARNING - llamafactory.data.template - New tokens have been added, make sure `resize_vocab` is True.\n","[INFO|configuration_utils.py:726] 2024-05-18 21:28:14,634 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-128k-instruct/snapshots/8a362e755d2faf8cec2bf98850ce2216023d178a/config.json\n","[INFO|configuration_utils.py:726] 2024-05-18 21:28:15,144 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-128k-instruct/snapshots/8a362e755d2faf8cec2bf98850ce2216023d178a/config.json\n","[INFO|configuration_utils.py:789] 2024-05-18 21:28:15,146 >> Model config Phi3Config {\n","  \"_name_or_path\": \"microsoft/Phi-3-mini-128k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"microsoft/Phi-3-mini-128k-instruct--configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-128k-instruct--modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 131072,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": {\n","    \"long_factor\": [\n","      1.0299999713897705,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0799999237060547,\n","      1.2299998998641968,\n","      1.2299998998641968,\n","      1.2999999523162842,\n","      1.4499999284744263,\n","      1.5999999046325684,\n","      1.6499998569488525,\n","      1.8999998569488525,\n","      2.859999895095825,\n","      3.68999981880188,\n","      5.419999599456787,\n","      5.489999771118164,\n","      5.489999771118164,\n","      9.09000015258789,\n","      11.579999923706055,\n","      15.65999984741211,\n","      15.769999504089355,\n","      15.789999961853027,\n","      18.360000610351562,\n","      21.989999771118164,\n","      23.079999923706055,\n","      30.009998321533203,\n","      32.35000228881836,\n","      32.590003967285156,\n","      35.56000518798828,\n","      39.95000457763672,\n","      53.840003967285156,\n","      56.20000457763672,\n","      57.95000457763672,\n","      59.29000473022461,\n","      59.77000427246094,\n","      59.920005798339844,\n","      61.190006256103516,\n","      61.96000671386719,\n","      62.50000762939453,\n","      63.3700065612793,\n","      63.48000717163086,\n","      63.48000717163086,\n","      63.66000747680664,\n","      63.850006103515625,\n","      64.08000946044922,\n","      64.760009765625,\n","      64.80001068115234,\n","      64.81001281738281,\n","      64.81001281738281\n","    ],\n","    \"short_factor\": [\n","      1.05,\n","      1.05,\n","      1.05,\n","      1.1,\n","      1.1,\n","      1.1500000000000001,\n","      1.2000000000000002,\n","      1.2500000000000002,\n","      1.3000000000000003,\n","      1.3500000000000003,\n","      1.5000000000000004,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.0500000000000007,\n","      2.0500000000000007,\n","      2.0500000000000007,\n","      2.1000000000000005,\n","      2.1000000000000005,\n","      2.1000000000000005,\n","      2.1500000000000004,\n","      2.1500000000000004,\n","      2.3499999999999996,\n","      2.549999999999999,\n","      2.5999999999999988,\n","      2.5999999999999988,\n","      2.7499999999999982,\n","      2.849999999999998,\n","      2.849999999999998,\n","      2.9499999999999975\n","    ],\n","    \"type\": \"su\"\n","  },\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 262144,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.40.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","05/18/2024 21:28:15 - INFO - llamafactory.model.patcher - Using KV cache for faster generation.\n","`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n","Current `flash-attenton` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n","[INFO|modeling_utils.py:3429] 2024-05-18 21:28:15,439 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-128k-instruct/snapshots/8a362e755d2faf8cec2bf98850ce2216023d178a/model.safetensors.index.json\n","[INFO|modeling_utils.py:1494] 2024-05-18 21:28:15,441 >> Instantiating Phi3ForCausalLM model under default dtype torch.bfloat16.\n","[INFO|configuration_utils.py:928] 2024-05-18 21:28:15,442 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 1,\n","  \"eos_token_id\": 32000,\n","  \"pad_token_id\": 32000\n","}\n","\n","Loading checkpoint shards: 100% 2/2 [00:00<00:00,  3.35it/s]\n","[INFO|modeling_utils.py:4170] 2024-05-18 21:28:16,101 >> All model checkpoint weights were used when initializing Phi3ForCausalLM.\n","\n","[INFO|modeling_utils.py:4178] 2024-05-18 21:28:16,101 >> All the weights of Phi3ForCausalLM were initialized from the model checkpoint at microsoft/Phi-3-mini-128k-instruct.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use Phi3ForCausalLM for predictions without further training.\n","[INFO|configuration_utils.py:883] 2024-05-18 21:28:16,376 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-128k-instruct/snapshots/8a362e755d2faf8cec2bf98850ce2216023d178a/generation_config.json\n","[INFO|configuration_utils.py:928] 2024-05-18 21:28:16,377 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 1,\n","  \"eos_token_id\": [\n","    32000,\n","    32001,\n","    32007\n","  ],\n","  \"pad_token_id\": 32000\n","}\n","\n","05/18/2024 21:28:16 - INFO - llamafactory.model.utils.attention - Using vanilla attention implementation.\n","05/18/2024 21:28:16 - INFO - llamafactory.model.adapter - Upcasting trainable params to float32.\n","05/18/2024 21:28:16 - INFO - llamafactory.model.adapter - Fine-tuning method: LoRA\n","05/18/2024 21:28:24 - INFO - llamafactory.model.adapter - Merged 1 adapter(s).\n","05/18/2024 21:28:24 - INFO - llamafactory.model.adapter - Loaded adapter(s): phi_lora\n","05/18/2024 21:28:24 - INFO - llamafactory.model.loader - all params: 3821079552\n","[INFO|configuration_utils.py:471] 2024-05-18 21:28:24,015 >> Configuration saved in phi_lora_merged/config.json\n","[INFO|configuration_utils.py:697] 2024-05-18 21:28:24,016 >> Configuration saved in phi_lora_merged/generation_config.json\n","[INFO|modeling_utils.py:2598] 2024-05-18 21:28:42,379 >> The model is bigger than the maximum size per checkpoint (2GB) and is going to be split in 4 checkpoint shards. You can find where each parameters has been saved in the index located at phi_lora_merged/model.safetensors.index.json.\n","[INFO|configuration_utils.py:471] 2024-05-18 21:28:44,755 >> Configuration saved in /tmp/tmpag0p2mz0/config.json\n","[INFO|configuration_utils.py:697] 2024-05-18 21:28:44,755 >> Configuration saved in /tmp/tmpag0p2mz0/generation_config.json\n","[INFO|modeling_utils.py:2598] 2024-05-18 21:29:05,259 >> The model is bigger than the maximum size per checkpoint (2GB) and is going to be split in 4 checkpoint shards. You can find where each parameters has been saved in the index located at /tmp/tmpag0p2mz0/model.safetensors.index.json.\n","[INFO|hub.py:757] 2024-05-18 21:29:26,955 >> Uploading the following files to bertilmuth/phi-3-mini-128k-15gen: README.md,config.json,model-00003-of-00004.safetensors,generation_config.json,modeling_phi3.py,model-00004-of-00004.safetensors,model-00001-of-00004.safetensors,model.safetensors.index.json,configuration_phi3.py,model-00002-of-00004.safetensors\n","model-00003-of-00004.safetensors:   0% 0.00/1.98G [00:00<?, ?B/s]\n","model-00004-of-00004.safetensors:   0% 0.00/1.76G [00:00<?, ?B/s]\u001b[A\n","\n","Upload 4 LFS files:   0% 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:   0% 0.00/1.94G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:   0% 0.00/1.96G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:   0% 16.4k/1.98G [00:00<6:15:31, 88.0kB/s]\n","\n","\n","model-00002-of-00004.safetensors:   0% 16.4k/1.94G [00:00<5:56:35, 90.6kB/s]\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:   0% 16.4k/1.76G [00:00<5:42:46, 85.8kB/s]\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:   0% 6.08M/1.94G [00:00<01:12, 26.7MB/s]  \u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:   0% 4.69M/1.76G [00:00<01:43, 17.1MB/s]  \u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:   0% 655k/1.98G [00:00<16:17, 2.03MB/s]   \n","model-00004-of-00004.safetensors:   0% 6.65M/1.76G [00:00<01:39, 17.6MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:   0% 901k/1.98G [00:00<18:52, 1.75MB/s]\n","\n","\n","model-00003-of-00004.safetensors:   0% 1.10M/1.98G [00:00<30:25, 1.08MB/s]\n","\n","\n","\n","model-00001-of-00004.safetensors:   0% 983k/1.96G [00:00<34:14, 953kB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00003-of-00004.safetensors:   0% 3.49M/1.98G [00:01<06:41, 4.93MB/s]\n","\n","\n","\n","model-00001-of-00004.safetensors:   0% 3.46M/1.96G [00:01<07:10, 4.54MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:   0% 4.41M/1.98G [00:01<06:31, 5.05MB/s]\n","model-00004-of-00004.safetensors:   2% 30.3M/1.76G [00:01<00:56, 30.9MB/s]\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:   0% 4.29M/1.96G [00:01<07:10, 4.54MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00003-of-00004.safetensors:   0% 5.37M/1.98G [00:01<06:26, 5.11MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:   0% 5.98M/1.98G [00:01<06:21, 5.18MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:   0% 7.31M/1.98G [00:01<05:34, 5.90MB/s]\n","model-00004-of-00004.safetensors:   2% 36.2M/1.76G [00:01<01:19, 21.8MB/s]\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:   0% 7.27M/1.96G [00:01<05:47, 5.61MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:   0% 8.93M/1.98G [00:01<04:46, 6.89MB/s]\n","\n","\n","\n","model-00001-of-00004.safetensors:   0% 8.04M/1.96G [00:01<05:30, 5.89MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00003-of-00004.safetensors:   0% 9.83M/1.98G [00:01<04:30, 7.29MB/s]\n","\n","\n","\n","model-00001-of-00004.safetensors:   0% 8.88M/1.96G [00:01<05:11, 6.25MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00003-of-00004.safetensors:   1% 10.9M/1.98G [00:02<04:50, 6.79MB/s]\n","\n","\n","\n","model-00001-of-00004.safetensors:   1% 11.0M/1.96G [00:02<04:34, 7.10MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:   1% 12.4M/1.98G [00:02<04:02, 8.11MB/s]\n","\n","\n","\n","model-00001-of-00004.safetensors:   1% 12.4M/1.96G [00:02<03:55, 8.26MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:   1% 14.7M/1.98G [00:02<03:14, 10.1MB/s]\n","\n","\n","\n","model-00001-of-00004.safetensors:   1% 13.5M/1.96G [00:02<03:51, 8.41MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:   3% 65.0M/1.94G [00:02<01:29, 20.8MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:   4% 78.9M/1.94G [00:02<00:57, 32.5MB/s]\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:   4% 64.2M/1.76G [00:02<01:33, 18.2MB/s]\u001b[A\n","model-00004-of-00004.safetensors:   4% 70.2M/1.76G [00:03<01:16, 22.1MB/s]\u001b[A\n","\n","\n","model-00003-of-00004.safetensors:   1% 16.0M/1.98G [00:03<08:06, 4.04MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:   1% 19.7M/1.98G [00:03<04:38, 7.04MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:   1% 23.1M/1.98G [00:03<03:28, 9.39MB/s]\n","\n","\n","\n","model-00001-of-00004.safetensors:   1% 23.0M/1.96G [00:03<03:24, 9.46MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:   4% 74.1M/1.76G [00:03<01:55, 14.6MB/s]\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:   5% 96.0M/1.94G [00:03<01:22, 22.4MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00003-of-00004.safetensors:   1% 26.1M/1.98G [00:04<04:02, 8.07MB/s]\n","\n","\n","\n","model-00001-of-00004.safetensors:   1% 26.8M/1.96G [00:04<04:20, 7.41MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:   6% 118M/1.94G [00:04<01:07, 27.0MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:   6% 124M/1.94G [00:04<01:00, 30.0MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:   1% 28.2M/1.96G [00:04<04:41, 6.85MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:   2% 29.8M/1.96G [00:04<04:23, 7.33MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:   2% 31.4M/1.96G [00:04<03:52, 8.30MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:   4% 77.1M/1.76G [00:04<03:44, 7.52MB/s]\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:   7% 129M/1.94G [00:05<01:33, 19.2MB/s]\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:   4% 79.2M/1.76G [00:05<03:38, 7.69MB/s]\u001b[A\n","\n","\n","model-00003-of-00004.safetensors:   2% 31.1M/1.98G [00:05<05:53, 5.52MB/s]\n","\n","\n","model-00002-of-00004.safetensors:   8% 150M/1.94G [00:05<01:14, 24.0MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:   2% 32.5M/1.96G [00:05<08:03, 3.99MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:   2% 36.1M/1.96G [00:05<04:58, 6.44MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:   5% 80.9M/1.76G [00:06<05:21, 5.23MB/s]\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:   2% 39.5M/1.96G [00:06<03:44, 8.53MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:   5% 93.4M/1.76G [00:06<02:10, 12.8MB/s]\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:   2% 41.2M/1.96G [00:06<03:24, 9.39MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:   8% 160M/1.94G [00:06<01:20, 22.1MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00003-of-00004.safetensors:   2% 32.2M/1.98G [00:06<09:53, 3.28MB/s]\n","model-00003-of-00004.safetensors:   2% 36.3M/1.98G [00:06<05:24, 5.99MB/s]\n","model-00003-of-00004.safetensors:   2% 38.2M/1.98G [00:06<04:30, 7.18MB/s]\n","\n","\n","model-00003-of-00004.safetensors:   2% 41.5M/1.98G [00:06<03:31, 9.16MB/s]\n","model-00004-of-00004.safetensors:   7% 117M/1.76G [00:07<01:29, 18.3MB/s]\u001b[A\n","model-00004-of-00004.safetensors:   7% 127M/1.76G [00:07<01:01, 26.7MB/s]\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  10% 192M/1.94G [00:07<01:14, 23.4MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  11% 207M/1.94G [00:07<00:49, 35.0MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:   2% 42.9M/1.96G [00:07<08:49, 3.62MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:   8% 133M/1.76G [00:07<01:15, 21.7MB/s]\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:   2% 44.4M/1.96G [00:07<08:07, 3.93MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  11% 214M/1.94G [00:08<01:04, 26.8MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:   2% 45.8M/1.96G [00:08<07:12, 4.43MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:   2% 43.1M/1.98G [00:08<08:26, 3.82MB/s]\n","model-00004-of-00004.safetensors:   8% 144M/1.76G [00:08<01:19, 20.4MB/s]\u001b[A\n","model-00003-of-00004.safetensors:   2% 44.4M/1.98G [00:08<07:48, 4.14MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  12% 224M/1.94G [00:08<01:12, 23.5MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00003-of-00004.safetensors:   2% 47.4M/1.98G [00:08<05:41, 5.66MB/s]\n","model-00004-of-00004.safetensors:   9% 166M/1.76G [00:09<01:07, 23.7MB/s]\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:   3% 49.3M/1.96G [00:09<08:37, 3.69MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  13% 244M/1.94G [00:09<01:07, 25.2MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:   3% 54.8M/1.96G [00:09<04:10, 7.59MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  13% 256M/1.94G [00:09<00:49, 33.7MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:   3% 54.0M/1.98G [00:09<04:17, 7.50MB/s]\n","\n","\n","model-00003-of-00004.safetensors:   3% 55.8M/1.98G [00:09<03:47, 8.46MB/s]\n","\n","\n","\n","model-00001-of-00004.safetensors:   3% 60.0M/1.96G [00:10<05:42, 5.54MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  14% 272M/1.94G [00:10<01:15, 22.0MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  15% 287M/1.94G [00:10<00:49, 33.2MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:   3% 61.9M/1.96G [00:10<05:07, 6.17MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:   3% 59.7M/1.98G [00:10<05:33, 5.76MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  15% 294M/1.94G [00:10<01:03, 26.0MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00003-of-00004.safetensors:   3% 61.9M/1.98G [00:11<04:56, 6.48MB/s]\n","model-00003-of-00004.safetensors:   3% 63.3M/1.98G [00:11<04:27, 7.18MB/s]\n","\n","\n","\n","model-00001-of-00004.safetensors:   3% 64.0M/1.96G [00:11<07:35, 4.16MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  16% 311M/1.94G [00:11<01:06, 24.5MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:   3% 68.3M/1.96G [00:11<04:45, 6.62MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:   4% 69.8M/1.96G [00:11<04:16, 7.37MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:   4% 73.5M/1.96G [00:11<03:13, 9.76MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:   3% 64.6M/1.98G [00:12<07:47, 4.10MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  17% 320M/1.94G [00:12<01:14, 21.8MB/s]\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:   4% 73.1M/1.98G [00:12<03:03, 10.4MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  17% 329M/1.94G [00:12<00:57, 28.1MB/s]\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:   4% 76.4M/1.98G [00:12<02:34, 12.3MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  17% 335M/1.94G [00:12<00:51, 31.1MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00003-of-00004.safetensors:   4% 80.0M/1.98G [00:12<02:49, 11.2MB/s]\n","model-00004-of-00004.safetensors:  11% 195M/1.76G [00:12<02:11, 11.9MB/s]\u001b[A\n","\n","\n","model-00003-of-00004.safetensors:   4% 85.7M/1.98G [00:12<01:55, 16.4MB/s]\n","model-00003-of-00004.safetensors:   5% 90.2M/1.98G [00:12<01:36, 19.7MB/s]\n","model-00003-of-00004.safetensors:   5% 94.9M/1.98G [00:13<01:18, 24.0MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  18% 356M/1.94G [00:13<01:05, 24.3MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:   4% 75.2M/1.96G [00:13<07:39, 4.10MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  19% 367M/1.94G [00:13<00:44, 35.5MB/s]\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  12% 212M/1.76G [00:13<01:34, 16.5MB/s]\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:   4% 76.5M/1.96G [00:13<07:09, 4.38MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:   4% 77.9M/1.96G [00:13<06:29, 4.82MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  19% 374M/1.94G [00:13<01:03, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  13% 224M/1.76G [00:14<01:23, 18.4MB/s]\u001b[A\n","model-00004-of-00004.safetensors:  14% 239M/1.76G [00:14<00:49, 30.9MB/s]\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  20% 384M/1.94G [00:14<01:11, 21.8MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  21% 400M/1.94G [00:14<00:44, 34.5MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:   4% 80.0M/1.96G [00:14<08:58, 3.49MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  14% 245M/1.76G [00:14<01:06, 22.8MB/s]\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:   5% 88.2M/1.96G [00:14<03:31, 8.84MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  14% 253M/1.76G [00:14<00:52, 28.6MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:   5% 98.6M/1.98G [00:14<05:12, 6.02MB/s]\n","\n","\n","model-00003-of-00004.safetensors:   5% 109M/1.98G [00:15<02:45, 11.3MB/s] \n","\n","\n","model-00002-of-00004.safetensors:  21% 412M/1.94G [00:15<00:52, 28.8MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:   5% 97.2M/1.96G [00:15<02:41, 11.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  15% 259M/1.76G [00:15<01:10, 21.5MB/s]\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:   5% 104M/1.96G [00:15<01:48, 17.1MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  15% 267M/1.76G [00:15<00:53, 27.9MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:   6% 126M/1.98G [00:15<01:30, 20.6MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  22% 417M/1.94G [00:15<01:10, 21.5MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  22% 428M/1.94G [00:15<00:48, 31.3MB/s]\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  15% 273M/1.76G [00:15<01:12, 20.5MB/s]\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:   6% 112M/1.96G [00:15<01:58, 15.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  16% 285M/1.76G [00:15<00:47, 31.3MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:   7% 133M/1.98G [00:16<01:46, 17.4MB/s]\n","\n","\n","model-00003-of-00004.safetensors:   7% 144M/1.98G [00:16<01:11, 25.9MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  23% 443M/1.94G [00:16<00:50, 29.4MB/s]\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  17% 291M/1.76G [00:16<01:01, 24.1MB/s]\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:   7% 128M/1.96G [00:16<01:32, 19.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:   8% 151M/1.98G [00:16<01:32, 19.9MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  23% 448M/1.94G [00:16<01:18, 18.9MB/s]\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  17% 304M/1.76G [00:17<01:02, 23.2MB/s]\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  24% 460M/1.94G [00:17<00:52, 28.4MB/s]\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  18% 311M/1.76G [00:17<00:51, 28.0MB/s]\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:   7% 144M/1.96G [00:17<01:27, 20.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  18% 318M/1.76G [00:17<00:44, 32.4MB/s]\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:   8% 151M/1.96G [00:17<01:11, 25.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  24% 466M/1.94G [00:17<01:04, 22.8MB/s]\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  18% 324M/1.76G [00:17<00:57, 25.1MB/s]\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  25% 479M/1.94G [00:17<00:42, 34.7MB/s]\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  19% 329M/1.76G [00:17<00:50, 28.5MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:   8% 156M/1.98G [00:17<02:31, 12.1MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:   8% 159M/1.98G [00:18<02:25, 12.5MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  25% 486M/1.94G [00:18<00:55, 26.2MB/s]\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  19% 336M/1.76G [00:18<01:07, 21.3MB/s]\u001b[A\n","model-00004-of-00004.safetensors:  20% 349M/1.76G [00:18<00:42, 33.5MB/s]\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:   9% 180M/1.96G [00:18<01:11, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  26% 496M/1.94G [00:18<01:03, 22.8MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  26% 511M/1.94G [00:18<00:40, 35.1MB/s]\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  20% 355M/1.76G [00:18<00:57, 24.6MB/s]\u001b[A\n","model-00004-of-00004.safetensors:  21% 368M/1.76G [00:18<00:37, 37.0MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:   8% 162M/1.98G [00:19<03:41, 8.21MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:   9% 171M/1.98G [00:19<02:21, 12.8MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  27% 518M/1.94G [00:19<00:54, 26.3MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:   9% 176M/1.98G [00:19<02:26, 12.3MB/s]\n","\n","\n","\n","model-00001-of-00004.safetensors:  11% 223M/1.96G [00:19<00:52, 33.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:   9% 182M/1.98G [00:19<01:53, 15.9MB/s]\n","model-00004-of-00004.safetensors:  22% 380M/1.76G [00:19<00:57, 24.0MB/s]\u001b[A\n","\n","\n","model-00003-of-00004.safetensors:   9% 187M/1.98G [00:19<01:30, 19.8MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  28% 534M/1.94G [00:19<00:55, 25.4MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  28% 544M/1.94G [00:20<00:41, 33.9MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  12% 229M/1.96G [00:20<01:08, 25.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  22% 385M/1.76G [00:20<01:08, 20.0MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  10% 192M/1.98G [00:20<01:47, 16.7MB/s]\n","model-00003-of-00004.safetensors:  10% 199M/1.98G [00:20<01:17, 22.9MB/s]\n","model-00003-of-00004.safetensors:  10% 207M/1.98G [00:20<00:57, 30.9MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  28% 550M/1.94G [00:20<00:56, 24.4MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  11% 212M/1.98G [00:20<01:21, 21.8MB/s]\n","model-00003-of-00004.safetensors:  11% 220M/1.98G [00:21<01:01, 28.8MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  29% 560M/1.94G [00:21<01:02, 22.1MB/s]\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  23% 410M/1.76G [00:21<00:58, 23.3MB/s]\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  29% 566M/1.94G [00:21<00:54, 25.4MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  13% 256M/1.96G [00:21<01:17, 21.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  30% 574M/1.94G [00:21<00:41, 32.8MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  11% 225M/1.98G [00:21<01:25, 20.6MB/s]\n","model-00003-of-00004.safetensors:  12% 237M/1.98G [00:21<00:53, 32.6MB/s]\n","model-00004-of-00004.safetensors:  24% 423M/1.76G [00:21<00:52, 25.3MB/s]\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  30% 580M/1.94G [00:21<00:59, 22.7MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  14% 272M/1.96G [00:21<01:16, 22.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  12% 243M/1.98G [00:22<01:14, 23.3MB/s]\n","model-00003-of-00004.safetensors:  13% 255M/1.98G [00:22<00:51, 33.3MB/s]\n","model-00004-of-00004.safetensors:  25% 439M/1.76G [00:22<00:48, 27.6MB/s]\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  31% 592M/1.94G [00:22<01:03, 21.3MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  31% 607M/1.94G [00:22<00:39, 33.3MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  15% 293M/1.96G [00:22<01:08, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  13% 261M/1.98G [00:22<01:11, 24.0MB/s]\n","model-00003-of-00004.safetensors:  14% 272M/1.98G [00:22<00:50, 34.1MB/s]\n","model-00004-of-00004.safetensors:  26% 457M/1.76G [00:22<00:43, 30.0MB/s]\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  32% 614M/1.94G [00:23<00:52, 25.0MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  14% 278M/1.98G [00:23<01:11, 23.9MB/s]\n","model-00004-of-00004.safetensors:  26% 464M/1.76G [00:23<00:57, 22.7MB/s]\u001b[A\n","model-00004-of-00004.safetensors:  27% 473M/1.76G [00:23<00:42, 30.1MB/s]\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  32% 624M/1.94G [00:23<00:59, 22.2MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  33% 639M/1.94G [00:23<00:38, 33.5MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  16% 320M/1.96G [00:23<01:15, 21.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  15% 302M/1.98G [00:23<00:50, 33.1MB/s]\n","model-00004-of-00004.safetensors:  27% 480M/1.76G [00:24<00:56, 22.8MB/s]\u001b[A\n","model-00004-of-00004.safetensors:  28% 494M/1.76G [00:24<00:35, 35.4MB/s]\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  33% 646M/1.94G [00:24<00:49, 26.3MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  16% 309M/1.98G [00:24<01:07, 24.8MB/s]\n","model-00004-of-00004.safetensors:  28% 501M/1.76G [00:24<00:49, 25.3MB/s]\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  34% 656M/1.94G [00:24<00:57, 22.5MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  18% 352M/1.96G [00:24<01:09, 23.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  35% 671M/1.94G [00:24<00:37, 33.6MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  17% 335M/1.98G [00:25<00:48, 33.8MB/s]\n","model-00004-of-00004.safetensors:  29% 512M/1.76G [00:25<00:56, 22.0MB/s]\u001b[A\n","model-00004-of-00004.safetensors:  30% 527M/1.76G [00:25<00:37, 33.4MB/s]\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  35% 678M/1.94G [00:25<00:49, 25.6MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  19% 370M/1.96G [00:25<01:06, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  17% 342M/1.98G [00:25<01:03, 25.8MB/s]\n","model-00004-of-00004.safetensors:  30% 534M/1.76G [00:25<00:46, 26.2MB/s]\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  36% 688M/1.94G [00:25<00:54, 22.7MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  36% 703M/1.94G [00:26<00:36, 34.1MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  18% 366M/1.98G [00:26<00:47, 33.7MB/s]\n","model-00004-of-00004.safetensors:  31% 544M/1.76G [00:26<00:52, 23.3MB/s]\u001b[A\n","model-00004-of-00004.safetensors:  32% 558M/1.76G [00:26<00:35, 34.4MB/s]\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  37% 711M/1.94G [00:26<00:46, 26.2MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  20% 400M/1.96G [00:26<01:07, 23.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  19% 374M/1.98G [00:26<01:01, 26.1MB/s]\n","model-00004-of-00004.safetensors:  32% 566M/1.76G [00:27<00:45, 26.5MB/s]\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  37% 720M/1.94G [00:27<00:53, 22.9MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  38% 735M/1.94G [00:27<00:35, 34.3MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  21% 421M/1.96G [00:27<00:59, 25.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  20% 398M/1.98G [00:27<00:46, 33.9MB/s]\n","model-00004-of-00004.safetensors:  33% 576M/1.76G [00:27<00:52, 22.6MB/s]\u001b[A\n","model-00004-of-00004.safetensors:  33% 583M/1.76G [00:27<00:44, 26.8MB/s]\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  38% 743M/1.94G [00:27<00:43, 27.6MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  39% 752M/1.94G [00:27<00:34, 34.1MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  20% 406M/1.98G [00:28<01:00, 26.2MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  39% 759M/1.94G [00:28<00:45, 25.8MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  23% 448M/1.96G [00:28<01:07, 22.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  21% 416M/1.98G [00:28<01:07, 23.3MB/s]\n","model-00003-of-00004.safetensors:  22% 431M/1.98G [00:28<00:45, 34.2MB/s]\n","\n","\n","\n","model-00001-of-00004.safetensors:  24% 470M/1.96G [00:28<00:55, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  22% 438M/1.98G [00:29<00:57, 26.7MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:  23% 463M/1.98G [00:29<00:44, 34.3MB/s]\n","model-00004-of-00004.safetensors:  34% 592M/1.76G [00:29<02:08, 9.11MB/s]\u001b[A\n","model-00004-of-00004.safetensors:  34% 607M/1.76G [00:30<01:08, 16.8MB/s]\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  25% 496M/1.96G [00:30<01:04, 22.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  24% 470M/1.98G [00:30<00:55, 27.4MB/s]\n","model-00004-of-00004.safetensors:  35% 613M/1.76G [00:30<01:15, 15.2MB/s]\u001b[A\n","model-00004-of-00004.safetensors:  35% 620M/1.76G [00:30<01:01, 18.5MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  24% 480M/1.98G [00:30<01:00, 24.6MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:  25% 487M/1.98G [00:30<00:52, 28.3MB/s]\n","\n","\n","\n","model-00001-of-00004.safetensors:  27% 531M/1.96G [00:31<01:00, 23.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  35% 625M/1.76G [00:31<01:22, 13.7MB/s]\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  28% 543M/1.96G [00:31<00:42, 33.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  25% 503M/1.98G [00:31<00:53, 27.6MB/s]\n","model-00004-of-00004.safetensors:  36% 640M/1.76G [00:31<01:01, 18.3MB/s]\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  28% 550M/1.96G [00:31<00:57, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  37% 648M/1.76G [00:32<00:46, 24.2MB/s]\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  28% 556M/1.96G [00:32<00:49, 28.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  27% 526M/1.98G [00:32<00:43, 33.5MB/s]\n","\n","\n","\n","model-00001-of-00004.safetensors:  29% 561M/1.96G [00:32<01:06, 21.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  37% 659M/1.76G [00:32<00:53, 20.7MB/s]\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  29% 575M/1.96G [00:32<00:40, 34.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  27% 544M/1.98G [00:32<00:42, 34.0MB/s]\n","\n","\n","\n","model-00001-of-00004.safetensors:  30% 582M/1.96G [00:33<00:55, 24.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  38% 672M/1.76G [00:33<00:58, 18.8MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  28% 560M/1.98G [00:33<00:44, 31.8MB/s]\n","\n","\n","\n","model-00001-of-00004.safetensors:  30% 592M/1.96G [00:33<01:06, 20.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  40% 768M/1.94G [00:33<04:03, 4.80MB/s]\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  39% 693M/1.76G [00:33<00:42, 25.1MB/s]\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  31% 602M/1.96G [00:33<00:49, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  29% 566M/1.98G [00:34<01:03, 22.2MB/s]\n","\n","\n","model-00003-of-00004.safetensors:  29% 573M/1.98G [00:34<00:52, 26.8MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  40% 777M/1.94G [00:34<02:53, 6.70MB/s]\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  40% 705M/1.76G [00:34<00:46, 22.6MB/s]\u001b[A\n","model-00004-of-00004.safetensors:  41% 720M/1.76G [00:34<00:27, 37.9MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  29% 578M/1.98G [00:34<01:03, 22.1MB/s]\n","\n","\n","\n","model-00001-of-00004.safetensors:  32% 623M/1.96G [00:34<00:42, 31.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00003-of-00004.safetensors:  30% 585M/1.98G [00:34<00:50, 27.4MB/s]\n","\n","\n","model-00003-of-00004.safetensors:  30% 591M/1.98G [00:34<00:42, 32.4MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  41% 799M/1.94G [00:34<01:13, 15.4MB/s]\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  41% 727M/1.76G [00:34<00:39, 26.4MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  30% 596M/1.98G [00:35<00:57, 24.1MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:  30% 602M/1.98G [00:35<00:48, 28.4MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  42% 804M/1.94G [00:35<01:22, 13.8MB/s]\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  42% 736M/1.76G [00:35<00:45, 22.7MB/s]\u001b[A\n","model-00004-of-00004.safetensors:  43% 750M/1.76G [00:35<00:29, 34.9MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  31% 619M/1.98G [00:35<00:43, 31.7MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  42% 816M/1.94G [00:35<01:07, 16.7MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  43% 827M/1.94G [00:35<00:46, 23.8MB/s]\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  43% 758M/1.76G [00:36<00:38, 26.4MB/s]\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  33% 656M/1.96G [00:36<00:58, 22.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  32% 638M/1.98G [00:36<00:37, 35.8MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  43% 832M/1.94G [00:36<01:01, 18.1MB/s]\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  44% 768M/1.76G [00:36<00:42, 23.6MB/s]\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  44% 847M/1.94G [00:36<00:36, 29.7MB/s]\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  33% 646M/1.98G [00:36<00:51, 25.9MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:  33% 655M/1.98G [00:37<00:40, 32.4MB/s]\n","\n","\n","\n","model-00001-of-00004.safetensors:  35% 683M/1.96G [00:37<00:52, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  44% 784M/1.76G [00:37<00:40, 24.0MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  33% 661M/1.98G [00:37<00:53, 24.6MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:  34% 672M/1.98G [00:37<00:38, 33.9MB/s]\n","\n","\n","\n","model-00001-of-00004.safetensors:  36% 696M/1.96G [00:37<00:50, 25.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  44% 854M/1.94G [00:37<01:07, 16.2MB/s]\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  46% 805M/1.76G [00:37<00:37, 25.5MB/s]\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  44% 859M/1.94G [00:37<00:59, 18.3MB/s]\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  34% 678M/1.98G [00:38<00:53, 24.3MB/s]\n","\n","\n","\n","model-00001-of-00004.safetensors:  36% 704M/1.96G [00:38<00:57, 21.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  36% 715M/1.96G [00:38<00:40, 30.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  35% 703M/1.98G [00:38<00:37, 34.2MB/s]\n","\n","\n","\n","model-00001-of-00004.safetensors:  37% 720M/1.96G [00:38<01:01, 20.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  47% 832M/1.76G [00:38<00:41, 22.6MB/s]\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  37% 733M/1.96G [00:39<00:39, 31.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  48% 838M/1.76G [00:39<00:35, 26.0MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  36% 710M/1.98G [00:39<00:48, 26.0MB/s]\n","model-00004-of-00004.safetensors:  48% 850M/1.76G [00:39<00:37, 24.7MB/s]\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  38% 740M/1.96G [00:39<00:51, 23.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  49% 857M/1.76G [00:39<00:28, 31.5MB/s]\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  38% 746M/1.96G [00:39<00:44, 27.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  37% 734M/1.98G [00:39<00:35, 34.8MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  45% 864M/1.94G [00:39<02:20, 7.66MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  45% 877M/1.94G [00:40<01:22, 12.8MB/s]\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  49% 864M/1.76G [00:40<00:38, 23.6MB/s]\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  39% 757M/1.96G [00:40<00:49, 24.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  50% 873M/1.76G [00:40<00:27, 32.0MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  37% 742M/1.98G [00:40<00:46, 26.6MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  46% 882M/1.94G [00:40<01:23, 12.6MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  46% 893M/1.94G [00:40<00:55, 18.9MB/s]\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  50% 880M/1.76G [00:40<00:36, 24.1MB/s]\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  39% 768M/1.96G [00:40<00:56, 21.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  50% 889M/1.76G [00:40<00:27, 31.5MB/s]\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  40% 777M/1.96G [00:40<00:40, 29.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  51% 895M/1.76G [00:40<00:24, 36.2MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  38% 752M/1.98G [00:41<01:02, 19.7MB/s]\n","model-00004-of-00004.safetensors:  51% 901M/1.76G [00:41<00:32, 26.9MB/s]\u001b[A\n","model-00004-of-00004.safetensors:  52% 908M/1.76G [00:41<00:25, 33.8MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  39% 764M/1.98G [00:41<00:47, 25.5MB/s]\n","\n","\n","\n","model-00001-of-00004.safetensors:  40% 792M/1.96G [00:41<00:50, 23.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  41% 799M/1.96G [00:41<00:37, 30.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  39% 769M/1.98G [00:41<01:00, 20.2MB/s]\n","model-00004-of-00004.safetensors:  52% 924M/1.76G [00:41<00:25, 32.4MB/s]\u001b[A\n","\n","\n","model-00003-of-00004.safetensors:  39% 780M/1.98G [00:42<00:39, 30.2MB/s]\n","\n","\n","\n","model-00001-of-00004.safetensors:  41% 804M/1.96G [00:42<00:58, 19.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  47% 904M/1.94G [00:42<01:22, 12.5MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  41% 807M/1.96G [00:42<00:53, 21.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  47% 910M/1.94G [00:42<01:07, 15.3MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  40% 799M/1.98G [00:42<00:33, 35.5MB/s]\n","model-00004-of-00004.safetensors:  53% 929M/1.76G [00:42<00:43, 19.0MB/s]\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  42% 819M/1.96G [00:42<00:53, 21.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  47% 914M/1.94G [00:42<01:15, 13.6MB/s]\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  53% 942M/1.76G [00:42<00:27, 30.1MB/s]\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  47% 918M/1.94G [00:42<01:05, 15.5MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  42% 823M/1.96G [00:42<00:49, 23.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  42% 831M/1.96G [00:42<00:34, 32.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00003-of-00004.safetensors:  41% 807M/1.98G [00:43<00:46, 25.4MB/s]\n","model-00004-of-00004.safetensors:  54% 949M/1.76G [00:43<00:35, 23.1MB/s]\u001b[A\n","model-00004-of-00004.safetensors:  54% 958M/1.76G [00:43<00:26, 30.3MB/s]\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  43% 836M/1.96G [00:43<00:50, 22.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  43% 844M/1.96G [00:43<00:36, 30.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  48% 928M/1.94G [00:43<01:07, 14.9MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00003-of-00004.safetensors:  41% 816M/1.98G [00:43<00:53, 21.8MB/s]\n","model-00003-of-00004.safetensors:  42% 828M/1.98G [00:43<00:37, 30.5MB/s]\n","model-00004-of-00004.safetensors:  55% 969M/1.76G [00:43<00:29, 27.3MB/s]\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  43% 849M/1.96G [00:43<00:55, 19.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  44% 864M/1.96G [00:44<00:30, 35.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  49% 944M/1.94G [00:44<00:56, 17.5MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00003-of-00004.safetensors:  42% 834M/1.98G [00:44<00:48, 23.6MB/s]\n","model-00003-of-00004.safetensors:  43% 846M/1.98G [00:44<00:33, 34.1MB/s]\n","model-00004-of-00004.safetensors:  56% 985M/1.76G [00:44<00:26, 29.0MB/s]\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  44% 871M/1.96G [00:44<00:43, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00003-of-00004.safetensors:  43% 853M/1.98G [00:44<00:44, 25.4MB/s]\n","model-00004-of-00004.safetensors:  56% 992M/1.76G [00:44<00:35, 21.5MB/s]\u001b[A\n","model-00004-of-00004.safetensors:  57% 1.01G/1.76G [00:45<00:22, 34.3MB/s]\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  45% 880M/1.96G [00:45<00:50, 21.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  46% 895M/1.96G [00:45<00:31, 33.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  50% 976M/1.94G [00:45<00:45, 21.3MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00003-of-00004.safetensors:  44% 878M/1.98G [00:45<00:32, 33.8MB/s]\n","model-00004-of-00004.safetensors:  57% 1.01G/1.76G [00:45<00:29, 25.2MB/s]\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  46% 902M/1.96G [00:45<00:42, 25.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00003-of-00004.safetensors:  45% 885M/1.98G [00:46<00:42, 25.8MB/s]\n","model-00003-of-00004.safetensors:  45% 892M/1.98G [00:46<00:36, 30.2MB/s]\n","model-00004-of-00004.safetensors:  59% 1.03G/1.76G [00:46<00:23, 30.5MB/s]\u001b[A\n","model-00004-of-00004.safetensors:  59% 1.04G/1.76G [00:46<00:21, 33.6MB/s]\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  47% 912M/1.96G [00:46<00:46, 22.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  47% 926M/1.96G [00:46<00:30, 33.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  52% 1.01G/1.94G [00:46<00:41, 22.5MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  53% 1.02G/1.94G [00:46<00:31, 28.9MB/s]\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  45% 898M/1.98G [00:46<00:50, 21.5MB/s]\n","model-00003-of-00004.safetensors:  46% 905M/1.98G [00:46<00:41, 26.0MB/s]\n","\n","\n","\n","model-00001-of-00004.safetensors:  48% 934M/1.96G [00:46<00:39, 25.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  47% 926M/1.98G [00:47<00:31, 33.1MB/s]\n","\n","\n","\n","model-00001-of-00004.safetensors:  48% 944M/1.96G [00:47<00:44, 22.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  49% 958M/1.96G [00:47<00:30, 33.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  61% 1.07G/1.76G [00:47<00:27, 25.4MB/s]\u001b[A\n","model-00004-of-00004.safetensors:  62% 1.09G/1.76G [00:47<00:17, 38.4MB/s]\u001b[A\n","\n","\n","model-00003-of-00004.safetensors:  48% 943M/1.98G [00:48<00:32, 32.4MB/s]\n","\n","\n","\n","model-00001-of-00004.safetensors:  49% 965M/1.96G [00:48<00:39, 25.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  48% 949M/1.98G [00:48<00:42, 24.4MB/s]\n","\n","\n","\n","model-00001-of-00004.safetensors:  50% 976M/1.96G [00:48<00:42, 22.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  53% 1.03G/1.94G [00:48<01:28, 10.3MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  51% 990M/1.96G [00:48<00:29, 33.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  63% 1.10G/1.76G [00:48<00:27, 24.2MB/s]\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  53% 1.03G/1.94G [00:48<01:19, 11.4MB/s]\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  63% 1.11G/1.76G [00:48<00:24, 27.0MB/s]\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  53% 1.04G/1.94G [00:48<01:00, 15.0MB/s]\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  49% 971M/1.98G [00:49<00:32, 30.7MB/s]\n","\n","\n","\n","model-00001-of-00004.safetensors:  51% 998M/1.96G [00:49<00:36, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  54% 1.04G/1.94G [00:49<01:09, 12.9MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  54% 1.05G/1.94G [00:49<00:48, 18.5MB/s]\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  64% 1.12G/1.76G [00:49<00:29, 21.6MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  50% 992M/1.98G [00:49<00:27, 35.8MB/s]\n","\n","\n","\n","model-00001-of-00004.safetensors:  51% 1.01G/1.96G [00:49<00:41, 22.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  52% 1.02G/1.96G [00:49<00:27, 33.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  50% 999M/1.98G [00:50<00:36, 27.0MB/s]\n","\n","\n","\n","model-00001-of-00004.safetensors:  53% 1.03G/1.96G [00:50<00:35, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  54% 1.05G/1.94G [00:50<01:26, 10.3MB/s]\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  65% 1.15G/1.76G [00:50<00:26, 23.0MB/s]\u001b[A\n","model-00004-of-00004.safetensors:  66% 1.17G/1.76G [00:50<00:16, 35.1MB/s]\u001b[A\n","\n","\n","model-00003-of-00004.safetensors:  52% 1.02G/1.98G [00:50<00:28, 33.9MB/s]\n","\n","\n","\n","model-00001-of-00004.safetensors:  53% 1.04G/1.96G [00:51<00:38, 23.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  54% 1.05G/1.96G [00:51<00:25, 34.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  52% 1.03G/1.98G [00:51<00:35, 26.6MB/s]\n","\n","\n","\n","model-00001-of-00004.safetensors:  54% 1.06G/1.96G [00:51<00:33, 27.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  67% 1.18G/1.76G [00:51<00:24, 24.0MB/s]\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  55% 1.06G/1.94G [00:51<02:18, 6.37MB/s]\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  68% 1.20G/1.76G [00:51<00:16, 34.6MB/s]\u001b[A\n","\n","\n","model-00003-of-00004.safetensors:  52% 1.04G/1.98G [00:51<00:38, 24.4MB/s]\n","\n","\n","model-00003-of-00004.safetensors:  53% 1.05G/1.98G [00:52<00:33, 28.3MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:  53% 1.06G/1.98G [00:52<00:26, 34.5MB/s]\n","\n","\n","\n","model-00001-of-00004.safetensors:  55% 1.08G/1.96G [00:52<00:29, 29.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  68% 1.20G/1.76G [00:52<00:21, 26.6MB/s]\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  55% 1.07G/1.94G [00:52<01:11, 12.2MB/s]\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  69% 1.22G/1.76G [00:52<00:15, 34.6MB/s]\u001b[A\n","\n","\n","model-00003-of-00004.safetensors:  54% 1.06G/1.98G [00:52<00:36, 24.9MB/s]\n","\n","\n","\n","model-00001-of-00004.safetensors:  56% 1.09G/1.96G [00:52<00:38, 22.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  56% 1.10G/1.96G [00:52<00:24, 35.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  69% 1.22G/1.76G [00:52<00:20, 26.1MB/s]\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  56% 1.09G/1.94G [00:53<00:48, 17.5MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00003-of-00004.safetensors:  55% 1.09G/1.98G [00:53<00:26, 33.7MB/s]\n","\n","\n","\n","model-00001-of-00004.safetensors:  57% 1.11G/1.96G [00:53<00:31, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  70% 1.23G/1.76G [00:53<00:23, 22.5MB/s]\u001b[A\n","model-00004-of-00004.safetensors:  71% 1.25G/1.76G [00:53<00:15, 34.1MB/s]\u001b[A\n","\n","\n","model-00003-of-00004.safetensors:  56% 1.10G/1.98G [00:53<00:26, 33.4MB/s]\n","\n","\n","\n","model-00001-of-00004.safetensors:  57% 1.12G/1.96G [00:53<00:36, 23.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  58% 1.13G/1.96G [00:54<00:23, 34.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  56% 1.11G/1.98G [00:54<00:35, 24.4MB/s]\n","\n","\n","\n","model-00001-of-00004.safetensors:  58% 1.14G/1.96G [00:54<00:31, 26.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  72% 1.26G/1.76G [00:54<00:21, 23.4MB/s]\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  59% 1.15G/1.96G [00:54<00:24, 33.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  72% 1.27G/1.76G [00:54<00:15, 31.0MB/s]\u001b[A\n","\n","\n","model-00003-of-00004.safetensors:  57% 1.12G/1.98G [00:54<00:39, 21.8MB/s]\n","\n","\n","model-00003-of-00004.safetensors:  57% 1.13G/1.98G [00:55<00:26, 32.5MB/s]\n","\n","\n","\n","model-00001-of-00004.safetensors:  59% 1.16G/1.96G [00:55<00:31, 25.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  60% 1.17G/1.96G [00:55<00:26, 30.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  73% 1.28G/1.76G [00:55<00:20, 23.3MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  58% 1.14G/1.98G [00:55<00:33, 25.1MB/s]\n","model-00004-of-00004.safetensors:  74% 1.30G/1.76G [00:55<00:20, 22.5MB/s]\u001b[A\n","model-00004-of-00004.safetensors:  74% 1.31G/1.76G [00:56<00:12, 35.2MB/s]\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  58% 1.12G/1.94G [00:56<01:35, 8.51MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  58% 1.15G/1.98G [00:56<00:35, 23.1MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  59% 1.14G/1.94G [00:56<00:49, 16.2MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  58% 1.16G/1.98G [00:56<00:30, 27.1MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:  59% 1.17G/1.98G [00:56<00:26, 30.6MB/s]\n","model-00004-of-00004.safetensors:  75% 1.32G/1.76G [00:56<00:17, 26.1MB/s]\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  59% 1.14G/1.94G [00:56<00:55, 14.4MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  59% 1.15G/1.94G [00:56<00:35, 22.4MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  59% 1.17G/1.98G [00:56<00:33, 24.4MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:  59% 1.18G/1.98G [00:56<00:28, 28.2MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:  60% 1.18G/1.98G [00:56<00:24, 32.5MB/s]\n","model-00004-of-00004.safetensors:  75% 1.33G/1.76G [00:57<00:18, 23.5MB/s]\u001b[A\n","model-00004-of-00004.safetensors:  76% 1.34G/1.76G [00:57<00:12, 32.8MB/s]\u001b[A\n","\n","\n","model-00003-of-00004.safetensors:  60% 1.19G/1.98G [00:57<00:33, 24.1MB/s]\n","\n","\n","\n","model-00001-of-00004.safetensors:  61% 1.20G/1.96G [00:57<00:34, 21.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  60% 1.20G/1.98G [00:57<00:23, 33.3MB/s]\n","model-00004-of-00004.safetensors:  76% 1.35G/1.76G [00:57<00:16, 25.5MB/s]\u001b[A\n","model-00004-of-00004.safetensors:  77% 1.36G/1.76G [00:57<00:12, 32.8MB/s]\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  60% 1.17G/1.94G [00:57<00:41, 18.7MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  61% 1.18G/1.94G [00:57<00:25, 29.8MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  61% 1.21G/1.98G [00:58<00:29, 26.2MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:  61% 1.21G/1.98G [00:58<00:23, 32.1MB/s]\n","model-00004-of-00004.safetensors:  77% 1.36G/1.76G [00:58<00:16, 24.1MB/s]\u001b[A\n","model-00004-of-00004.safetensors:  78% 1.37G/1.76G [00:58<00:11, 33.9MB/s]\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  61% 1.19G/1.94G [00:58<00:31, 23.7MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  63% 1.23G/1.96G [00:58<00:30, 24.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00003-of-00004.safetensors:  61% 1.22G/1.98G [00:58<00:34, 22.2MB/s]\n","\n","\n","\n","model-00001-of-00004.safetensors:  63% 1.24G/1.96G [00:58<00:23, 30.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  62% 1.23G/1.98G [00:58<00:22, 33.8MB/s]\n","model-00004-of-00004.safetensors:  78% 1.38G/1.76G [00:58<00:15, 24.8MB/s]\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  62% 1.21G/1.94G [00:58<00:30, 23.8MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  64% 1.25G/1.96G [00:59<00:27, 25.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  62% 1.24G/1.98G [00:59<00:35, 21.1MB/s]\n","model-00004-of-00004.safetensors:  79% 1.39G/1.76G [00:59<00:16, 22.8MB/s]\u001b[A\n","model-00004-of-00004.safetensors:  80% 1.41G/1.76G [00:59<00:10, 34.4MB/s]\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  63% 1.22G/1.94G [00:59<00:33, 21.6MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  63% 1.23G/1.94G [00:59<00:21, 32.9MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  64% 1.26G/1.98G [00:59<00:23, 30.6MB/s]\n","model-00004-of-00004.safetensors:  80% 1.41G/1.76G [01:00<00:13, 25.7MB/s]\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  64% 1.24G/1.94G [01:00<00:26, 26.0MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  65% 1.28G/1.96G [01:00<00:31, 21.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  64% 1.26G/1.98G [01:00<00:34, 20.6MB/s]\n","model-00003-of-00004.safetensors:  65% 1.28G/1.98G [01:00<00:20, 33.5MB/s]\n","model-00004-of-00004.safetensors:  81% 1.43G/1.76G [01:00<00:11, 28.8MB/s]\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  64% 1.25G/1.94G [01:00<00:30, 22.8MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  65% 1.26G/1.94G [01:00<00:21, 31.5MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  65% 1.29G/1.98G [01:01<00:27, 25.7MB/s]\n","model-00004-of-00004.safetensors:  82% 1.44G/1.76G [01:01<00:14, 22.5MB/s]\u001b[A\n","model-00004-of-00004.safetensors:  82% 1.45G/1.76G [01:01<00:08, 34.6MB/s]\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  65% 1.27G/1.94G [01:01<00:27, 24.3MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  66% 1.28G/1.94G [01:01<00:20, 32.8MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  67% 1.31G/1.96G [01:01<00:28, 22.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  66% 1.31G/1.98G [01:01<00:19, 34.6MB/s]\n","model-00004-of-00004.safetensors:  83% 1.46G/1.76G [01:01<00:11, 26.4MB/s]\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  66% 1.28G/1.94G [01:01<00:26, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  66% 1.32G/1.98G [01:02<00:25, 26.0MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  67% 1.30G/1.94G [01:02<00:27, 23.0MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  68% 1.31G/1.94G [01:02<00:18, 34.5MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  69% 1.34G/1.96G [01:02<00:27, 22.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  68% 1.34G/1.98G [01:02<00:19, 33.4MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  68% 1.32G/1.94G [01:03<00:23, 26.4MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  68% 1.35G/1.98G [01:03<00:24, 26.1MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  69% 1.33G/1.94G [01:03<00:25, 23.6MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  69% 1.34G/1.94G [01:03<00:17, 35.0MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  70% 1.38G/1.96G [01:03<00:25, 22.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  69% 1.37G/1.98G [01:04<00:17, 34.4MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  70% 1.35G/1.94G [01:04<00:21, 27.0MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  70% 1.36G/1.94G [01:04<00:19, 29.9MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  71% 1.40G/1.96G [01:04<00:21, 26.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  70% 1.38G/1.98G [01:04<00:22, 26.4MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:  70% 1.39G/1.98G [01:05<00:25, 23.5MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:  71% 1.41G/1.98G [01:05<00:16, 34.0MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  70% 1.36G/1.94G [01:05<00:39, 14.5MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  71% 1.37G/1.94G [01:05<00:24, 23.0MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  73% 1.43G/1.96G [01:05<00:24, 22.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  71% 1.41G/1.98G [01:05<00:23, 24.5MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  71% 1.38G/1.94G [01:06<00:28, 19.6MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  73% 1.44G/1.98G [01:06<00:16, 33.3MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  72% 1.39G/1.94G [01:06<00:28, 19.2MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  73% 1.41G/1.94G [01:06<00:17, 29.8MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  74% 1.46G/1.96G [01:06<00:23, 21.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  73% 1.44G/1.98G [01:06<00:21, 24.6MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  73% 1.41G/1.94G [01:07<00:21, 23.9MB/s]\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  83% 1.47G/1.76G [01:07<00:57, 5.11MB/s]\u001b[A\n","model-00004-of-00004.safetensors:  84% 1.48G/1.76G [01:07<00:42, 6.64MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  74% 1.46G/1.98G [01:07<00:19, 27.0MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  73% 1.42G/1.94G [01:07<00:23, 22.0MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  74% 1.44G/1.94G [01:07<00:15, 33.0MB/s]\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  84% 1.49G/1.76G [01:07<00:34, 7.98MB/s]\u001b[A\n","model-00004-of-00004.safetensors:  85% 1.50G/1.76G [01:08<00:20, 13.0MB/s]\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  76% 1.49G/1.96G [01:08<00:20, 22.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  75% 1.48G/1.98G [01:08<00:15, 31.5MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  75% 1.45G/1.94G [01:08<00:18, 26.3MB/s]\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  86% 1.51G/1.76G [01:08<00:19, 13.2MB/s]\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  77% 1.51G/1.96G [01:08<00:18, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  75% 1.49G/1.98G [01:08<00:22, 22.3MB/s]\n","\n","\n","model-00003-of-00004.safetensors:  76% 1.50G/1.98G [01:08<00:13, 34.8MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  76% 1.47G/1.94G [01:09<00:15, 30.5MB/s]\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  86% 1.52G/1.76G [01:09<00:16, 14.7MB/s]\u001b[A\n","model-00004-of-00004.safetensors:  87% 1.53G/1.76G [01:09<00:10, 22.5MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  76% 1.51G/1.98G [01:09<00:18, 25.9MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  76% 1.47G/1.94G [01:09<00:19, 23.7MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  77% 1.48G/1.94G [01:09<00:14, 31.0MB/s]\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  87% 1.54G/1.76G [01:09<00:11, 20.0MB/s]\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  78% 1.54G/1.96G [01:09<00:18, 23.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  77% 1.54G/1.98G [01:10<00:12, 34.4MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  77% 1.49G/1.94G [01:10<00:20, 22.4MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  78% 1.50G/1.94G [01:10<00:12, 34.7MB/s]\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  88% 1.55G/1.76G [01:10<00:10, 19.3MB/s]\u001b[A\n","model-00004-of-00004.safetensors:  89% 1.56G/1.76G [01:10<00:07, 27.3MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  78% 1.54G/1.98G [01:10<00:16, 26.3MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  78% 1.51G/1.94G [01:10<00:16, 26.5MB/s]\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  89% 1.57G/1.76G [01:10<00:08, 22.3MB/s]\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  80% 1.57G/1.96G [01:10<00:17, 22.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  79% 1.57G/1.98G [01:11<00:12, 34.0MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  78% 1.52G/1.94G [01:11<00:18, 22.7MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  79% 1.53G/1.94G [01:11<00:11, 34.3MB/s]\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  90% 1.58G/1.76G [01:11<00:08, 22.1MB/s]\u001b[A\n","model-00004-of-00004.safetensors:  91% 1.60G/1.76G [01:11<00:05, 32.2MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  79% 1.57G/1.98G [01:11<00:15, 25.7MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  80% 1.54G/1.94G [01:11<00:15, 25.1MB/s]\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  91% 1.61G/1.76G [01:12<00:06, 24.9MB/s]\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  82% 1.60G/1.96G [01:12<00:15, 23.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  81% 1.60G/1.98G [01:12<00:11, 33.0MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  80% 1.55G/1.94G [01:12<00:17, 22.6MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  81% 1.57G/1.94G [01:12<00:10, 33.8MB/s]\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  92% 1.62G/1.76G [01:12<00:06, 22.4MB/s]\u001b[A\n","model-00004-of-00004.safetensors:  92% 1.63G/1.76G [01:12<00:04, 33.0MB/s]\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  83% 1.62G/1.96G [01:12<00:13, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  81% 1.61G/1.98G [01:12<00:15, 25.1MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  81% 1.57G/1.94G [01:13<00:13, 26.1MB/s]\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  93% 1.64G/1.76G [01:13<00:04, 26.1MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  82% 1.63G/1.98G [01:13<00:10, 34.2MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  82% 1.58G/1.94G [01:13<00:15, 22.9MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  83% 1.60G/1.94G [01:13<00:09, 34.0MB/s]\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  93% 1.65G/1.76G [01:13<00:05, 22.8MB/s]\u001b[A\n","model-00004-of-00004.safetensors:  94% 1.66G/1.76G [01:13<00:03, 33.4MB/s]\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  84% 1.65G/1.96G [01:14<00:14, 21.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  83% 1.64G/1.98G [01:14<00:13, 25.7MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  83% 1.61G/1.94G [01:14<00:12, 25.7MB/s]\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  95% 1.67G/1.76G [01:14<00:03, 25.9MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  84% 1.66G/1.98G [01:14<00:10, 30.6MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  83% 1.62G/1.94G [01:14<00:14, 22.5MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  84% 1.63G/1.94G [01:14<00:09, 33.4MB/s]\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  95% 1.68G/1.76G [01:15<00:03, 23.1MB/s]\u001b[A\n","model-00004-of-00004.safetensors:  96% 1.69G/1.76G [01:15<00:02, 31.9MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  84% 1.66G/1.98G [01:15<00:13, 23.3MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:  84% 1.67G/1.98G [01:15<00:10, 30.6MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  85% 1.64G/1.94G [01:15<00:11, 26.1MB/s]\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  96% 1.70G/1.76G [01:15<00:02, 25.2MB/s]\u001b[A\n","model-00004-of-00004.safetensors:  97% 1.71G/1.76G [01:15<00:01, 30.2MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  85% 1.69G/1.98G [01:15<00:08, 35.4MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  85% 1.65G/1.94G [01:16<00:12, 22.8MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  86% 1.66G/1.94G [01:16<00:08, 33.7MB/s]\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  97% 1.71G/1.76G [01:16<00:02, 21.8MB/s]\u001b[A\n","model-00004-of-00004.safetensors:  98% 1.73G/1.76G [01:16<00:01, 34.7MB/s]\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  87% 1.71G/1.96G [01:16<00:10, 22.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  86% 1.71G/1.98G [01:16<00:07, 34.4MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  86% 1.67G/1.94G [01:16<00:10, 26.4MB/s]\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  98% 1.73G/1.76G [01:16<00:01, 26.4MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  87% 1.72G/1.98G [01:17<00:10, 25.5MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  87% 1.68G/1.94G [01:17<00:11, 23.0MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  87% 1.69G/1.94G [01:17<00:07, 33.6MB/s]\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  99% 1.74G/1.76G [01:17<00:00, 23.1MB/s]\u001b[A\n","model-00004-of-00004.safetensors: 100% 1.76G/1.76G [01:17<00:00, 32.5MB/s]\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  89% 1.74G/1.96G [01:17<00:09, 22.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  88% 1.74G/1.98G [01:17<00:07, 32.2MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  88% 1.70G/1.94G [01:17<00:08, 26.3MB/s]\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors: 100% 1.76G/1.76G [01:17<00:00, 25.2MB/s]\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  88% 1.71G/1.94G [01:17<00:06, 33.2MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00004-of-00004.safetensors: 100% 1.76G/1.76G [01:18<00:00, 22.5MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  89% 1.72G/1.94G [01:18<00:09, 24.3MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  91% 1.78G/1.96G [01:18<00:08, 22.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  90% 1.77G/1.98G [01:18<00:06, 34.1MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  89% 1.73G/1.94G [01:19<00:09, 21.5MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  90% 1.74G/1.94G [01:19<00:05, 32.6MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  90% 1.78G/1.98G [01:19<00:07, 26.5MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  90% 1.75G/1.94G [01:19<00:07, 25.5MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  92% 1.81G/1.96G [01:19<00:06, 23.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  91% 1.81G/1.98G [01:20<00:05, 34.0MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  91% 1.76G/1.94G [01:20<00:07, 23.0MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  92% 1.78G/1.94G [01:20<00:04, 34.4MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  92% 1.81G/1.98G [01:20<00:06, 26.0MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  92% 1.78G/1.94G [01:20<00:05, 26.1MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  94% 1.84G/1.96G [01:21<00:05, 22.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  93% 1.84G/1.98G [01:21<00:04, 31.9MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  92% 1.79G/1.94G [01:21<00:06, 22.4MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  93% 1.81G/1.94G [01:21<00:03, 33.1MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  93% 1.85G/1.98G [01:21<00:04, 26.8MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  94% 1.81G/1.94G [01:22<00:06, 20.6MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  96% 1.87G/1.96G [01:22<00:03, 21.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  94% 1.82G/1.94G [01:22<00:04, 24.6MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  94% 1.87G/1.98G [01:22<00:03, 34.2MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  94% 1.83G/1.94G [01:22<00:05, 21.3MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  96% 1.89G/1.96G [01:22<00:03, 22.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  95% 1.88G/1.98G [01:23<00:04, 23.2MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  95% 1.84G/1.94G [01:23<00:04, 22.3MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  96% 1.85G/1.94G [01:23<00:02, 33.3MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  97% 1.91G/1.96G [01:23<00:02, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  96% 1.90G/1.98G [01:23<00:02, 34.0MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  96% 1.86G/1.94G [01:24<00:03, 24.5MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  98% 1.93G/1.96G [01:24<00:01, 24.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  97% 1.87G/1.94G [01:24<00:02, 22.2MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors:  99% 1.94G/1.96G [01:24<00:00, 23.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00002-of-00004.safetensors:  97% 1.89G/1.94G [01:24<00:01, 32.3MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  96% 1.91G/1.98G [01:24<00:04, 17.2MB/s]\n","\n","\n","model-00002-of-00004.safetensors:  98% 1.89G/1.94G [01:25<00:01, 25.4MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00001-of-00004.safetensors: 100% 1.96G/1.96G [01:25<00:00, 22.8MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  98% 1.90G/1.94G [01:25<00:01, 23.1MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","model-00003-of-00004.safetensors:  98% 1.94G/1.98G [01:26<00:01, 22.5MB/s]\n","\n","\n","model-00003-of-00004.safetensors:  99% 1.97G/1.98G [01:26<00:00, 31.4MB/s]\n","\n","\n","model-00002-of-00004.safetensors: 100% 1.94G/1.94G [01:27<00:00, 22.2MB/s]\n","model-00003-of-00004.safetensors: 100% 1.98G/1.98G [01:27<00:00, 22.6MB/s]\n","\n","\n","Upload 4 LFS files: 100% 4/4 [01:28<00:00, 22.07s/it]\n","[INFO|tokenization_utils_base.py:2488] 2024-05-18 21:30:59,462 >> tokenizer config file saved in phi_lora_merged/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2497] 2024-05-18 21:30:59,462 >> Special tokens file saved in phi_lora_merged/special_tokens_map.json\n","README.md: 100% 5.19k/5.19k [00:00<00:00, 24.5MB/s]\n","[INFO|tokenization_utils_base.py:2488] 2024-05-18 21:31:00,282 >> tokenizer config file saved in /tmp/tmpoc4eubqy/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2497] 2024-05-18 21:31:00,282 >> Special tokens file saved in /tmp/tmpoc4eubqy/special_tokens_map.json\n","[INFO|hub.py:757] 2024-05-18 21:31:00,317 >> Uploading the following files to bertilmuth/phi-3-mini-128k-15gen: README.md,special_tokens_map.json,tokenizer.json,tokenizer_config.json,tokenizer.model,added_tokens.json\n","tokenizer.model: 100% 500k/500k [00:02<00:00, 246kB/s] \n","  adding: phi_lora/ (stored 0%)\n","  adding: phi_lora/all_results.json (deflated 38%)\n","  adding: phi_lora/README.md (deflated 47%)\n","  adding: phi_lora/train_results.json (deflated 38%)\n","  adding: phi_lora/runs/ (stored 0%)\n","  adding: phi_lora/runs/May18_18-34-01_0d0c67952c35/ (stored 0%)\n","  adding: phi_lora/runs/May18_18-34-01_0d0c67952c35/events.out.tfevents.1716057283.0d0c67952c35.7829.0 (deflated 69%)\n","  adding: phi_lora/adapter_model.safetensors (deflated 7%)\n","  adding: phi_lora/checkpoint-1000/ (stored 0%)\n","  adding: phi_lora/checkpoint-1000/README.md (deflated 66%)\n","  adding: phi_lora/checkpoint-1000/adapter_model.safetensors (deflated 7%)\n","  adding: phi_lora/checkpoint-1000/rng_state.pth (deflated 25%)\n","  adding: phi_lora/checkpoint-1000/trainer_state.json (deflated 79%)\n","  adding: phi_lora/checkpoint-1000/special_tokens_map.json (deflated 78%)\n","  adding: phi_lora/checkpoint-1000/scheduler.pt (deflated 53%)\n","  adding: phi_lora/checkpoint-1000/tokenizer.json (deflated 74%)\n","  adding: phi_lora/checkpoint-1000/adapter_config.json (deflated 52%)\n","  adding: phi_lora/checkpoint-1000/tokenizer_config.json (deflated 82%)\n","  adding: phi_lora/checkpoint-1000/optimizer.pt (deflated 9%)\n","  adding: phi_lora/checkpoint-1000/training_args.bin (deflated 51%)\n","  adding: phi_lora/checkpoint-1000/tokenizer.model (deflated 55%)\n","  adding: phi_lora/checkpoint-1000/added_tokens.json (deflated 62%)\n","  adding: phi_lora/trainer_state.json (deflated 80%)\n","  adding: phi_lora/trainer_log.jsonl (deflated 83%)\n","  adding: phi_lora/special_tokens_map.json (deflated 78%)\n","  adding: phi_lora/tokenizer.json (deflated 74%)\n","  adding: phi_lora/adapter_config.json (deflated 52%)\n","  adding: phi_lora/checkpoint-2000/ (stored 0%)\n","  adding: phi_lora/checkpoint-2000/README.md (deflated 66%)\n","  adding: phi_lora/checkpoint-2000/adapter_model.safetensors (deflated 7%)\n","  adding: phi_lora/checkpoint-2000/rng_state.pth (deflated 25%)\n","  adding: phi_lora/checkpoint-2000/trainer_state.json (deflated 80%)\n","  adding: phi_lora/checkpoint-2000/special_tokens_map.json (deflated 78%)\n","  adding: phi_lora/checkpoint-2000/scheduler.pt (deflated 53%)\n","  adding: phi_lora/checkpoint-2000/tokenizer.json (deflated 74%)\n","  adding: phi_lora/checkpoint-2000/adapter_config.json (deflated 52%)\n","  adding: phi_lora/checkpoint-2000/tokenizer_config.json (deflated 82%)\n","  adding: phi_lora/checkpoint-2000/optimizer.pt (deflated 9%)\n","  adding: phi_lora/checkpoint-2000/training_args.bin (deflated 51%)\n","  adding: phi_lora/checkpoint-2000/tokenizer.model (deflated 55%)\n","  adding: phi_lora/checkpoint-2000/added_tokens.json (deflated 62%)\n","  adding: phi_lora/tokenizer_config.json (deflated 82%)\n","  adding: phi_lora/training_args.bin (deflated 51%)\n","  adding: phi_lora/tokenizer.model (deflated 55%)\n","  adding: phi_lora/added_tokens.json (deflated 62%)\n"]}],"source":["# Upload the data to Huggingface\n","# IMPORTANT: You need to set HF_WRITE_TOKEN to a write token of Huggingface for this to work!\n","from google.colab import userdata\n","from huggingface_hub import login\n","import json\n","\n","login(token=userdata.get('HF_WRITE_TOKEN'))\n","\n","%cd /content/LLaMA-Factory\n","args = dict(\n","  model_name_or_path=hf_base_model_id,             # the hugging face model id\n","  adapter_name_or_path=adapter_name,            # load the saved LoRA adapters\n","  template=llamafactory_template_name,          # same to the one in training\n","  finetuning_type=\"lora\",                  # same to the one in training\n","  export_dir=saved_merged_model_path,              # the path to save the merged model\n","  export_size=2,                       # the file shard size (in GB) of the merged model\n","  export_device=\"cpu\",                    # the device used in export, can be chosen from `cpu` and `cuda`\n","  export_hub_model_id=hf_finetuned_model_id      # the Hugging Face hub ID to upload model\n",")\n","\n","json.dump(args, open(\"merge_file.json\", \"w\", encoding=\"utf-8\"), indent=2)\n","!llamafactory-cli export merge_file.json\n","\n","# Upload the adapter to Google Drive\n","directory_to_zip = adapter_name  # Change this to your directory\n","zip_output_path = f'{adapter_name}.zip'  # Change this to your desired output zip file name\n","drive_zip_output_path = f'/content/drive/MyDrive/{adapter_name}.zip'  # Change this to your desired location on Google Drive\n","\n","!zip -r $zip_output_path $directory_to_zip\n","!mv $zip_output_path $drive_zip_output_path"]},{"cell_type":"markdown","metadata":{"id":"TaJ8kgJ6SXLL"},"source":["### Infer 100 different SysML v2 models"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["96adc00aa550415cae77310c3b9bf784","e4f59dcb5ddb47e28cdd1eda981845a0","9422709ed26242549598c74064dd73d2","e58ef07bd0684d228f05e4d60998c693","fee4638689094b7aa8bd6cff5c943c67","7fa65913b7c54521a15afe29ff6d61a1","6bba2e20d72b46fbb9b3d2033ef11783","a01519d001104fbbb0dbb80e30f305a7","2f9a9d9b315e4f8fb804b0b1718c74ca","53bb32c5e6284bfab283cdf21f5a9c4a","b31e1d0d5b904f359062aaf73fddc0e7"]},"id":"d0zWn87qSb3R","executionInfo":{"status":"ok","timestamp":1716043419743,"user_tz":-120,"elapsed":8272872,"user":{"displayName":"Bertil Muth","userId":"02558266373806387996"}},"outputId":"17b19b39-15c7-4b38-f83e-7c0d416d87a2"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/LLaMA-Factory\n"]},{"output_type":"stream","name":"stderr","text":["[INFO|tokenization_utils_base.py:2087] 2024-05-18 12:25:47,794 >> loading file tokenizer.model from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-128k-instruct/snapshots/8a362e755d2faf8cec2bf98850ce2216023d178a/tokenizer.model\n","[INFO|tokenization_utils_base.py:2087] 2024-05-18 12:25:47,795 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-128k-instruct/snapshots/8a362e755d2faf8cec2bf98850ce2216023d178a/tokenizer.json\n","[INFO|tokenization_utils_base.py:2087] 2024-05-18 12:25:47,796 >> loading file added_tokens.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-128k-instruct/snapshots/8a362e755d2faf8cec2bf98850ce2216023d178a/added_tokens.json\n","[INFO|tokenization_utils_base.py:2087] 2024-05-18 12:25:47,796 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-128k-instruct/snapshots/8a362e755d2faf8cec2bf98850ce2216023d178a/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2087] 2024-05-18 12:25:47,797 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-128k-instruct/snapshots/8a362e755d2faf8cec2bf98850ce2216023d178a/tokenizer_config.json\n","[WARNING|logging.py:314] 2024-05-18 12:25:47,866 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"output_type":"stream","name":"stdout","text":["05/18/2024 12:25:47 - INFO - llamafactory.data.template - Replace eos token: <|end|>\n"]},{"output_type":"stream","name":"stderr","text":["INFO:llamafactory.data.template:Replace eos token: <|end|>\n"]},{"output_type":"stream","name":"stdout","text":["05/18/2024 12:25:47 - WARNING - llamafactory.data.template - New tokens have been added, make sure `resize_vocab` is True.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:llamafactory.data.template:New tokens have been added, make sure `resize_vocab` is True.\n","[INFO|configuration_utils.py:726] 2024-05-18 12:25:48,141 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-128k-instruct/snapshots/8a362e755d2faf8cec2bf98850ce2216023d178a/config.json\n","[INFO|configuration_utils.py:726] 2024-05-18 12:25:48,676 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-128k-instruct/snapshots/8a362e755d2faf8cec2bf98850ce2216023d178a/config.json\n","[INFO|configuration_utils.py:789] 2024-05-18 12:25:48,679 >> Model config Phi3Config {\n","  \"_name_or_path\": \"microsoft/Phi-3-mini-128k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"microsoft/Phi-3-mini-128k-instruct--configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-128k-instruct--modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 131072,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": {\n","    \"long_factor\": [\n","      1.0299999713897705,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0799999237060547,\n","      1.2299998998641968,\n","      1.2299998998641968,\n","      1.2999999523162842,\n","      1.4499999284744263,\n","      1.5999999046325684,\n","      1.6499998569488525,\n","      1.8999998569488525,\n","      2.859999895095825,\n","      3.68999981880188,\n","      5.419999599456787,\n","      5.489999771118164,\n","      5.489999771118164,\n","      9.09000015258789,\n","      11.579999923706055,\n","      15.65999984741211,\n","      15.769999504089355,\n","      15.789999961853027,\n","      18.360000610351562,\n","      21.989999771118164,\n","      23.079999923706055,\n","      30.009998321533203,\n","      32.35000228881836,\n","      32.590003967285156,\n","      35.56000518798828,\n","      39.95000457763672,\n","      53.840003967285156,\n","      56.20000457763672,\n","      57.95000457763672,\n","      59.29000473022461,\n","      59.77000427246094,\n","      59.920005798339844,\n","      61.190006256103516,\n","      61.96000671386719,\n","      62.50000762939453,\n","      63.3700065612793,\n","      63.48000717163086,\n","      63.48000717163086,\n","      63.66000747680664,\n","      63.850006103515625,\n","      64.08000946044922,\n","      64.760009765625,\n","      64.80001068115234,\n","      64.81001281738281,\n","      64.81001281738281\n","    ],\n","    \"short_factor\": [\n","      1.05,\n","      1.05,\n","      1.05,\n","      1.1,\n","      1.1,\n","      1.1500000000000001,\n","      1.2000000000000002,\n","      1.2500000000000002,\n","      1.3000000000000003,\n","      1.3500000000000003,\n","      1.5000000000000004,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.0500000000000007,\n","      2.0500000000000007,\n","      2.0500000000000007,\n","      2.1000000000000005,\n","      2.1000000000000005,\n","      2.1000000000000005,\n","      2.1500000000000004,\n","      2.1500000000000004,\n","      2.3499999999999996,\n","      2.549999999999999,\n","      2.5999999999999988,\n","      2.5999999999999988,\n","      2.7499999999999982,\n","      2.849999999999998,\n","      2.849999999999998,\n","      2.9499999999999975\n","    ],\n","    \"type\": \"su\"\n","  },\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 262144,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.40.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n"]},{"output_type":"stream","name":"stdout","text":["05/18/2024 12:25:48 - INFO - llamafactory.model.utils.quantization - Quantizing model to 4 bit.\n"]},{"output_type":"stream","name":"stderr","text":["INFO:llamafactory.model.utils.quantization:Quantizing model to 4 bit.\n"]},{"output_type":"stream","name":"stdout","text":["05/18/2024 12:25:48 - INFO - llamafactory.model.patcher - Using KV cache for faster generation.\n"]},{"output_type":"stream","name":"stderr","text":["INFO:llamafactory.model.patcher:Using KV cache for faster generation.\n","WARNING:transformers_modules.microsoft.Phi-3-mini-128k-instruct.8a362e755d2faf8cec2bf98850ce2216023d178a.modeling_phi3:`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n","WARNING:transformers_modules.microsoft.Phi-3-mini-128k-instruct.8a362e755d2faf8cec2bf98850ce2216023d178a.modeling_phi3:Current `flash-attenton` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n","[INFO|modeling_utils.py:3429] 2024-05-18 12:25:48,978 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-128k-instruct/snapshots/8a362e755d2faf8cec2bf98850ce2216023d178a/model.safetensors.index.json\n","[INFO|modeling_utils.py:1494] 2024-05-18 12:25:48,980 >> Instantiating Phi3ForCausalLM model under default dtype torch.bfloat16.\n","[INFO|configuration_utils.py:928] 2024-05-18 12:25:48,982 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 1,\n","  \"eos_token_id\": 32000,\n","  \"pad_token_id\": 32000\n","}\n","\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96adc00aa550415cae77310c3b9bf784"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[INFO|modeling_utils.py:4170] 2024-05-18 12:25:52,400 >> All model checkpoint weights were used when initializing Phi3ForCausalLM.\n","\n","[INFO|modeling_utils.py:4178] 2024-05-18 12:25:52,403 >> All the weights of Phi3ForCausalLM were initialized from the model checkpoint at microsoft/Phi-3-mini-128k-instruct.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use Phi3ForCausalLM for predictions without further training.\n","[INFO|configuration_utils.py:883] 2024-05-18 12:25:52,666 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-128k-instruct/snapshots/8a362e755d2faf8cec2bf98850ce2216023d178a/generation_config.json\n","[INFO|configuration_utils.py:928] 2024-05-18 12:25:52,667 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 1,\n","  \"eos_token_id\": [\n","    32000,\n","    32001,\n","    32007\n","  ],\n","  \"pad_token_id\": 32000\n","}\n","\n"]},{"output_type":"stream","name":"stdout","text":["05/18/2024 12:25:52 - INFO - llamafactory.model.utils.attention - Using vanilla attention implementation.\n"]},{"output_type":"stream","name":"stderr","text":["INFO:llamafactory.model.utils.attention:Using vanilla attention implementation.\n"]},{"output_type":"stream","name":"stdout","text":["05/18/2024 12:25:52 - INFO - llamafactory.model.adapter - Upcasting trainable params to float32.\n"]},{"output_type":"stream","name":"stderr","text":["INFO:llamafactory.model.adapter:Upcasting trainable params to float32.\n"]},{"output_type":"stream","name":"stdout","text":["05/18/2024 12:25:52 - INFO - llamafactory.model.adapter - Fine-tuning method: LoRA\n"]},{"output_type":"stream","name":"stderr","text":["INFO:llamafactory.model.adapter:Fine-tuning method: LoRA\n"]},{"output_type":"stream","name":"stdout","text":["05/18/2024 12:25:53 - INFO - llamafactory.model.adapter - Loaded adapter(s): phi_lora\n"]},{"output_type":"stream","name":"stderr","text":["INFO:llamafactory.model.adapter:Loaded adapter(s): phi_lora\n"]},{"output_type":"stream","name":"stdout","text":["05/18/2024 12:25:53 - INFO - llamafactory.model.loader - all params: 3833662464\n"]},{"output_type":"stream","name":"stderr","text":["INFO:llamafactory.model.loader:all params: 3833662464\n","WARNING:transformers_modules.microsoft.Phi-3-mini-128k-instruct.8a362e755d2faf8cec2bf98850ce2216023d178a.modeling_phi3:You are not running the flash-attention implementation, expect numerical differences.\n"]},{"output_type":"stream","name":"stdout","text":["Created sysml v2 model no. 1\n","Created sysml v2 model no. 2\n","Created sysml v2 model no. 3\n","Created sysml v2 model no. 4\n","Created sysml v2 model no. 5\n","Created sysml v2 model no. 6\n","Created sysml v2 model no. 7\n","Created sysml v2 model no. 8\n","Created sysml v2 model no. 9\n","Created sysml v2 model no. 10\n","Created sysml v2 model no. 11\n","Created sysml v2 model no. 12\n","Created sysml v2 model no. 13\n","Created sysml v2 model no. 14\n","Created sysml v2 model no. 15\n","Created sysml v2 model no. 16\n","Created sysml v2 model no. 17\n","Created sysml v2 model no. 18\n","Created sysml v2 model no. 19\n","Created sysml v2 model no. 20\n","Created sysml v2 model no. 21\n","Created sysml v2 model no. 22\n","Created sysml v2 model no. 23\n","Created sysml v2 model no. 24\n","Created sysml v2 model no. 25\n","Created sysml v2 model no. 26\n","Created sysml v2 model no. 27\n","Created sysml v2 model no. 28\n","Created sysml v2 model no. 29\n","Created sysml v2 model no. 30\n","Created sysml v2 model no. 31\n","Created sysml v2 model no. 32\n","Created sysml v2 model no. 33\n","Created sysml v2 model no. 34\n","Created sysml v2 model no. 35\n","Created sysml v2 model no. 36\n","Created sysml v2 model no. 37\n","Created sysml v2 model no. 38\n","Created sysml v2 model no. 39\n","Created sysml v2 model no. 40\n","Created sysml v2 model no. 41\n","Created sysml v2 model no. 42\n","Created sysml v2 model no. 43\n","Created sysml v2 model no. 44\n","Created sysml v2 model no. 45\n","Created sysml v2 model no. 46\n","Created sysml v2 model no. 47\n","Created sysml v2 model no. 48\n","Created sysml v2 model no. 49\n","Created sysml v2 model no. 50\n","Created sysml v2 model no. 51\n","Created sysml v2 model no. 52\n","Created sysml v2 model no. 53\n","Created sysml v2 model no. 54\n","Created sysml v2 model no. 55\n","Created sysml v2 model no. 56\n","Created sysml v2 model no. 57\n","Created sysml v2 model no. 58\n","Created sysml v2 model no. 59\n","Created sysml v2 model no. 60\n","Created sysml v2 model no. 61\n","Created sysml v2 model no. 62\n","Created sysml v2 model no. 63\n","Created sysml v2 model no. 64\n","Created sysml v2 model no. 65\n","Created sysml v2 model no. 66\n","Created sysml v2 model no. 67\n","Created sysml v2 model no. 68\n","Created sysml v2 model no. 69\n","Created sysml v2 model no. 70\n","Created sysml v2 model no. 71\n","Created sysml v2 model no. 72\n","Created sysml v2 model no. 73\n","Created sysml v2 model no. 74\n","Created sysml v2 model no. 75\n","Created sysml v2 model no. 76\n","Created sysml v2 model no. 77\n","Created sysml v2 model no. 78\n","Created sysml v2 model no. 79\n","Created sysml v2 model no. 80\n","Created sysml v2 model no. 81\n","Created sysml v2 model no. 82\n","Created sysml v2 model no. 83\n","Created sysml v2 model no. 84\n","Created sysml v2 model no. 85\n","Created sysml v2 model no. 86\n","Created sysml v2 model no. 87\n","Created sysml v2 model no. 88\n","Created sysml v2 model no. 89\n","Created sysml v2 model no. 90\n","Created sysml v2 model no. 91\n","Created sysml v2 model no. 92\n","Created sysml v2 model no. 93\n","Created sysml v2 model no. 94\n","Created sysml v2 model no. 95\n","Created sysml v2 model no. 96\n","Created sysml v2 model no. 97\n","Created sysml v2 model no. 98\n","Created sysml v2 model no. 99\n","Created sysml v2 model no. 100\n","Created sysml v2 model no. 101\n","Created sysml v2 model no. 102\n","Created sysml v2 model no. 103\n","Created sysml v2 model no. 104\n","Created sysml v2 model no. 105\n","Created sysml v2 model no. 106\n","Created sysml v2 model no. 107\n","Created sysml v2 model no. 108\n","Created sysml v2 model no. 109\n","Created sysml v2 model no. 110\n","Created sysml v2 model no. 111\n","Created sysml v2 model no. 112\n","  adding: 100systems_sysml/ (stored 0%)\n","  adding: 100systems_sysml/Quantum Key Distribution System.sysml (deflated 77%)\n","  adding: 100systems_sysml/Biodegradable Material Processing System.sysml (deflated 71%)\n","  adding: 100systems_sysml/Drone-based Delivery System.sysml (deflated 73%)\n","  adding: 100systems_sysml/Laser Communication System.sysml (deflated 79%)\n","  adding: 100systems_sysml/Precision Agriculture Decision Support System.sysml (deflated 78%)\n","  adding: 100systems_sysml/Organ-on-a-Chip Testing Platform.sysml (deflated 81%)\n","  adding: 100systems_sysml/Kinetic Energy Recovery System.sysml (deflated 69%)\n","  adding: 100systems_sysml/Journalist's Digital Research Assistant.sysml (deflated 80%)\n","  adding: 100systems_sysml/Automated Tax Compliance System.sysml (deflated 76%)\n","  adding: 100systems_sysml/Nanostructured Material Development Kit.sysml (deflated 76%)\n","  adding: 100systems_sysml/Youth Digital Inclusion Program.sysml (deflated 83%)\n","  adding: 100systems_sysml/X-ray Crystallography Data Analysis Software.sysml (deflated 75%)\n","  adding: 100systems_sysml/Nutrient Recycling System.sysml (deflated 79%)\n","  adding: 100systems_sysml/Blockchain-based Supply Chain Verification.sysml (deflated 72%)\n","  adding: 100systems_sysml/Quantum Computing Simulation System.sysml (deflated 76%)\n","  adding: 100systems_sysml/Space Habitat Life Support System.sysml (deflated 79%)\n","  adding: 100systems_sysml/Ocean Acidification Monitoring System.sysml (deflated 71%)\n","  adding: 100systems_sysml/Facial Recognition Security System.sysml (deflated 76%)\n","  adding: 100systems_sysml/Carbon Capture and Storage System.sysml (deflated 69%)\n","  adding: 100systems_sysml/Xenobiotic Detection System.sysml (deflated 72%)\n","  adding: 100systems_sysml/Invasive Species Management Tool.sysml (deflated 72%)\n","  adding: 100systems_sysml/Waste-to-Energy Conversion System.sysml (deflated 77%)\n","  adding: 100systems_sysml/Genomic Data Analysis System.sysml (deflated 76%)\n","  adding: 100systems_sysml/Microbial Fuel Cell System.sysml (deflated 75%)\n","  adding: 100systems_sysml/Quantum Annealing Solver.sysml (deflated 72%)\n","  adding: 100systems_sysml/Telehealth Service Platform.sysml (deflated 74%)\n","  adding: 100systems_sysml/Environmental Impact Assessment Tool.sysml (deflated 78%)\n","  adding: 100systems_sysml/Municipal Waste Sorting System.sysml (deflated 72%)\n","  adding: 100systems_sysml/Wearable Translator Device.sysml (deflated 78%)\n","  adding: 100systems_sysml/Graphene Production Facility.sysml (deflated 74%)\n","  adding: 100systems_sysml/Smart Grid Control System.sysml (deflated 79%)\n","  adding: 100systems_sysml/Remote Sensing Satellite System.sysml (deflated 70%)\n","  adding: 100systems_sysml/Green Building Management System.sysml (deflated 77%)\n","  adding: 100systems_sysml/Wildlife Monitoring System.sysml (deflated 75%)\n","  adding: 100systems_sysml/Fog Computing Network.sysml (deflated 72%)\n","  adding: 100systems_sysml/Offshore Aquaculture System.sysml (deflated 75%)\n","  adding: 100systems_sysml/Therapeutic Virtual Reality Environment.sysml (deflated 75%)\n","  adding: 100systems_sysml/Industrial Internet of Things Platform.sysml (deflated 77%)\n","  adding: 100systems_sysml/Ocean Current Energy Conversion System.sysml (deflated 76%)\n","  adding: 100systems_sysml/Space Junk Tracking System.sysml (deflated 77%)\n","  adding: 100systems_sysml/Smart Contract Audit Platform.sysml (deflated 76%)\n","  adding: 100systems_sysml/High-Altitude Pseudo-Satellite System.sysml (deflated 75%)\n","  adding: 100systems_sysml/Underwater Communication System.sysml (deflated 79%)\n","  adding: 100systems_sysml/Wearable Health Monitoring System.sysml (deflated 75%)\n","  adding: 100systems_sysml/Augmented Reality Shopping Assistant.sysml (deflated 79%)\n","  adding: 100systems_sysml/Zero-Emission Vehicle Charging Network.sysml (deflated 77%)\n","  adding: 100systems_sysml/Youth Mental Health Service Platform.sysml (deflated 78%)\n","  adding: 100systems_sysml/Liquid Metal Battery System.sysml (deflated 73%)\n","  adding: 100systems_sysml/Quantum Dot Display Manufacturing System.sysml (deflated 72%)\n","  adding: 100systems_sysml/Pervasive Computing System.sysml (deflated 76%)\n","  adding: 100systems_sysml/Urban Traffic Control System.sysml (deflated 75%)\n","  adding: 100systems_sysml/Thermal Energy Storage System.sysml (deflated 75%)\n","  adding: 100systems_sysml/Automated Legal Reasoning System.sysml (deflated 76%)\n","  adding: 100systems_sysml/Extended Reality Collaboration Platform.sysml (deflated 77%)\n","  adding: 100systems_sysml/Zero-Trust Network Architecture.sysml (deflated 77%)\n","  adding: 100systems_sysml/Knowledge Discovery in Databases System.sysml (deflated 85%)\n","  adding: 100systems_sysml/Rapid Prototyping Machine.sysml (deflated 73%)\n","  adding: 100systems_sysml/Neural Network Training Platform.sysml (deflated 75%)\n","  adding: 100systems_sysml/Zettabyte File System.sysml (deflated 77%)\n","  adding: 100systems_sysml/Crowdsourced Weather Prediction Platform.sysml (deflated 78%)\n","  adding: 100systems_sysml/Molecular Manufacturing System.sysml (deflated 73%)\n","  adding: 100systems_sysml/Self-Healing Material System.sysml (deflated 69%)\n","  adding: 100systems_sysml/Plasma Waste Recycling System.sysml (deflated 72%)\n","  adding: 100systems_sysml/Knowledge Graph-Based Recommendation System.sysml (deflated 74%)\n","  adding: 100systems_sysml/Intelligent Transportation Coordination System.sysml (deflated 77%)\n","  adding: 100systems_sysml/Vaccine Research and Development Platform.sysml (deflated 80%)\n","  adding: 100systems_sysml/Renewable Energy Microgrid.sysml (deflated 76%)\n","  adding: 100systems_sysml/Nano-Medicine Delivery System.sysml (deflated 78%)\n","  adding: 100systems_sysml/Automated Contract Enforcement System.sysml (deflated 76%)\n","  adding: 100systems_sysml/Quantum Sensor Network.sysml (deflated 75%)\n","  adding: 100systems_sysml/Blockchain-based Voting System.sysml (deflated 73%)\n","  adding: 100systems_sysml/Tidal Power Generation System.sysml (deflated 72%)\n","  adding: 100systems_sysml/Youth Entrepreneurship Support Platform.sysml (deflated 79%)\n","  adding: 100systems_sysml/Fusion Energy Control System.sysml (deflated 77%)\n","  adding: 100systems_sysml/Deep Sea Exploration System.sysml (deflated 76%)\n","  adding: 100systems_sysml/Jail Management System.sysml (deflated 77%)\n","  adding: 100systems_sysml/Low Earth Orbit Satellite Internet System.sysml (deflated 74%)\n","  adding: 100systems_sysml/Hyperloop Transport System.sysml (deflated 73%)\n","  adding: 100systems_sysml/Language Learning Companion Bot.sysml (deflated 79%)\n","  adding: 100systems_sysml/High Efficiency Photovoltaic System.sysml (deflated 75%)\n","  adding: 100systems_sysml/Exascale Computing System.sysml (deflated 76%)\n","  adding: 100systems_sysml/Exoplanet Discovery System.sysml (deflated 77%)\n","  adding: 100systems_sysml/Zero-Knowledge Proof System.sysml (deflated 74%)\n","  adding: 100systems_sysml/Cryptographic Currency Exchange.sysml (deflated 74%)\n","  adding: 100systems_sysml/Urban Air Mobility System.sysml (deflated 75%)\n","  adding: 100systems_sysml/Wind Farm Optimization System.sysml (deflated 76%)\n","  adding: 100systems_sysml/Biometric Authentication System.sysml (deflated 81%)\n","  adding: 100systems_sysml/Multiphysics Simulation Software.sysml (deflated 75%)\n","  adding: 100systems_sysml/Vertical Farming Climate Control System.sysml (deflated 80%)\n","  adding: 100systems_sysml/Smart Agriculture System.sysml (deflated 80%)\n","  adding: 100systems_sysml/Resilient Infrastructure Design Software.sysml (deflated 79%)\n","  adding: 100systems_sysml/Fintech Blockchain Platform.sysml (deflated 74%)\n","  adding: 100systems_sysml/Junk Data Cleanup Software.sysml (deflated 75%)\n","  adding: 100systems_sysml/Digital Twin for Industrial Automation.sysml (deflated 75%)\n","  adding: 100systems_sysml/Cognitive Behavioral Therapy Application.sysml (deflated 79%)\n","  adding: 100systems_sysml/Kinematic Analysis Software.sysml (deflated 74%)\n","  adding: 100systems_sysml/Underground Transportation System.sysml (deflated 72%)\n","  adding: 100systems_sysml/Haptic Feedback Virtual Reality System.sysml (deflated 73%)\n","  adding: 100systems_sysml/Intelligent Drug Discovery System.sysml (deflated 80%)\n","  adding: 100systems_sysml/Unmanned Combat Aerial Vehicle System.sysml (deflated 76%)\n","  adding: 100systems_sysml/Voice-Activated Home Assistant.sysml (deflated 74%)\n","  adding: 100systems_sysml/Journalistic Integrity Verification System.sysml (deflated 73%)\n","  adding: 100systems_sysml/Volumetric 3D Printing System.sysml (deflated 73%)\n","  adding: 100systems_sysml/Personalized Learning Environment.sysml (deflated 72%)\n","  adding: 100systems_sysml/Elderly Care Robotic System.sysml (deflated 81%)\n","  adding: 100systems_sysml/Gene Editing CRISPR Control System.sysml (deflated 70%)\n","  adding: 100systems_sysml/Distributed Cloud Storage System.sysml (deflated 76%)\n","  adding: 100systems_sysml/Synthetic Biology Engineering Platform.sysml (deflated 80%)\n","  adding: 100systems_sysml/Distributed Autonomous Organization Management.sysml (deflated 78%)\n","  adding: 100systems_sysml/Youth Sports Management Platform.sysml (deflated 80%)\n","  adding: 100systems_sysml/Ultra-High Definition Holographic Display.sysml (deflated 75%)\n","  adding: 100systems_sysml/Emergency Response Coordination System.sysml (deflated 70%)\n"]}],"source":["import os\n","from llamafactory.chat import ChatModel\n","from llamafactory.extras.misc import torch_gc\n","\n","# Change directory to where LLaMA-Factory is located\n","%cd /content/LLaMA-Factory/\n","\n","technical_systems = [\n","    \"Underwater Communication System\",\n","    \"Smart Grid Control System\",\n","    \"Quantum Key Distribution System\",\n","    \"Space Habitat Life Support System\",\n","    \"Deep Sea Exploration System\",\n","    \"Smart Agriculture System\",\n","    \"Urban Traffic Control System\",\n","    \"Wildlife Monitoring System\",\n","    \"Automated Legal Reasoning System\",\n","    \"Blockchain-based Voting System\",\n","    \"Cryptographic Currency Exchange\",\n","    \"Distributed Cloud Storage System\",\n","    \"Elderly Care Robotic System\",\n","    \"Facial Recognition Security System\",\n","    \"Gene Editing CRISPR Control System\",\n","    \"Haptic Feedback Virtual Reality System\",\n","    \"Intelligent Transportation Coordination System\",\n","    \"Jail Management System\",\n","    \"Kinetic Energy Recovery System\",\n","    \"Laser Communication System\",\n","    \"Municipal Waste Sorting System\",\n","    \"Nano-Medicine Delivery System\",\n","    \"Ocean Current Energy Conversion System\",\n","    \"Pervasive Computing System\",\n","    \"Quantum Computing Simulation System\",\n","    \"Remote Sensing Satellite System\",\n","    \"Synthetic Biology Engineering Platform\",\n","    \"Thermal Energy Storage System\",\n","    \"Unmanned Combat Aerial Vehicle System\",\n","    \"Volumetric 3D Printing System\",\n","    \"Wearable Health Monitoring System\",\n","    \"Exoplanet Discovery System\",\n","    \"Youth Sports Management Platform\",\n","    \"Zero-Emission Vehicle Charging Network\",\n","    \"Automated Tax Compliance System\",\n","    \"Biometric Authentication System\",\n","    \"Crowdsourced Weather Prediction Platform\",\n","    \"Drone-based Delivery System\",\n","    \"Emergency Response Coordination System\",\n","    \"Fintech Blockchain Platform\",\n","    \"Green Building Management System\",\n","    \"High-Altitude Pseudo-Satellite System\",\n","    \"Intelligent Drug Discovery System\",\n","    \"Junk Data Cleanup Software\",\n","    \"Knowledge Discovery in Databases System\",\n","    \"Low Earth Orbit Satellite Internet System\",\n","    \"Molecular Manufacturing System\",\n","    \"Neural Network Training Platform\",\n","    \"Ocean Acidification Monitoring System\",\n","    \"Precision Agriculture Decision Support System\",\n","    \"Quantum Sensor Network\",\n","    \"Renewable Energy Microgrid\",\n","    \"Space Junk Tracking System\",\n","    \"Telehealth Service Platform\",\n","    \"Underground Transportation System\",\n","    \"Vaccine Research and Development Platform\",\n","    \"Wind Farm Optimization System\",\n","    \"Xenobiotic Detection System\",\n","    \"Youth Mental Health Service Platform\",\n","    \"Zero-Knowledge Proof System\",\n","    \"Automated Contract Enforcement System\",\n","    \"Biodegradable Material Processing System\",\n","    \"Carbon Capture and Storage System\",\n","    \"Digital Twin for Industrial Automation\",\n","    \"Exascale Computing System\",\n","    \"Fusion Energy Control System\",\n","    \"Genomic Data Analysis System\",\n","    \"Hyperloop Transport System\",\n","    \"Industrial Internet of Things Platform\",\n","    \"Journalist's Digital Research Assistant\",\n","    \"Knowledge Graph-Based Recommendation System\",\n","    \"Liquid Metal Battery System\",\n","    \"Microbial Fuel Cell System\",\n","    \"Nanostructured Material Development Kit\",\n","    \"Offshore Aquaculture System\",\n","    \"Personalized Learning Environment\",\n","    \"Quantum Dot Display Manufacturing System\",\n","    \"Rapid Prototyping Machine\",\n","    \"Self-Healing Material System\",\n","    \"Tidal Power Generation System\",\n","    \"Urban Air Mobility System\",\n","    \"Vertical Farming Climate Control System\",\n","    \"Wearable Translator Device\",\n","    \"Extended Reality Collaboration Platform\",\n","    \"Youth Digital Inclusion Program\",\n","    \"Zettabyte File System\",\n","    \"Augmented Reality Shopping Assistant\",\n","    \"Blockchain-based Supply Chain Verification\",\n","    \"Cognitive Behavioral Therapy Application\",\n","    \"Distributed Autonomous Organization Management\",\n","    \"Environmental Impact Assessment Tool\",\n","    \"Fog Computing Network\",\n","    \"Graphene Production Facility\",\n","    \"High Efficiency Photovoltaic System\",\n","    \"Invasive Species Management Tool\",\n","    \"Journalistic Integrity Verification System\",\n","    \"Kinematic Analysis Software\",\n","    \"Language Learning Companion Bot\",\n","    \"Multiphysics Simulation Software\",\n","    \"Nutrient Recycling System\",\n","    \"Organ-on-a-Chip Testing Platform\",\n","    \"Plasma Waste Recycling System\",\n","    \"Quantum Annealing Solver\",\n","    \"Resilient Infrastructure Design Software\",\n","    \"Smart Contract Audit Platform\",\n","    \"Therapeutic Virtual Reality Environment\",\n","    \"Ultra-High Definition Holographic Display\",\n","    \"Voice-Activated Home Assistant\",\n","    \"Waste-to-Energy Conversion System\",\n","    \"X-ray Crystallography Data Analysis Software\",\n","    \"Youth Entrepreneurship Support Platform\",\n","    \"Zero-Trust Network Architecture\"\n","]\n","\n","# Setup chat model arguments\n","args = dict(\n","  model_name_or_path=hf_base_model_id,\n","  adapter_name_or_path=adapter_name,      # load the saved LoRA adapters\n","  template=llamafactory_template_name,                     # same to the one in training\n","  finetuning_type=\"lora\",                  # same to the one in training\n","  quantization_bit=4,                    # load 4-bit quantized model\n","  use_unsloth=False,                     # don't use UnslothAI's LoRA optimization for 2x faster generation\n",")\n","\n","# Initialize the chat model\n","chat_model = ChatModel(args)\n","\n","# Ensure the sysml_files directory exists\n","output_dir = '100systems_sysml'\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# Iterate over the technical system names\n","n = 0\n","for technical_system in technical_systems:\n","    query = \"Create a model for \" + technical_system\n","    messages = [{\"role\": \"user\", \"content\": query}]\n","\n","    response = \"\"\n","    for new_text in chat_model.stream_chat(messages):\n","        response += new_text\n","\n","    # Write the response to a file\n","    file_path = os.path.join(output_dir, f\"{technical_system}.sysml\")\n","    with open(file_path, 'w') as file:\n","        file.write(response)\n","    n+=1\n","    print(\"Created sysml v2 model no. \" + str(n) )\n","\n","# Free up memory\n","torch_gc()\n","\n","# Upload to Google Drive\n","directory_to_zip = output_dir  # Change this to your directory\n","zip_output_path = f'{output_dir}.zip'  # Change this to your desired output zip file name\n","drive_zip_output_path = f'/content/drive/MyDrive/{output_dir}.zip'  # Change this to your desired location on Google Drive\n","\n","!zip -r $zip_output_path $directory_to_zip\n","!mv $zip_output_path $drive_zip_output_path\n"]},{"cell_type":"markdown","metadata":{"id":"_X3mSfPfHQID"},"source":["### Infer 100 system models (AUTOSAR)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"A8dWgXmCKhre","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["0207d5fc3ad24f3a8cc7cb3e8ebaa26b","dc56a71045804460b3b49e89e1bc532e","a803702be854418580a4c34fbbb9e1b7","c5c228e3c56f4803babd7c7636036e8a","c9ae949b5c06423e99b2acf286393f62","7410cccaaace475d9e0dc82df19f22c5","952c0c6da3a346f38ea8140a6cb3ed54","443fc6d119f749f7bd7dae9a47966932","4681a692486c4f028c2c73b1c7850e59","dd05256385894add821bc9944fee5a15","c78aaeebdf6841a28c6b4601fb98104a","8e26631564d24eb2bdcacbcd063e9259","87dc5964e77c4b4cb13e5fe7eae827f7","a9644e4b97a94e1b9f653aec3cadcb00","d04f060e2d334d5dbe827c7382d8cb91","c6a9661d91b4405088c11939ad795141","4f2a62a1ca54422ba99fea2c4a7e485f","93fa013e029349cca413228956014538","dff0bab3c975434eaee597389c7bdf9d","e5be63eff40a4c2a895ebdafa0d5ad2f","cb4c593a415e4d009aa40384d9fed590","5cf2b2e82426426cb917fe0d66d4634f","fd8d5d48bc4a48a5bc5b2f505b6b0e27","a77bce5dcd7c4989b2a536d9e70152a9","0ab3c85a6fb34ca5918b4d2b5d8b35f5","86e3366ee44b4cd294c96811956d0bfa","feb29218c8dc412c93658b1c5efa7a47","f196523c4ce744d2b3d5319183203fab","25304884db0d40f6a4e677ef359d3571","907893332b424d41a0a2d03517313bc5","b93215dea5254c61a7c60dacf763d2cf","9889d1346da4461a9ce07362751e577d","c0c6eb27550040bd8a7e7adbcd6fac9d","887d160bd7254e73a6889fe6b37f879b","c75380750e3d475aa7bcb34d726cb0bd","a63190853c514fd7abf9232bff7fcfcf","778b0e604e824cceaab515fcc7711b0f","a9264344d8824176a1833e71fcd69520","097539c0882945ee813d84bfe98d0740","da4a797a8e2546c4a5a51caf5c8dcb9e","0af74fad1aa74185a8b928a23efb9b74","187c04d1871743aebf13679d33505dd8","5a2025cbf58046d4b1c9c39ef0e447d4","a8ef4761394f4103b39392f7ab627ad0","d95b5fad9b2c45299d72134f1d139c21","05cb2d9b691a4220a4b96bd08ee17c36","1c7e75f57f2e45f8a86ae04cc551ae62","d5faf580a5da403d87306d96933c3dc8","6f545b255abb4302b60e62f56c97fc69","c4ce26ccf0a7496cba61600c9aa32e0e","2f957a5772ac4df893a9cf6fe42ef456","38dcd3df26e64da6a3f59483ec6cffa5","b0511e146b9e42d883b70123602a8654","ca48d622d46447e69ebe9d52085d5765","07f61d1d9d5f47f1804cfa2eacf89a68","b1579a828796407da8582ec720fa3939","bbc1dc9012a74fcb892db67a030170d6","6225843db029435f9dccb7dd66c2a5d3","66f9b6baa5214b41ba4fd5969d95adf9","f0005c30f71e49aa8c83e5e574bdf6da","fea2cd38284446c6abe9166945c3ce64","1b132896fdd0463598ee224a47959334","53029bf98a954c9dbe5dd790a49eb40d","7dcc05d7c42c47649c2c5404bf62921a","ec1aaccb96e94a80bd31ed543fabfc31","e991b0d63aec44fbbf45004128ced8fc","99358e03481541d197192ace60d35189","81d19356ac8346dc818db873e04876f8","058699baa6de45388ea3f703d73e6e09","81a524827e0248e1b590e187aec62e31","0bcc860db2104f8696aa6895697ed68f","23f42ddd1a6b4e889449d5fcffd85712","b59f1f28047c4d43a79f9c2e804d7455","e3f2f13b0d9b41d0bba3efb759f66e27","e910824672174ba2ab17649606f6b5b1","42128f01b1d34fb9aa10abe80c07578e","0f846bd1de85422da9d03dc51e705024","480624461726450a9f8aeddcd78a08ec","0c4445b9980941fbaac2a2cf72dde61a","5203d6a2ee754bf8857c19aca7158bcb","83b694de2f3d4cb38a7190eabf4a2460","e041589aba7f42158e00f679c72cb86d","b3284eb5b40e405ab03f411e8f2033d4","67a35e0030074f048e5732539a7abfe1","a1299f0a13374a5c9f836cab0aeb9acf","911a92ca9ffb4dc5b62d74ed99931dd5","b9774283f1af4cd29705f0065e65a69f","93417fc686d3415dadb1772eed1d2ebb","ed798f6f9c214c11942ba710617b7f2d","1e4b29f968fd4f3e9d70b10d34a72da1","605653da174f4a9e8fbc631d33125d96","e1ca5d455aed48f7be61f936cca9e1a0","9bc0bb034ee54dfc87685e839526117f","49b725afaf414c7ba7ea577cbfec8c66","291a67c25e8545d8bea439c7cf71d22d","1a49e4e8e23e446a835634f7556d0830","77ce231234954ec9a751aaf88b183861","7fec79233f2e4749a4f2d5b50c052111","b54d1e8773a54ab18fce7bbf30e55e62","b9fb8dd57c0f417a9f6387984875140e","b73f67bf29084cc28911da2c7aa181e1","e265b9e8ac7246f68bb74fee63fea4c5","e013b20891e34ac487b4853bcc351354","c7ba26c4bac34d4eb4c9d6c86555ee15","c103a2f453094fec95d5492024e946c5","9311d116f756470ca6b3a58865825f25","53f2b740397141b8818c2981dc7766f1","9944c46db62248bdb46b93a112bce6f5","dae4faabe24f42afb9f518098f9cfdf6","654b7a1d800e4a7a8b497c34a49dc52c","c2fb26185a774b40814cfc849584d238","c9c96e9e10364c6b97c1637718ab571d","49c772ed77f7462cae1f10610855f907","00d5ee01c9bc47bea312b1efc62892d1","78f4cf80e87b428d9effb3ab196717ac","516067b4e9ba43249b4335e34f5af68c","a64fe86450ae4fb98c74f7d91cd56a08","1c3a9112df214c9db789ebc8a844be91","523d8f6bd7054d02a6ed84d68505239e","93fbf21cd88b47b080a4820d2f70f0c4","d1d62c94007a4ffeb1483187122018e4","71d612d7d6794bb0a45ce8527654d90a","b64fb738bdb34279b2d2b28bb38572c5","27fe4ff30c5c43649154a068d793a7af","0d579079d61d438b9779d72ee76c92a9","4e7f7da7b87944228e2e90ad51c07343","3c77547a61e049d7a64abde568bf7cd7","6f3bfc2b572b4587a5495a3ea68382a3","f122d59c6e584eb2b0d89b5ed5d29a9a","7cbac3ac744748a59d5be9e85ba038d0","c71fc6cc569d4e40a7400bbf970dbcb8","9888c9692509477fb78c3f469232ce2a","fd546efa13914c97b04a4b4fcd5ac61c","470f88decf974202aff27d40e5ca52aa","b1ed954fcb2b4eeb863cdcc034092eab","99e9cff4cbe04cf490c2ad1d560ed933","7d6a58c273c54aeca2d518ddeaa5aa0e","69817fc241d44f33b8d8f87539c446e8","3bc732a24752461388d7b97c840d3e89","f1a7e0d1eff249d2bef844e1e36b6210","a49f4f5989b84410b19a21e384c15346","1868b39e5dd34473a8d75073150c89da","14efac5d1dad49e7812b1ebef1902661","0550dd01c73d4c9783e58b5b15141f62","969b098c91104f3eaa0c21e3d3338b9c","088d91ad0e5e42c090a0111d5f9e2489","b0bd14a5f8274b449f0f58721d21206f","acc3d38501dc4accb7530e6f89399cf1","f085978923cc401db514376da523e361","42933890ee59493a97a4f14d6a4aaee3","b899b5faba044b18b15927f45279a6f7","d8d7d0cada6f41aa9cdfc261826dda65","bedef9aa1315443293789ecadf7fd7e8","1d6f3c5e3fc6433780cf5344f3bf5d10"]},"executionInfo":{"status":"ok","timestamp":1716076434139,"user_tz":-120,"elapsed":7702872,"user":{"displayName":"Bertil Muth","userId":"02558266373806387996"}},"outputId":"c69fbcfe-9d6d-4de4-a28c-d3f82d84957b"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/3.17k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0207d5fc3ad24f3a8cc7cb3e8ebaa26b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e26631564d24eb2bdcacbcd063e9259"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd8d5d48bc4a48a5bc5b2f505b6b0e27"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["added_tokens.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"887d160bd7254e73a6889fe6b37f879b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/568 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d95b5fad9b2c45299d72134f1d139c21"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[INFO|tokenization_utils_base.py:2087] 2024-05-18 21:45:46,720 >> loading file tokenizer.model from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-128k-instruct/snapshots/8a362e755d2faf8cec2bf98850ce2216023d178a/tokenizer.model\n","[INFO|tokenization_utils_base.py:2087] 2024-05-18 21:45:46,721 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-128k-instruct/snapshots/8a362e755d2faf8cec2bf98850ce2216023d178a/tokenizer.json\n","[INFO|tokenization_utils_base.py:2087] 2024-05-18 21:45:46,722 >> loading file added_tokens.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-128k-instruct/snapshots/8a362e755d2faf8cec2bf98850ce2216023d178a/added_tokens.json\n","[INFO|tokenization_utils_base.py:2087] 2024-05-18 21:45:46,725 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-128k-instruct/snapshots/8a362e755d2faf8cec2bf98850ce2216023d178a/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2087] 2024-05-18 21:45:46,726 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-128k-instruct/snapshots/8a362e755d2faf8cec2bf98850ce2216023d178a/tokenizer_config.json\n","[WARNING|logging.py:314] 2024-05-18 21:45:46,809 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"output_type":"stream","name":"stdout","text":["05/18/2024 21:45:46 - INFO - llamafactory.data.template - Replace eos token: <|end|>\n"]},{"output_type":"stream","name":"stderr","text":["INFO:llamafactory.data.template:Replace eos token: <|end|>\n"]},{"output_type":"stream","name":"stdout","text":["05/18/2024 21:45:46 - WARNING - llamafactory.data.template - New tokens have been added, make sure `resize_vocab` is True.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:llamafactory.data.template:New tokens have been added, make sure `resize_vocab` is True.\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/3.35k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1579a828796407da8582ec720fa3939"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[INFO|configuration_utils.py:726] 2024-05-18 21:45:47,042 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-128k-instruct/snapshots/8a362e755d2faf8cec2bf98850ce2216023d178a/config.json\n"]},{"output_type":"display_data","data":{"text/plain":["configuration_phi3.py:   0%|          | 0.00/10.4k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99358e03481541d197192ace60d35189"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[INFO|configuration_utils.py:726] 2024-05-18 21:45:47,385 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-128k-instruct/snapshots/8a362e755d2faf8cec2bf98850ce2216023d178a/config.json\n","[INFO|configuration_utils.py:789] 2024-05-18 21:45:47,387 >> Model config Phi3Config {\n","  \"_name_or_path\": \"microsoft/Phi-3-mini-128k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"microsoft/Phi-3-mini-128k-instruct--configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-128k-instruct--modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 131072,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": {\n","    \"long_factor\": [\n","      1.0299999713897705,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0799999237060547,\n","      1.2299998998641968,\n","      1.2299998998641968,\n","      1.2999999523162842,\n","      1.4499999284744263,\n","      1.5999999046325684,\n","      1.6499998569488525,\n","      1.8999998569488525,\n","      2.859999895095825,\n","      3.68999981880188,\n","      5.419999599456787,\n","      5.489999771118164,\n","      5.489999771118164,\n","      9.09000015258789,\n","      11.579999923706055,\n","      15.65999984741211,\n","      15.769999504089355,\n","      15.789999961853027,\n","      18.360000610351562,\n","      21.989999771118164,\n","      23.079999923706055,\n","      30.009998321533203,\n","      32.35000228881836,\n","      32.590003967285156,\n","      35.56000518798828,\n","      39.95000457763672,\n","      53.840003967285156,\n","      56.20000457763672,\n","      57.95000457763672,\n","      59.29000473022461,\n","      59.77000427246094,\n","      59.920005798339844,\n","      61.190006256103516,\n","      61.96000671386719,\n","      62.50000762939453,\n","      63.3700065612793,\n","      63.48000717163086,\n","      63.48000717163086,\n","      63.66000747680664,\n","      63.850006103515625,\n","      64.08000946044922,\n","      64.760009765625,\n","      64.80001068115234,\n","      64.81001281738281,\n","      64.81001281738281\n","    ],\n","    \"short_factor\": [\n","      1.05,\n","      1.05,\n","      1.05,\n","      1.1,\n","      1.1,\n","      1.1500000000000001,\n","      1.2000000000000002,\n","      1.2500000000000002,\n","      1.3000000000000003,\n","      1.3500000000000003,\n","      1.5000000000000004,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.000000000000001,\n","      2.0500000000000007,\n","      2.0500000000000007,\n","      2.0500000000000007,\n","      2.1000000000000005,\n","      2.1000000000000005,\n","      2.1000000000000005,\n","      2.1500000000000004,\n","      2.1500000000000004,\n","      2.3499999999999996,\n","      2.549999999999999,\n","      2.5999999999999988,\n","      2.5999999999999988,\n","      2.7499999999999982,\n","      2.849999999999998,\n","      2.849999999999998,\n","      2.9499999999999975\n","    ],\n","    \"type\": \"su\"\n","  },\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 262144,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.40.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n"]},{"output_type":"stream","name":"stdout","text":["05/18/2024 21:45:47 - INFO - llamafactory.model.utils.quantization - Quantizing model to 4 bit.\n"]},{"output_type":"stream","name":"stderr","text":["INFO:llamafactory.model.utils.quantization:Quantizing model to 4 bit.\n"]},{"output_type":"stream","name":"stdout","text":["05/18/2024 21:45:47 - INFO - llamafactory.model.patcher - Using KV cache for faster generation.\n"]},{"output_type":"stream","name":"stderr","text":["INFO:llamafactory.model.patcher:Using KV cache for faster generation.\n"]},{"output_type":"display_data","data":{"text/plain":["modeling_phi3.py:   0%|          | 0.00/73.8k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"480624461726450a9f8aeddcd78a08ec"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:transformers_modules.microsoft.Phi-3-mini-128k-instruct.8a362e755d2faf8cec2bf98850ce2216023d178a.modeling_phi3:`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n","WARNING:transformers_modules.microsoft.Phi-3-mini-128k-instruct.8a362e755d2faf8cec2bf98850ce2216023d178a.modeling_phi3:Current `flash-attenton` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors.index.json:   0%|          | 0.00/16.3k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed798f6f9c214c11942ba710617b7f2d"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[INFO|modeling_utils.py:3429] 2024-05-18 21:45:48,273 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-128k-instruct/snapshots/8a362e755d2faf8cec2bf98850ce2216023d178a/model.safetensors.index.json\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9fb8dd57c0f417a9f6387984875140e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2fb26185a774b40814cfc849584d238"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71d612d7d6794bb0a45ce8527654d90a"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[INFO|modeling_utils.py:1494] 2024-05-18 21:46:17,395 >> Instantiating Phi3ForCausalLM model under default dtype torch.float16.\n","[INFO|configuration_utils.py:928] 2024-05-18 21:46:17,398 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 1,\n","  \"eos_token_id\": 32000,\n","  \"pad_token_id\": 32000\n","}\n","\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd546efa13914c97b04a4b4fcd5ac61c"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[INFO|modeling_utils.py:4170] 2024-05-18 21:46:23,905 >> All model checkpoint weights were used when initializing Phi3ForCausalLM.\n","\n","[INFO|modeling_utils.py:4178] 2024-05-18 21:46:23,907 >> All the weights of Phi3ForCausalLM were initialized from the model checkpoint at microsoft/Phi-3-mini-128k-instruct.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use Phi3ForCausalLM for predictions without further training.\n"]},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/172 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0550dd01c73d4c9783e58b5b15141f62"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[INFO|configuration_utils.py:883] 2024-05-18 21:46:24,132 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-128k-instruct/snapshots/8a362e755d2faf8cec2bf98850ce2216023d178a/generation_config.json\n","[INFO|configuration_utils.py:928] 2024-05-18 21:46:24,134 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 1,\n","  \"eos_token_id\": [\n","    32000,\n","    32001,\n","    32007\n","  ],\n","  \"pad_token_id\": 32000\n","}\n","\n"]},{"output_type":"stream","name":"stdout","text":["05/18/2024 21:46:24 - INFO - llamafactory.model.utils.attention - Using vanilla attention implementation.\n"]},{"output_type":"stream","name":"stderr","text":["INFO:llamafactory.model.utils.attention:Using vanilla attention implementation.\n"]},{"output_type":"stream","name":"stdout","text":["05/18/2024 21:46:24 - INFO - llamafactory.model.adapter - Upcasting trainable params to float32.\n"]},{"output_type":"stream","name":"stderr","text":["INFO:llamafactory.model.adapter:Upcasting trainable params to float32.\n"]},{"output_type":"stream","name":"stdout","text":["05/18/2024 21:46:24 - INFO - llamafactory.model.adapter - Fine-tuning method: LoRA\n"]},{"output_type":"stream","name":"stderr","text":["INFO:llamafactory.model.adapter:Fine-tuning method: LoRA\n"]},{"output_type":"stream","name":"stdout","text":["05/18/2024 21:46:24 - INFO - llamafactory.model.adapter - Loaded adapter(s): phi_lora\n"]},{"output_type":"stream","name":"stderr","text":["INFO:llamafactory.model.adapter:Loaded adapter(s): phi_lora\n"]},{"output_type":"stream","name":"stdout","text":["05/18/2024 21:46:24 - INFO - llamafactory.model.loader - all params: 3833662464\n"]},{"output_type":"stream","name":"stderr","text":["INFO:llamafactory.model.loader:all params: 3833662464\n","WARNING:transformers_modules.microsoft.Phi-3-mini-128k-instruct.8a362e755d2faf8cec2bf98850ce2216023d178a.modeling_phi3:You are not running the flash-attention implementation, expect numerical differences.\n"]},{"output_type":"stream","name":"stdout","text":["Created sysml v2 model no. 0\n","Created sysml v2 model no. 1\n","Created sysml v2 model no. 2\n","Created sysml v2 model no. 3\n","Created sysml v2 model no. 4\n","Created sysml v2 model no. 5\n","Created sysml v2 model no. 6\n","Created sysml v2 model no. 7\n","Created sysml v2 model no. 8\n","Created sysml v2 model no. 9\n","Created sysml v2 model no. 10\n","Created sysml v2 model no. 11\n","Created sysml v2 model no. 12\n","Created sysml v2 model no. 13\n","Created sysml v2 model no. 14\n","Created sysml v2 model no. 15\n","Created sysml v2 model no. 16\n","Created sysml v2 model no. 17\n","Created sysml v2 model no. 18\n","Created sysml v2 model no. 19\n","Created sysml v2 model no. 20\n","Created sysml v2 model no. 21\n","Created sysml v2 model no. 22\n","Created sysml v2 model no. 23\n","Created sysml v2 model no. 24\n","Created sysml v2 model no. 25\n","Created sysml v2 model no. 26\n","Created sysml v2 model no. 27\n","Created sysml v2 model no. 28\n","Created sysml v2 model no. 29\n","Created sysml v2 model no. 30\n","Created sysml v2 model no. 31\n","Created sysml v2 model no. 32\n","Created sysml v2 model no. 33\n","Created sysml v2 model no. 34\n","Created sysml v2 model no. 35\n","Created sysml v2 model no. 36\n","Created sysml v2 model no. 37\n","Created sysml v2 model no. 38\n","Created sysml v2 model no. 39\n","Created sysml v2 model no. 40\n","Created sysml v2 model no. 41\n","Created sysml v2 model no. 42\n","Created sysml v2 model no. 43\n","Created sysml v2 model no. 44\n","Created sysml v2 model no. 45\n","Created sysml v2 model no. 46\n","Created sysml v2 model no. 47\n","Created sysml v2 model no. 48\n","Created sysml v2 model no. 49\n","Created sysml v2 model no. 50\n","Created sysml v2 model no. 51\n","Created sysml v2 model no. 52\n","Created sysml v2 model no. 53\n","Created sysml v2 model no. 54\n","Created sysml v2 model no. 55\n","Created sysml v2 model no. 56\n","Created sysml v2 model no. 57\n","Created sysml v2 model no. 58\n","Created sysml v2 model no. 59\n","Created sysml v2 model no. 60\n","Created sysml v2 model no. 61\n","Created sysml v2 model no. 62\n","Created sysml v2 model no. 63\n","Created sysml v2 model no. 64\n","Created sysml v2 model no. 65\n","Created sysml v2 model no. 66\n","Created sysml v2 model no. 67\n","Created sysml v2 model no. 68\n","Created sysml v2 model no. 69\n","Created sysml v2 model no. 70\n","Created sysml v2 model no. 71\n","Created sysml v2 model no. 72\n","Created sysml v2 model no. 73\n","Created sysml v2 model no. 74\n","Created sysml v2 model no. 75\n","Created sysml v2 model no. 76\n","Created sysml v2 model no. 77\n","Created sysml v2 model no. 78\n","Created sysml v2 model no. 79\n","Created sysml v2 model no. 80\n","Created sysml v2 model no. 81\n","Created sysml v2 model no. 82\n","Created sysml v2 model no. 83\n","Created sysml v2 model no. 84\n","Created sysml v2 model no. 85\n","Created sysml v2 model no. 86\n","Created sysml v2 model no. 87\n","Created sysml v2 model no. 88\n","Created sysml v2 model no. 89\n","Created sysml v2 model no. 90\n","Created sysml v2 model no. 91\n","Created sysml v2 model no. 92\n","Created sysml v2 model no. 93\n","Created sysml v2 model no. 94\n","Created sysml v2 model no. 95\n","Created sysml v2 model no. 96\n","Created sysml v2 model no. 97\n","Created sysml v2 model no. 98\n","Created sysml v2 model no. 99\n","  adding: 100systems_AUTOSAR_sysml/ (stored 0%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_30.sysml (deflated 79%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_62.sysml (deflated 81%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_76.sysml (deflated 79%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_58.sysml (deflated 80%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_10.sysml (deflated 82%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_31.sysml (deflated 79%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_84.sysml (deflated 77%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_92.sysml (deflated 81%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_60.sysml (deflated 80%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_37.sysml (deflated 88%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_43.sysml (deflated 86%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_34.sysml (deflated 80%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_82.sysml (deflated 83%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_87.sysml (deflated 83%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_52.sysml (deflated 85%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_55.sysml (deflated 81%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_23.sysml (deflated 81%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_81.sysml (deflated 76%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_79.sysml (deflated 86%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_65.sysml (deflated 82%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_12.sysml (deflated 78%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_32.sysml (deflated 80%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_63.sysml (deflated 82%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_0.sysml (deflated 71%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_56.sysml (deflated 80%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_61.sysml (deflated 81%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_28.sysml (deflated 81%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_44.sysml (deflated 75%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_75.sysml (deflated 80%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_51.sysml (deflated 85%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_47.sysml (deflated 86%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_67.sysml (deflated 80%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_15.sysml (deflated 80%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_22.sysml (deflated 85%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_21.sysml (deflated 85%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_18.sysml (deflated 85%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_41.sysml (deflated 88%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_38.sysml (deflated 81%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_6.sysml (deflated 78%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_78.sysml (deflated 85%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_66.sysml (deflated 81%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_83.sysml (deflated 78%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_7.sysml (deflated 79%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_98.sysml (deflated 82%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_40.sysml (deflated 81%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_25.sysml (deflated 79%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_27.sysml (deflated 82%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_49.sysml (deflated 81%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_39.sysml (deflated 81%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_2.sysml (deflated 80%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_73.sysml (deflated 84%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_99.sysml (deflated 85%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_91.sysml (deflated 81%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_57.sysml (deflated 77%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_72.sysml (deflated 77%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_20.sysml (deflated 83%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_74.sysml (deflated 80%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_95.sysml (deflated 78%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_13.sysml (deflated 84%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_86.sysml (deflated 79%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_35.sysml (deflated 81%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_36.sysml (deflated 80%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_90.sysml (deflated 76%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_5.sysml (deflated 78%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_71.sysml (deflated 80%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_4.sysml (deflated 79%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_85.sysml (deflated 81%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_89.sysml (deflated 85%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_96.sysml (deflated 81%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_9.sysml (deflated 86%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_29.sysml (deflated 81%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_88.sysml (deflated 79%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_1.sysml (deflated 85%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_53.sysml (deflated 81%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_50.sysml (deflated 80%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_33.sysml (deflated 87%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_80.sysml (deflated 82%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_14.sysml (deflated 78%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_69.sysml (deflated 82%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_77.sysml (deflated 80%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_54.sysml (deflated 75%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_17.sysml (deflated 81%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_46.sysml (deflated 82%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_42.sysml (deflated 78%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_68.sysml (deflated 76%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_70.sysml (deflated 80%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_16.sysml (deflated 80%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_26.sysml (deflated 82%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_45.sysml (deflated 80%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_11.sysml (deflated 87%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_19.sysml (deflated 80%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_59.sysml (deflated 82%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_93.sysml (deflated 79%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_24.sysml (deflated 82%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_97.sysml (deflated 81%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_48.sysml (deflated 80%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_8.sysml (deflated 77%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_64.sysml (deflated 82%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_94.sysml (deflated 79%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_3.sysml (deflated 81%)\n"]}],"source":["import os\n","from llamafactory.chat import ChatModel\n","from llamafactory.extras.misc import torch_gc\n","\n","# Setup chat model arguments\n","args = dict(\n","  model_name_or_path=hf_base_model_id,\n","  adapter_name_or_path=adapter_name,      # load the saved LoRA adapters\n","  template=llamafactory_template_name,                     # same to the one in training\n","  finetuning_type=\"lora\",                  # same to the one in training\n","  quantization_bit=4,                    # load 4-bit quantized model\n","  use_unsloth=False,                     # use UnslothAI's LoRA optimization for 2x faster generation\n",")\n","\n","# Initialize the chat model\n","chat_model = ChatModel(args)\n","\n","# Ensure the sysml_files directory exists\n","output_dir = \"100systems_AUTOSAR_sysml\"\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# Iterate over the technical system names\n","query = \"\"\"\n","You create a model with these parts: Front Light Manager, Ignition, Light Switch, Low Beam Light. Each part contains at least one statemachine.\n","The Front Light Manager shall evaluate the Ignition Key position.\n","The Front Light Manager shall read the LS switch position\n","The Front Light Manager shall evaluate the LS switch status.\n","Only if the LS switch status changes from OFF to ON the Front Light Manager shall create a switch event (ON).\n","If the LS switch status changes from ON to OFF the Front Light Manager shall create a switch event (OFF).\n","The Front Light Manager shall activate the low beam light, if the Ignition Key position is ON and a light switch event is detected\n","The Front Light Manager shall deactivate the low beam light if the Ignition Key position is OFF or a switch event (OFF) is detected.\n","\"\"\"\n","messages = [{\"role\": \"user\", \"content\": query}]\n","\n","for n in range(100):\n","    response = \"\"\n","    for new_text in chat_model.stream_chat(messages):\n","      response += new_text\n","\n","    # Write the response to a file\n","    file_path = os.path.join(output_dir, f\"AUTOSAR_{n}.sysml\")\n","    with open(file_path, 'w') as file:\n","        file.write(response)\n","\n","    print(\"Created sysml v2 model no. \" + str(n) )\n","\n","# Free up memory\n","torch_gc()\n","\n","# Upload to Google Drive\n","directory_to_zip = output_dir  # Change this to your directory\n","zip_output_path = f'{output_dir}.zip'  # Change this to your desired output zip file name\n","drive_zip_output_path = f'/content/drive/MyDrive/{output_dir}.zip'  # Change this to your desired location on Google Drive\n","\n","!zip -r $zip_output_path $directory_to_zip\n","!mv $zip_output_path $drive_zip_output_path"]},{"cell_type":"code","source":["# Upload to Google Drive\n","directory_to_zip = output_dir  # Change this to your directory\n","zip_output_path = f'{output_dir}.zip'  # Change this to your desired output zip file name\n","drive_zip_output_path = f'/content/drive/MyDrive/{output_dir}.zip'  # Change this to your desired location on Google Drive\n","\n","!zip -r $zip_output_path $directory_to_zip\n","!mv $zip_output_path $drive_zip_output_path"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DX58cYCcsVxv","executionInfo":{"status":"ok","timestamp":1716076434551,"user_tz":-120,"elapsed":15,"user":{"displayName":"Bertil Muth","userId":"02558266373806387996"}},"outputId":"a0087282-41b5-45bd-c3ae-e4cf5fdec05b"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: 100systems_AUTOSAR_sysml/ (stored 0%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_30.sysml (deflated 79%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_62.sysml (deflated 81%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_76.sysml (deflated 79%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_58.sysml (deflated 80%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_10.sysml (deflated 82%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_31.sysml (deflated 79%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_84.sysml (deflated 77%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_92.sysml (deflated 81%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_60.sysml (deflated 80%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_37.sysml (deflated 88%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_43.sysml (deflated 86%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_34.sysml (deflated 80%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_82.sysml (deflated 83%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_87.sysml (deflated 83%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_52.sysml (deflated 85%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_55.sysml (deflated 81%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_23.sysml (deflated 81%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_81.sysml (deflated 76%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_79.sysml (deflated 86%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_65.sysml (deflated 82%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_12.sysml (deflated 78%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_32.sysml (deflated 80%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_63.sysml (deflated 82%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_0.sysml (deflated 71%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_56.sysml (deflated 80%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_61.sysml (deflated 81%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_28.sysml (deflated 81%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_44.sysml (deflated 75%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_75.sysml (deflated 80%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_51.sysml (deflated 85%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_47.sysml (deflated 86%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_67.sysml (deflated 80%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_15.sysml (deflated 80%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_22.sysml (deflated 85%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_21.sysml (deflated 85%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_18.sysml (deflated 85%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_41.sysml (deflated 88%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_38.sysml (deflated 81%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_6.sysml (deflated 78%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_78.sysml (deflated 85%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_66.sysml (deflated 81%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_83.sysml (deflated 78%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_7.sysml (deflated 79%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_98.sysml (deflated 82%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_40.sysml (deflated 81%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_25.sysml (deflated 79%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_27.sysml (deflated 82%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_49.sysml (deflated 81%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_39.sysml (deflated 81%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_2.sysml (deflated 80%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_73.sysml (deflated 84%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_99.sysml (deflated 85%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_91.sysml (deflated 81%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_57.sysml (deflated 77%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_72.sysml (deflated 77%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_20.sysml (deflated 83%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_74.sysml (deflated 80%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_95.sysml (deflated 78%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_13.sysml (deflated 84%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_86.sysml (deflated 79%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_35.sysml (deflated 81%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_36.sysml (deflated 80%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_90.sysml (deflated 76%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_5.sysml (deflated 78%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_71.sysml (deflated 80%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_4.sysml (deflated 79%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_85.sysml (deflated 81%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_89.sysml (deflated 85%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_96.sysml (deflated 81%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_9.sysml (deflated 86%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_29.sysml (deflated 81%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_88.sysml (deflated 79%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_1.sysml (deflated 85%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_53.sysml (deflated 81%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_50.sysml (deflated 80%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_33.sysml (deflated 87%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_80.sysml (deflated 82%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_14.sysml (deflated 78%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_69.sysml (deflated 82%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_77.sysml (deflated 80%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_54.sysml (deflated 75%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_17.sysml (deflated 81%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_46.sysml (deflated 82%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_42.sysml (deflated 78%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_68.sysml (deflated 76%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_70.sysml (deflated 80%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_16.sysml (deflated 80%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_26.sysml (deflated 82%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_45.sysml (deflated 80%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_11.sysml (deflated 87%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_19.sysml (deflated 80%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_59.sysml (deflated 82%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_93.sysml (deflated 79%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_24.sysml (deflated 82%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_97.sysml (deflated 81%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_48.sysml (deflated 80%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_8.sysml (deflated 77%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_64.sysml (deflated 82%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_94.sysml (deflated 79%)\n","  adding: 100systems_AUTOSAR_sysml/AUTOSAR_3.sysml (deflated 81%)\n"]}]},{"cell_type":"markdown","metadata":{"id":"NkdbvaEIImGH"},"source":["### Unzip the adapter from Google Drive"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4260,"status":"ok","timestamp":1716068676606,"user":{"displayName":"Bertil Muth","userId":"02558266373806387996"},"user_tz":-120},"id":"ielP1NXQIozA","outputId":"bd0071d1-2ffd-4fb1-830e-d809b5a762bf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  /content/drive/MyDrive/phi_lora.zip\n","   creating: /content/LLaMA-Factory/phi_lora/\n","  inflating: /content/LLaMA-Factory/phi_lora/all_results.json  \n","  inflating: /content/LLaMA-Factory/phi_lora/README.md  \n","  inflating: /content/LLaMA-Factory/phi_lora/train_results.json  \n","   creating: /content/LLaMA-Factory/phi_lora/runs/\n","   creating: /content/LLaMA-Factory/phi_lora/runs/May18_18-34-01_0d0c67952c35/\n","  inflating: /content/LLaMA-Factory/phi_lora/runs/May18_18-34-01_0d0c67952c35/events.out.tfevents.1716057283.0d0c67952c35.7829.0  \n","  inflating: /content/LLaMA-Factory/phi_lora/adapter_model.safetensors  \n","   creating: /content/LLaMA-Factory/phi_lora/checkpoint-1000/\n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-1000/README.md  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-1000/adapter_model.safetensors  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-1000/rng_state.pth  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-1000/trainer_state.json  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-1000/special_tokens_map.json  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-1000/scheduler.pt  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-1000/tokenizer.json  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-1000/adapter_config.json  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-1000/tokenizer_config.json  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-1000/optimizer.pt  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-1000/training_args.bin  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-1000/tokenizer.model  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-1000/added_tokens.json  \n","  inflating: /content/LLaMA-Factory/phi_lora/trainer_state.json  \n","  inflating: /content/LLaMA-Factory/phi_lora/trainer_log.jsonl  \n","  inflating: /content/LLaMA-Factory/phi_lora/special_tokens_map.json  \n","  inflating: /content/LLaMA-Factory/phi_lora/tokenizer.json  \n","  inflating: /content/LLaMA-Factory/phi_lora/adapter_config.json  \n","   creating: /content/LLaMA-Factory/phi_lora/checkpoint-2000/\n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-2000/README.md  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-2000/adapter_model.safetensors  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-2000/rng_state.pth  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-2000/trainer_state.json  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-2000/special_tokens_map.json  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-2000/scheduler.pt  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-2000/tokenizer.json  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-2000/adapter_config.json  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-2000/tokenizer_config.json  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-2000/optimizer.pt  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-2000/training_args.bin  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-2000/tokenizer.model  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-2000/added_tokens.json  \n","  inflating: /content/LLaMA-Factory/phi_lora/tokenizer_config.json  \n","  inflating: /content/LLaMA-Factory/phi_lora/training_args.bin  \n","  inflating: /content/LLaMA-Factory/phi_lora/tokenizer.model  \n","  inflating: /content/LLaMA-Factory/phi_lora/added_tokens.json  \n"]}],"source":["# Paths\n","zip_file_path = f'/content/drive/MyDrive/{adapter_name}.zip'  # Path to the zip file\n","unzip_output_path = f'/content/LLaMA-Factory'  # Path to extract the zip file contents\n","\n","# Unzip the file\n","!unzip $zip_file_path -d $unzip_output_path"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[{"file_id":"1eRTPn37ltBbYsISy9Aw2NuI2Aq5CQrD9","timestamp":1715161074742}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"96adc00aa550415cae77310c3b9bf784":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e4f59dcb5ddb47e28cdd1eda981845a0","IPY_MODEL_9422709ed26242549598c74064dd73d2","IPY_MODEL_e58ef07bd0684d228f05e4d60998c693"],"layout":"IPY_MODEL_fee4638689094b7aa8bd6cff5c943c67"}},"e4f59dcb5ddb47e28cdd1eda981845a0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7fa65913b7c54521a15afe29ff6d61a1","placeholder":"","style":"IPY_MODEL_6bba2e20d72b46fbb9b3d2033ef11783","value":"Loadingcheckpointshards:100%"}},"9422709ed26242549598c74064dd73d2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a01519d001104fbbb0dbb80e30f305a7","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2f9a9d9b315e4f8fb804b0b1718c74ca","value":2}},"e58ef07bd0684d228f05e4d60998c693":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_53bb32c5e6284bfab283cdf21f5a9c4a","placeholder":"","style":"IPY_MODEL_b31e1d0d5b904f359062aaf73fddc0e7","value":"2/2[00:03&lt;00:00,1.54s/it]"}},"fee4638689094b7aa8bd6cff5c943c67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7fa65913b7c54521a15afe29ff6d61a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6bba2e20d72b46fbb9b3d2033ef11783":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a01519d001104fbbb0dbb80e30f305a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f9a9d9b315e4f8fb804b0b1718c74ca":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"53bb32c5e6284bfab283cdf21f5a9c4a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b31e1d0d5b904f359062aaf73fddc0e7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0207d5fc3ad24f3a8cc7cb3e8ebaa26b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dc56a71045804460b3b49e89e1bc532e","IPY_MODEL_a803702be854418580a4c34fbbb9e1b7","IPY_MODEL_c5c228e3c56f4803babd7c7636036e8a"],"layout":"IPY_MODEL_c9ae949b5c06423e99b2acf286393f62"}},"dc56a71045804460b3b49e89e1bc532e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7410cccaaace475d9e0dc82df19f22c5","placeholder":"","style":"IPY_MODEL_952c0c6da3a346f38ea8140a6cb3ed54","value":"tokenizer_config.json:100%"}},"a803702be854418580a4c34fbbb9e1b7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_443fc6d119f749f7bd7dae9a47966932","max":3171,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4681a692486c4f028c2c73b1c7850e59","value":3171}},"c5c228e3c56f4803babd7c7636036e8a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd05256385894add821bc9944fee5a15","placeholder":"","style":"IPY_MODEL_c78aaeebdf6841a28c6b4601fb98104a","value":"3.17k/3.17k[00:00&lt;00:00,279kB/s]"}},"c9ae949b5c06423e99b2acf286393f62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7410cccaaace475d9e0dc82df19f22c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"952c0c6da3a346f38ea8140a6cb3ed54":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"443fc6d119f749f7bd7dae9a47966932":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4681a692486c4f028c2c73b1c7850e59":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dd05256385894add821bc9944fee5a15":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c78aaeebdf6841a28c6b4601fb98104a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8e26631564d24eb2bdcacbcd063e9259":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_87dc5964e77c4b4cb13e5fe7eae827f7","IPY_MODEL_a9644e4b97a94e1b9f653aec3cadcb00","IPY_MODEL_d04f060e2d334d5dbe827c7382d8cb91"],"layout":"IPY_MODEL_c6a9661d91b4405088c11939ad795141"}},"87dc5964e77c4b4cb13e5fe7eae827f7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f2a62a1ca54422ba99fea2c4a7e485f","placeholder":"","style":"IPY_MODEL_93fa013e029349cca413228956014538","value":"tokenizer.model:100%"}},"a9644e4b97a94e1b9f653aec3cadcb00":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dff0bab3c975434eaee597389c7bdf9d","max":499723,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e5be63eff40a4c2a895ebdafa0d5ad2f","value":499723}},"d04f060e2d334d5dbe827c7382d8cb91":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb4c593a415e4d009aa40384d9fed590","placeholder":"","style":"IPY_MODEL_5cf2b2e82426426cb917fe0d66d4634f","value":"500k/500k[00:00&lt;00:00,8.18MB/s]"}},"c6a9661d91b4405088c11939ad795141":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f2a62a1ca54422ba99fea2c4a7e485f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93fa013e029349cca413228956014538":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dff0bab3c975434eaee597389c7bdf9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5be63eff40a4c2a895ebdafa0d5ad2f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cb4c593a415e4d009aa40384d9fed590":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5cf2b2e82426426cb917fe0d66d4634f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fd8d5d48bc4a48a5bc5b2f505b6b0e27":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a77bce5dcd7c4989b2a536d9e70152a9","IPY_MODEL_0ab3c85a6fb34ca5918b4d2b5d8b35f5","IPY_MODEL_86e3366ee44b4cd294c96811956d0bfa"],"layout":"IPY_MODEL_feb29218c8dc412c93658b1c5efa7a47"}},"a77bce5dcd7c4989b2a536d9e70152a9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f196523c4ce744d2b3d5319183203fab","placeholder":"","style":"IPY_MODEL_25304884db0d40f6a4e677ef359d3571","value":"tokenizer.json:100%"}},"0ab3c85a6fb34ca5918b4d2b5d8b35f5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_907893332b424d41a0a2d03517313bc5","max":1844409,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b93215dea5254c61a7c60dacf763d2cf","value":1844409}},"86e3366ee44b4cd294c96811956d0bfa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9889d1346da4461a9ce07362751e577d","placeholder":"","style":"IPY_MODEL_c0c6eb27550040bd8a7e7adbcd6fac9d","value":"1.84M/1.84M[00:00&lt;00:00,4.51MB/s]"}},"feb29218c8dc412c93658b1c5efa7a47":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f196523c4ce744d2b3d5319183203fab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25304884db0d40f6a4e677ef359d3571":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"907893332b424d41a0a2d03517313bc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b93215dea5254c61a7c60dacf763d2cf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9889d1346da4461a9ce07362751e577d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0c6eb27550040bd8a7e7adbcd6fac9d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"887d160bd7254e73a6889fe6b37f879b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c75380750e3d475aa7bcb34d726cb0bd","IPY_MODEL_a63190853c514fd7abf9232bff7fcfcf","IPY_MODEL_778b0e604e824cceaab515fcc7711b0f"],"layout":"IPY_MODEL_a9264344d8824176a1833e71fcd69520"}},"c75380750e3d475aa7bcb34d726cb0bd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_097539c0882945ee813d84bfe98d0740","placeholder":"","style":"IPY_MODEL_da4a797a8e2546c4a5a51caf5c8dcb9e","value":"added_tokens.json:100%"}},"a63190853c514fd7abf9232bff7fcfcf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0af74fad1aa74185a8b928a23efb9b74","max":293,"min":0,"orientation":"horizontal","style":"IPY_MODEL_187c04d1871743aebf13679d33505dd8","value":293}},"778b0e604e824cceaab515fcc7711b0f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a2025cbf58046d4b1c9c39ef0e447d4","placeholder":"","style":"IPY_MODEL_a8ef4761394f4103b39392f7ab627ad0","value":"293/293[00:00&lt;00:00,25.6kB/s]"}},"a9264344d8824176a1833e71fcd69520":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"097539c0882945ee813d84bfe98d0740":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da4a797a8e2546c4a5a51caf5c8dcb9e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0af74fad1aa74185a8b928a23efb9b74":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"187c04d1871743aebf13679d33505dd8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5a2025cbf58046d4b1c9c39ef0e447d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8ef4761394f4103b39392f7ab627ad0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d95b5fad9b2c45299d72134f1d139c21":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_05cb2d9b691a4220a4b96bd08ee17c36","IPY_MODEL_1c7e75f57f2e45f8a86ae04cc551ae62","IPY_MODEL_d5faf580a5da403d87306d96933c3dc8"],"layout":"IPY_MODEL_6f545b255abb4302b60e62f56c97fc69"}},"05cb2d9b691a4220a4b96bd08ee17c36":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c4ce26ccf0a7496cba61600c9aa32e0e","placeholder":"","style":"IPY_MODEL_2f957a5772ac4df893a9cf6fe42ef456","value":"special_tokens_map.json:100%"}},"1c7e75f57f2e45f8a86ae04cc551ae62":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_38dcd3df26e64da6a3f59483ec6cffa5","max":568,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b0511e146b9e42d883b70123602a8654","value":568}},"d5faf580a5da403d87306d96933c3dc8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca48d622d46447e69ebe9d52085d5765","placeholder":"","style":"IPY_MODEL_07f61d1d9d5f47f1804cfa2eacf89a68","value":"568/568[00:00&lt;00:00,48.8kB/s]"}},"6f545b255abb4302b60e62f56c97fc69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4ce26ccf0a7496cba61600c9aa32e0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f957a5772ac4df893a9cf6fe42ef456":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"38dcd3df26e64da6a3f59483ec6cffa5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0511e146b9e42d883b70123602a8654":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ca48d622d46447e69ebe9d52085d5765":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07f61d1d9d5f47f1804cfa2eacf89a68":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b1579a828796407da8582ec720fa3939":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bbc1dc9012a74fcb892db67a030170d6","IPY_MODEL_6225843db029435f9dccb7dd66c2a5d3","IPY_MODEL_66f9b6baa5214b41ba4fd5969d95adf9"],"layout":"IPY_MODEL_f0005c30f71e49aa8c83e5e574bdf6da"}},"bbc1dc9012a74fcb892db67a030170d6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fea2cd38284446c6abe9166945c3ce64","placeholder":"","style":"IPY_MODEL_1b132896fdd0463598ee224a47959334","value":"config.json:100%"}},"6225843db029435f9dccb7dd66c2a5d3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_53029bf98a954c9dbe5dd790a49eb40d","max":3353,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7dcc05d7c42c47649c2c5404bf62921a","value":3353}},"66f9b6baa5214b41ba4fd5969d95adf9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec1aaccb96e94a80bd31ed543fabfc31","placeholder":"","style":"IPY_MODEL_e991b0d63aec44fbbf45004128ced8fc","value":"3.35k/3.35k[00:00&lt;00:00,300kB/s]"}},"f0005c30f71e49aa8c83e5e574bdf6da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fea2cd38284446c6abe9166945c3ce64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b132896fdd0463598ee224a47959334":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"53029bf98a954c9dbe5dd790a49eb40d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7dcc05d7c42c47649c2c5404bf62921a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ec1aaccb96e94a80bd31ed543fabfc31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e991b0d63aec44fbbf45004128ced8fc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"99358e03481541d197192ace60d35189":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_81d19356ac8346dc818db873e04876f8","IPY_MODEL_058699baa6de45388ea3f703d73e6e09","IPY_MODEL_81a524827e0248e1b590e187aec62e31"],"layout":"IPY_MODEL_0bcc860db2104f8696aa6895697ed68f"}},"81d19356ac8346dc818db873e04876f8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_23f42ddd1a6b4e889449d5fcffd85712","placeholder":"","style":"IPY_MODEL_b59f1f28047c4d43a79f9c2e804d7455","value":"configuration_phi3.py:100%"}},"058699baa6de45388ea3f703d73e6e09":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e3f2f13b0d9b41d0bba3efb759f66e27","max":10411,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e910824672174ba2ab17649606f6b5b1","value":10411}},"81a524827e0248e1b590e187aec62e31":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_42128f01b1d34fb9aa10abe80c07578e","placeholder":"","style":"IPY_MODEL_0f846bd1de85422da9d03dc51e705024","value":"10.4k/10.4k[00:00&lt;00:00,831kB/s]"}},"0bcc860db2104f8696aa6895697ed68f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23f42ddd1a6b4e889449d5fcffd85712":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b59f1f28047c4d43a79f9c2e804d7455":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e3f2f13b0d9b41d0bba3efb759f66e27":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e910824672174ba2ab17649606f6b5b1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"42128f01b1d34fb9aa10abe80c07578e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f846bd1de85422da9d03dc51e705024":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"480624461726450a9f8aeddcd78a08ec":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0c4445b9980941fbaac2a2cf72dde61a","IPY_MODEL_5203d6a2ee754bf8857c19aca7158bcb","IPY_MODEL_83b694de2f3d4cb38a7190eabf4a2460"],"layout":"IPY_MODEL_e041589aba7f42158e00f679c72cb86d"}},"0c4445b9980941fbaac2a2cf72dde61a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b3284eb5b40e405ab03f411e8f2033d4","placeholder":"","style":"IPY_MODEL_67a35e0030074f048e5732539a7abfe1","value":"modeling_phi3.py:100%"}},"5203d6a2ee754bf8857c19aca7158bcb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a1299f0a13374a5c9f836cab0aeb9acf","max":73778,"min":0,"orientation":"horizontal","style":"IPY_MODEL_911a92ca9ffb4dc5b62d74ed99931dd5","value":73778}},"83b694de2f3d4cb38a7190eabf4a2460":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9774283f1af4cd29705f0065e65a69f","placeholder":"","style":"IPY_MODEL_93417fc686d3415dadb1772eed1d2ebb","value":"73.8k/73.8k[00:00&lt;00:00,904kB/s]"}},"e041589aba7f42158e00f679c72cb86d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3284eb5b40e405ab03f411e8f2033d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67a35e0030074f048e5732539a7abfe1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a1299f0a13374a5c9f836cab0aeb9acf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"911a92ca9ffb4dc5b62d74ed99931dd5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b9774283f1af4cd29705f0065e65a69f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93417fc686d3415dadb1772eed1d2ebb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ed798f6f9c214c11942ba710617b7f2d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1e4b29f968fd4f3e9d70b10d34a72da1","IPY_MODEL_605653da174f4a9e8fbc631d33125d96","IPY_MODEL_e1ca5d455aed48f7be61f936cca9e1a0"],"layout":"IPY_MODEL_9bc0bb034ee54dfc87685e839526117f"}},"1e4b29f968fd4f3e9d70b10d34a72da1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_49b725afaf414c7ba7ea577cbfec8c66","placeholder":"","style":"IPY_MODEL_291a67c25e8545d8bea439c7cf71d22d","value":"model.safetensors.index.json:100%"}},"605653da174f4a9e8fbc631d33125d96":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a49e4e8e23e446a835634f7556d0830","max":16331,"min":0,"orientation":"horizontal","style":"IPY_MODEL_77ce231234954ec9a751aaf88b183861","value":16331}},"e1ca5d455aed48f7be61f936cca9e1a0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7fec79233f2e4749a4f2d5b50c052111","placeholder":"","style":"IPY_MODEL_b54d1e8773a54ab18fce7bbf30e55e62","value":"16.3k/16.3k[00:00&lt;00:00,1.22MB/s]"}},"9bc0bb034ee54dfc87685e839526117f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49b725afaf414c7ba7ea577cbfec8c66":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"291a67c25e8545d8bea439c7cf71d22d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1a49e4e8e23e446a835634f7556d0830":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77ce231234954ec9a751aaf88b183861":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7fec79233f2e4749a4f2d5b50c052111":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b54d1e8773a54ab18fce7bbf30e55e62":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b9fb8dd57c0f417a9f6387984875140e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b73f67bf29084cc28911da2c7aa181e1","IPY_MODEL_e265b9e8ac7246f68bb74fee63fea4c5","IPY_MODEL_e013b20891e34ac487b4853bcc351354"],"layout":"IPY_MODEL_c7ba26c4bac34d4eb4c9d6c86555ee15"}},"b73f67bf29084cc28911da2c7aa181e1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c103a2f453094fec95d5492024e946c5","placeholder":"","style":"IPY_MODEL_9311d116f756470ca6b3a58865825f25","value":"Downloadingshards:100%"}},"e265b9e8ac7246f68bb74fee63fea4c5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_53f2b740397141b8818c2981dc7766f1","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9944c46db62248bdb46b93a112bce6f5","value":2}},"e013b20891e34ac487b4853bcc351354":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dae4faabe24f42afb9f518098f9cfdf6","placeholder":"","style":"IPY_MODEL_654b7a1d800e4a7a8b497c34a49dc52c","value":"2/2[00:29&lt;00:00,13.57s/it]"}},"c7ba26c4bac34d4eb4c9d6c86555ee15":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c103a2f453094fec95d5492024e946c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9311d116f756470ca6b3a58865825f25":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"53f2b740397141b8818c2981dc7766f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9944c46db62248bdb46b93a112bce6f5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dae4faabe24f42afb9f518098f9cfdf6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"654b7a1d800e4a7a8b497c34a49dc52c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c2fb26185a774b40814cfc849584d238":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c9c96e9e10364c6b97c1637718ab571d","IPY_MODEL_49c772ed77f7462cae1f10610855f907","IPY_MODEL_00d5ee01c9bc47bea312b1efc62892d1"],"layout":"IPY_MODEL_78f4cf80e87b428d9effb3ab196717ac"}},"c9c96e9e10364c6b97c1637718ab571d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_516067b4e9ba43249b4335e34f5af68c","placeholder":"","style":"IPY_MODEL_a64fe86450ae4fb98c74f7d91cd56a08","value":"model-00001-of-00002.safetensors:100%"}},"49c772ed77f7462cae1f10610855f907":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1c3a9112df214c9db789ebc8a844be91","max":4972489328,"min":0,"orientation":"horizontal","style":"IPY_MODEL_523d8f6bd7054d02a6ed84d68505239e","value":4972489328}},"00d5ee01c9bc47bea312b1efc62892d1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_93fbf21cd88b47b080a4820d2f70f0c4","placeholder":"","style":"IPY_MODEL_d1d62c94007a4ffeb1483187122018e4","value":"4.97G/4.97G[00:19&lt;00:00,353MB/s]"}},"78f4cf80e87b428d9effb3ab196717ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"516067b4e9ba43249b4335e34f5af68c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a64fe86450ae4fb98c74f7d91cd56a08":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1c3a9112df214c9db789ebc8a844be91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"523d8f6bd7054d02a6ed84d68505239e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"93fbf21cd88b47b080a4820d2f70f0c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1d62c94007a4ffeb1483187122018e4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"71d612d7d6794bb0a45ce8527654d90a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b64fb738bdb34279b2d2b28bb38572c5","IPY_MODEL_27fe4ff30c5c43649154a068d793a7af","IPY_MODEL_0d579079d61d438b9779d72ee76c92a9"],"layout":"IPY_MODEL_4e7f7da7b87944228e2e90ad51c07343"}},"b64fb738bdb34279b2d2b28bb38572c5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c77547a61e049d7a64abde568bf7cd7","placeholder":"","style":"IPY_MODEL_6f3bfc2b572b4587a5495a3ea68382a3","value":"model-00002-of-00002.safetensors:100%"}},"27fe4ff30c5c43649154a068d793a7af":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f122d59c6e584eb2b0d89b5ed5d29a9a","max":2669692552,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7cbac3ac744748a59d5be9e85ba038d0","value":2669692552}},"0d579079d61d438b9779d72ee76c92a9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c71fc6cc569d4e40a7400bbf970dbcb8","placeholder":"","style":"IPY_MODEL_9888c9692509477fb78c3f469232ce2a","value":"2.67G/2.67G[00:08&lt;00:00,334MB/s]"}},"4e7f7da7b87944228e2e90ad51c07343":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c77547a61e049d7a64abde568bf7cd7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f3bfc2b572b4587a5495a3ea68382a3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f122d59c6e584eb2b0d89b5ed5d29a9a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7cbac3ac744748a59d5be9e85ba038d0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c71fc6cc569d4e40a7400bbf970dbcb8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9888c9692509477fb78c3f469232ce2a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fd546efa13914c97b04a4b4fcd5ac61c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_470f88decf974202aff27d40e5ca52aa","IPY_MODEL_b1ed954fcb2b4eeb863cdcc034092eab","IPY_MODEL_99e9cff4cbe04cf490c2ad1d560ed933"],"layout":"IPY_MODEL_7d6a58c273c54aeca2d518ddeaa5aa0e"}},"470f88decf974202aff27d40e5ca52aa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_69817fc241d44f33b8d8f87539c446e8","placeholder":"","style":"IPY_MODEL_3bc732a24752461388d7b97c840d3e89","value":"Loadingcheckpointshards:100%"}},"b1ed954fcb2b4eeb863cdcc034092eab":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f1a7e0d1eff249d2bef844e1e36b6210","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a49f4f5989b84410b19a21e384c15346","value":2}},"99e9cff4cbe04cf490c2ad1d560ed933":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1868b39e5dd34473a8d75073150c89da","placeholder":"","style":"IPY_MODEL_14efac5d1dad49e7812b1ebef1902661","value":"2/2[00:05&lt;00:00,2.78s/it]"}},"7d6a58c273c54aeca2d518ddeaa5aa0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69817fc241d44f33b8d8f87539c446e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3bc732a24752461388d7b97c840d3e89":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f1a7e0d1eff249d2bef844e1e36b6210":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a49f4f5989b84410b19a21e384c15346":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1868b39e5dd34473a8d75073150c89da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14efac5d1dad49e7812b1ebef1902661":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0550dd01c73d4c9783e58b5b15141f62":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_969b098c91104f3eaa0c21e3d3338b9c","IPY_MODEL_088d91ad0e5e42c090a0111d5f9e2489","IPY_MODEL_b0bd14a5f8274b449f0f58721d21206f"],"layout":"IPY_MODEL_acc3d38501dc4accb7530e6f89399cf1"}},"969b098c91104f3eaa0c21e3d3338b9c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f085978923cc401db514376da523e361","placeholder":"","style":"IPY_MODEL_42933890ee59493a97a4f14d6a4aaee3","value":"generation_config.json:100%"}},"088d91ad0e5e42c090a0111d5f9e2489":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b899b5faba044b18b15927f45279a6f7","max":172,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d8d7d0cada6f41aa9cdfc261826dda65","value":172}},"b0bd14a5f8274b449f0f58721d21206f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bedef9aa1315443293789ecadf7fd7e8","placeholder":"","style":"IPY_MODEL_1d6f3c5e3fc6433780cf5344f3bf5d10","value":"172/172[00:00&lt;00:00,16.1kB/s]"}},"acc3d38501dc4accb7530e6f89399cf1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f085978923cc401db514376da523e361":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42933890ee59493a97a4f14d6a4aaee3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b899b5faba044b18b15927f45279a6f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8d7d0cada6f41aa9cdfc261826dda65":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bedef9aa1315443293789ecadf7fd7e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d6f3c5e3fc6433780cf5344f3bf5d10":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}