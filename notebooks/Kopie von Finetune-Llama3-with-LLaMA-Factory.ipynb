{"cells":[{"cell_type":"markdown","metadata":{"id":"1oHFCsV0z-Jw"},"source":["# Finetune Llama-3 with LLaMA Factory\n","\n","Please use a **free** Tesla T4 Colab GPU to run this!\n","\n","Project homepage: https://github.com/hiyouga/LLaMA-Factory"]},{"cell_type":"markdown","metadata":{"id":"55MFt9F12aIx"},"source":["### Configuration"]},{"cell_type":"markdown","metadata":{"id":"IIuQljeJZhP2"},"source":[]},{"cell_type":"code","execution_count":3,"metadata":{"id":"GLYa6ODY2UvG","executionInfo":{"status":"ok","timestamp":1715952847031,"user_tz":-120,"elapsed":299,"user":{"displayName":"Bertil Muth","userId":"02558266373806387996"}}},"outputs":[],"source":["# The dataset used in finetuning\n","finetuning_data_url = \"https://raw.githubusercontent.com/bertilmuth/hf_to_gguf/main/finetuning_dataset/FinetuningData_ALL_llamafactory_clean.json\"\n","\n","# The model that is finetuned with the dataset\n","hf_base_model_id=\"microsoft/Phi-3-mini-4k-instruct\"\n","\n","# The llamafactory prompt template, dependent on the base model\n","llamafactory_template_name=\"phi\"\n","\n","# Epochs of finetuning\n","epochs = 5\n","\n","# The model id on Hugging Face\n","# IMPORTANT: You need to set a Google Collab secret called HF_WRITE_TOKEN to a write token of Hugging Face for this to work!\n","hf_finetuned_model_id = \"bertilmuth/phi-3-mini-4k\"\n","\n"]},{"cell_type":"markdown","metadata":{"id":"YLXUrEeiQtdF"},"source":["### Mount Google Drive\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2327,"status":"ok","timestamp":1715952836390,"user":{"displayName":"Bertil Muth","userId":"02558266373806387996"},"user_tz":-120},"id":"4WlSmQyDQx5l","outputId":"2d988c89-3f9f-4182-e9df-32068e4af3b8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"H9RXn_YQnn9f"},"source":["### Check GPU environment"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"ZkN-ktlsnrdU","executionInfo":{"status":"ok","timestamp":1715952761759,"user_tz":-120,"elapsed":257,"user":{"displayName":"Bertil Muth","userId":"02558266373806387996"}}},"outputs":[],"source":["import torch\n","try:\n","  assert torch.cuda.is_available() is True\n","except AssertionError:\n","  print(\"Please set up a GPU before using LLaMA Factory: https://medium.com/mlearning-ai/training-yolov4-on-google-colab-316f8fff99c6\")"]},{"cell_type":"markdown","metadata":{"id":"2i4Z4qw8aAzI"},"source":["### Install Dependencies & Setup"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":54927,"status":"ok","timestamp":1715952904945,"user":{"displayName":"Bertil Muth","userId":"02558266373806387996"},"user_tz":-120},"id":"giM74oK1rRIH","outputId":"fa2e1fee-bbb9-46f9-9e4b-0b7af4a62b37"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","Cloning into 'LLaMA-Factory'...\n","remote: Enumerating objects: 11725, done.\u001b[K\n","remote: Counting objects: 100% (516/516), done.\u001b[K\n","remote: Compressing objects: 100% (247/247), done.\u001b[K\n","remote: Total 11725 (delta 304), reused 430 (delta 260), pack-reused 11209\u001b[K\n","Receiving objects: 100% (11725/11725), 215.25 MiB | 28.12 MiB/s, done.\n","Resolving deltas: 100% (8544/8544), done.\n","Updating files: 100% (217/217), done.\n","/content/LLaMA-Factory\n","\u001b[0m\u001b[01;34massets\u001b[0m/       docker-compose.yml  \u001b[01;34mexamples\u001b[0m/  pyproject.toml  requirements.txt  \u001b[01;34msrc\u001b[0m/\n","CITATION.cff  Dockerfile          LICENSE    README.md       \u001b[01;34mscripts\u001b[0m/          \u001b[01;34mtests\u001b[0m/\n","\u001b[01;34mdata\u001b[0m/         \u001b[01;34mevaluation\u001b[0m/         Makefile   README_zh.md    setup.py\n","Collecting unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git\n","  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-n_752kjw/unsloth_ae3f0707aecb4418a76c47cef20d7d17\n","  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-n_752kjw/unsloth_ae3f0707aecb4418a76c47cef20d7d17\n","  Resolved https://github.com/unslothai/unsloth.git to commit e6f63d1d5e2ead92428bfb2ae2003cc238f93719\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tyro in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.8.4)\n","Requirement already satisfied: transformers>=4.38.2 in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.40.2)\n","Requirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.19.1)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.99)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.66.4)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (5.9.5)\n","Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.43.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.25.2)\n","Requirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.20.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.14.0)\n","Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.6)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.0.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.31.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.70.16)\n","Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.9.5)\n","Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.23.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.38.2->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2023.12.25)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.38.2->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.38.2->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.4.3)\n","Requirement already satisfied: docstring-parser>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.16)\n","Requirement already satisfied: typing-extensions>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.11.0)\n","Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (13.7.1)\n","Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.7.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.0.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.2.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.16.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.16.0)\n","Requirement already satisfied: xformers==0.0.25 in /usr/local/lib/python3.10/dist-packages (0.0.25)\n","Processing /content/LLaMA-Factory\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: transformers>=4.37.2 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (4.40.2)\n","Requirement already satisfied: datasets>=2.14.3 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (2.19.1)\n","Requirement already satisfied: accelerate>=0.27.2 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (0.30.1)\n","Requirement already satisfied: peft>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (0.11.0)\n","Requirement already satisfied: trl>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (0.8.6)\n","Requirement already satisfied: gradio>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (4.31.3)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (1.11.4)\n","Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (0.8.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (0.1.99)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (3.20.3)\n","Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (0.29.0)\n","Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (2.7.1)\n","Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (0.111.0)\n","Requirement already satisfied: sse-starlette in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (2.1.0)\n","Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (3.7.1)\n","Requirement already satisfied: fire in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (0.6.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (24.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (6.0.1)\n","Requirement already satisfied: bitsandbytes>=0.39.0 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (0.43.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.27.2->llamafactory==0.7.2.dev0) (1.25.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.27.2->llamafactory==0.7.2.dev0) (5.9.5)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.27.2->llamafactory==0.7.2.dev0) (2.2.1+cu121)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.27.2->llamafactory==0.7.2.dev0) (0.23.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.27.2->llamafactory==0.7.2.dev0) (0.4.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.3->llamafactory==0.7.2.dev0) (3.14.0)\n","Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.3->llamafactory==0.7.2.dev0) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.3->llamafactory==0.7.2.dev0) (0.6)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.3->llamafactory==0.7.2.dev0) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.3->llamafactory==0.7.2.dev0) (2.0.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.3->llamafactory==0.7.2.dev0) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.3->llamafactory==0.7.2.dev0) (4.66.4)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.3->llamafactory==0.7.2.dev0) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.3->llamafactory==0.7.2.dev0) (0.70.16)\n","Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.3->llamafactory==0.7.2.dev0) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.3->llamafactory==0.7.2.dev0) (3.9.5)\n","Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.7.2.dev0) (23.2.1)\n","Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.7.2.dev0) (4.2.2)\n","Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.7.2.dev0) (0.3.2)\n","Requirement already satisfied: gradio-client==0.16.3 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.7.2.dev0) (0.16.3)\n","Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.7.2.dev0) (0.27.0)\n","Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.7.2.dev0) (6.4.0)\n","Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.7.2.dev0) (3.1.4)\n","Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.7.2.dev0) (2.1.5)\n","Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.7.2.dev0) (3.10.3)\n","Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.7.2.dev0) (9.4.0)\n","Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.7.2.dev0) (0.25.1)\n","Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.7.2.dev0) (0.0.9)\n","Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.7.2.dev0) (0.4.4)\n","Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.7.2.dev0) (2.10.0)\n","Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.7.2.dev0) (0.12.0)\n","Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.7.2.dev0) (0.12.3)\n","Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.7.2.dev0) (4.11.0)\n","Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.7.2.dev0) (2.0.7)\n","Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.16.3->gradio>=4.0.0->llamafactory==0.7.2.dev0) (11.0.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.7.2.dev0) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.7.2.dev0) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.7.2.dev0) (4.51.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.7.2.dev0) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.7.2.dev0) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.7.2.dev0) (2.8.2)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->llamafactory==0.7.2.dev0) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic->llamafactory==0.7.2.dev0) (2.18.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.37.2->llamafactory==0.7.2.dev0) (2023.12.25)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.37.2->llamafactory==0.7.2.dev0) (0.19.1)\n","Requirement already satisfied: tyro>=0.5.11 in /usr/local/lib/python3.10/dist-packages (from trl>=0.8.1->llamafactory==0.7.2.dev0) (0.8.4)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn->llamafactory==0.7.2.dev0) (8.1.7)\n","Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn->llamafactory==0.7.2.dev0) (0.14.0)\n","Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->llamafactory==0.7.2.dev0) (0.37.2)\n","Requirement already satisfied: fastapi-cli>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->llamafactory==0.7.2.dev0) (0.0.3)\n","Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->llamafactory==0.7.2.dev0) (5.10.0)\n","Requirement already satisfied: email_validator>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->llamafactory==0.7.2.dev0) (2.1.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->llamafactory==0.7.2.dev0) (1.16.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->llamafactory==0.7.2.dev0) (2.4.0)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from sse-starlette->llamafactory==0.7.2.dev0) (3.7.1)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio>=4.0.0->llamafactory==0.7.2.dev0) (0.4)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio>=4.0.0->llamafactory==0.7.2.dev0) (4.19.2)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio>=4.0.0->llamafactory==0.7.2.dev0) (0.12.1)\n","Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi->llamafactory==0.7.2.dev0) (2.6.1)\n","Requirement already satisfied: idna>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi->llamafactory==0.7.2.dev0) (3.7)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.3->llamafactory==0.7.2.dev0) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.3->llamafactory==0.7.2.dev0) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.3->llamafactory==0.7.2.dev0) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.3->llamafactory==0.7.2.dev0) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.3->llamafactory==0.7.2.dev0) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.3->llamafactory==0.7.2.dev0) (4.0.3)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio>=4.0.0->llamafactory==0.7.2.dev0) (2024.2.2)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio>=4.0.0->llamafactory==0.7.2.dev0) (1.0.5)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio>=4.0.0->llamafactory==0.7.2.dev0) (1.3.1)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.14.3->llamafactory==0.7.2.dev0) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.14.3->llamafactory==0.7.2.dev0) (2024.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.14.3->llamafactory==0.7.2.dev0) (3.3.2)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->sse-starlette->llamafactory==0.7.2.dev0) (1.2.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.27.2->llamafactory==0.7.2.dev0) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.27.2->llamafactory==0.7.2.dev0) (3.3)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.27.2->llamafactory==0.7.2.dev0) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.27.2->llamafactory==0.7.2.dev0) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.27.2->llamafactory==0.7.2.dev0) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.27.2->llamafactory==0.7.2.dev0) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.27.2->llamafactory==0.7.2.dev0) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.27.2->llamafactory==0.7.2.dev0) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.27.2->llamafactory==0.7.2.dev0) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.27.2->llamafactory==0.7.2.dev0) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.27.2->llamafactory==0.7.2.dev0) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.27.2->llamafactory==0.7.2.dev0) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.27.2->llamafactory==0.7.2.dev0) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.27.2->llamafactory==0.7.2.dev0) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate>=0.27.2->llamafactory==0.7.2.dev0) (12.4.127)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.7.2.dev0) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.7.2.dev0) (13.7.1)\n","Requirement already satisfied: docstring-parser>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl>=0.8.1->llamafactory==0.7.2.dev0) (0.16)\n","Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl>=0.8.1->llamafactory==0.7.2.dev0) (1.7.1)\n","Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn->llamafactory==0.7.2.dev0) (0.6.1)\n","Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn->llamafactory==0.7.2.dev0) (1.0.1)\n","Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn->llamafactory==0.7.2.dev0) (0.19.0)\n","Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn->llamafactory==0.7.2.dev0) (0.21.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio>=4.0.0->llamafactory==0.7.2.dev0) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio>=4.0.0->llamafactory==0.7.2.dev0) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio>=4.0.0->llamafactory==0.7.2.dev0) (0.18.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.7.2.dev0) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.7.2.dev0) (2.16.1)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate>=0.27.2->llamafactory==0.7.2.dev0) (1.3.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.7.2.dev0) (0.1.2)\n","Building wheels for collected packages: llamafactory\n","  Building wheel for llamafactory (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for llamafactory: filename=llamafactory-0.7.2.dev0-py3-none-any.whl size=164636 sha256=3ab2d17925a94d7d49893ce9044e1bdcaca46a1719275e6444cb5f051041484a\n","  Stored in directory: /root/.cache/pip/wheels/de/aa/c5/27b5682c5592b7c0eecc3e208f176dedf6b11a61cf2a910b85\n","Successfully built llamafactory\n","Installing collected packages: llamafactory\n","  Attempting uninstall: llamafactory\n","    Found existing installation: llamafactory 0.7.2.dev0\n","    Uninstalling llamafactory-0.7.2.dev0:\n","      Successfully uninstalled llamafactory-0.7.2.dev0\n","Successfully installed llamafactory-0.7.2.dev0\n","The content has been successfully written to identity.json.\n"]}],"source":["# Set paths where to store the output\n","adapter_name = llamafactory_template_name + \"_lora\"\n","saved_merged_model_path = adapter_name + \"_merged\"\n","\n","# Install dependencies\n","%cd /content/\n","%rm -rf LLaMA-Factory\n","!git clone https://github.com/hiyouga/LLaMA-Factory.git\n","%cd LLaMA-Factory\n","%ls\n","!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n","!pip install --no-deps xformers==0.0.25\n","!pip install .[bitsandbytes]\n","\n","import os, requests\n","\n","# Download the finetuning data using requests\n","response = requests.get(finetuning_data_url)\n","\n","# Check if the request was successful\n","if response.status_code == 200:\n","    # Extract the text content from the response\n","    text_content = response.text\n","\n","    # Write the text content to the file identity.json\n","    with open(\"/content/LLaMA-Factory/data/identity.json\", \"w\", encoding=\"utf-8\") as file:\n","        file.write(text_content)\n","    print(\"The content has been successfully written to identity.json.\")\n","else:\n","    print(f\"Error: Failed to retrieve the file from {finetuning_data_url}. Status code: {response.status_code}\")\n"]},{"cell_type":"markdown","metadata":{"id":"rgR3UFhB0Ifq"},"source":["### Fine-tune model and store it in Hugging Face & Google Drive\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"CS0Qk5OR0i4Q","executionInfo":{"status":"error","timestamp":1715958162342,"user_tz":-120,"elapsed":3733101,"user":{"displayName":"Bertil Muth","userId":"02558266373806387996"}},"outputId":"3e546460-dcad-4512-f338-70a7b69dafab"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/LLaMA-Factory\n","2024-05-17 13:35:21.221431: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-05-17 13:35:21.221485: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-05-17 13:35:21.223255: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-05-17 13:35:22.467456: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","05/17/2024 13:35:26 - WARNING - llamafactory.hparams.parser - We recommend enable `upcast_layernorm` in quantized training.\n","05/17/2024 13:35:26 - INFO - llamafactory.hparams.parser - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, compute dtype: torch.float16\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","[INFO|tokenization_utils_base.py:2087] 2024-05-17 13:35:26,274 >> loading file tokenizer.model from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/8f5f3a02ec472594e949c39f8e38c7be8d983bcd/tokenizer.model\n","[INFO|tokenization_utils_base.py:2087] 2024-05-17 13:35:26,274 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/8f5f3a02ec472594e949c39f8e38c7be8d983bcd/tokenizer.json\n","[INFO|tokenization_utils_base.py:2087] 2024-05-17 13:35:26,274 >> loading file added_tokens.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/8f5f3a02ec472594e949c39f8e38c7be8d983bcd/added_tokens.json\n","[INFO|tokenization_utils_base.py:2087] 2024-05-17 13:35:26,274 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/8f5f3a02ec472594e949c39f8e38c7be8d983bcd/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2087] 2024-05-17 13:35:26,274 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/8f5f3a02ec472594e949c39f8e38c7be8d983bcd/tokenizer_config.json\n","[WARNING|logging.py:314] 2024-05-17 13:35:26,343 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","05/17/2024 13:35:26 - INFO - llamafactory.data.template - Replace eos token: <|end|>\n","05/17/2024 13:35:26 - WARNING - llamafactory.data.template - New tokens have been added, make sure `resize_vocab` is True.\n","05/17/2024 13:35:26 - INFO - llamafactory.data.loader - Loading dataset identity.json...\n","Generating train split: 2180 examples [00:00, 20276.58 examples/s]\n","Converting format of dataset: 100% 2180/2180 [00:00<00:00, 49067.77 examples/s]\n","Running tokenizer on dataset: 100% 2180/2180 [00:05<00:00, 424.59 examples/s]\n","input_ids:\n","[1, 32006, 887, 526, 263, 8444, 319, 29902, 20255, 29889, 32007, 29871, 13, 32010, 6204, 263, 1904, 3577, 525, 12636, 442, 6710, 29915, 426, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 5215, 16117, 26841, 6678, 29879, 1057, 275, 29928, 3864, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12715, 822, 9206, 2951, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12715, 822, 9206, 6880, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12715, 822, 853, 908, 11357, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12715, 822, 18199, 11357, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12715, 822, 512, 11506, 5594, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12715, 822, 2796, 5594, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12715, 822, 7370, 2052, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12715, 822, 23186, 2052, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 1595, 9206, 27107, 29912, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 3859, 9206, 2792, 29912, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 3859, 5947, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 3859, 1551, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 8269, 3158, 2069, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 20543, 2069, 769, 5947, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 20543, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 4102, 5947, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 16044, 9206, 2951, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 6098, 1551, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 20543, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 4102, 1551, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 16044, 9206, 6880, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 6098, 5947, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 29913, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 29913, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 1595, 22666, 29912, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 3859, 22666, 2792, 29912, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 3859, 18199, 287, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 3859, 853, 29113, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 8269, 3158, 2069, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 20543, 2069, 769, 18199, 287, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 20543, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 4102, 18199, 287, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 16044, 853, 908, 11357, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 6098, 853, 29113, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 20543, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 4102, 853, 29113, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 16044, 18199, 11357, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 6098, 18199, 287, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 29913, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 29913, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 1595, 8251, 3260, 29912, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 3859, 8251, 2792, 29912, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 3859, 5163, 280, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 3859, 512, 5594, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 8269, 3158, 2069, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 20543, 2069, 769, 5163, 280, 29936, 12]\n","inputs:\n","<s><|system|> You are a helpful AI assistant.<|end|> \n","<|user|> Create a model package 'Smartphone' {\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\timport OccurrenceFunctions::isDuring;\t\t\t\t\t\t\t\t\t\t\n","\tattribute def PowerOn;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\tattribute def PowerOff;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\tattribute def UnlockScreen;\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\tattribute def LockScreen;\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\tattribute def IncomingCall;\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\tattribute def EndCall;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\tattribute def StartApp;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\tattribute def CloseApp;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\tpart PowerManagement{\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\tstate PowerState{\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\tstate Off;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\tstate On;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\tentry action init;\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\ttransition init then Off;\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\ttransition\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\t\tfirst Off\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\t\taccept PowerOn\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\t\tthen On;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\ttransition\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\t\tfirst On\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\t\taccept PowerOff\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\t\tthen Off;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t}\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t}\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\tpart Screen{\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\tstate ScreenState{\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\tstate Locked;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\tstate Unlocked;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\tentry action init;\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\ttransition init then Locked;\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\ttransition\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\t\tfirst Locked\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\t\taccept UnlockScreen\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\t\tthen Unlocked;\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\ttransition\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\t\tfirst Unlocked\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\t\taccept LockScreen\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\t\tthen Locked;\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t}\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t}\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\tpart CallManager{\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\tstate CallState{\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\tstate Idle;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\tstate InCall;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\tentry action init;\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\ttransition init then Idle;\t\n","label_ids:\n","[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 3577, 525, 12636, 442, 6710, 29915, 426, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 5215, 16117, 26841, 6678, 29879, 1057, 275, 29928, 3864, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12715, 822, 9206, 2951, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12715, 822, 9206, 6880, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12715, 822, 853, 908, 11357, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12715, 822, 18199, 11357, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12715, 822, 512, 11506, 5594, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12715, 822, 2796, 5594, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12715, 822, 7370, 2052, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12715, 822, 23186, 2052, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 1595, 9206, 27107, 29912, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 3859, 9206, 2792, 29912, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 3859, 5947, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 3859, 1551, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 8269, 3158, 2069, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 20543, 2069, 769, 5947, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 20543, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 4102, 5947, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 16044, 9206, 2951, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 6098, 1551, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 20543, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 4102, 1551, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 16044, 9206, 6880, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 6098, 5947, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 29913, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 29913, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 1595, 22666, 29912, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 3859, 22666, 2792, 29912, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 3859, 18199, 287, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 3859, 853, 29113, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 8269, 3158, 2069, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 20543, 2069, 769, 18199, 287, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 20543, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 4102, 18199, 287, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 16044, 853, 908, 11357, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 6098, 853, 29113, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 20543, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 4102, 853, 29113, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 16044, 18199, 11357, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 12, 6098, 18199, 287, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 29913, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 29913, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 1595, 8251, 3260, 29912, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 3859, 8251, 2792, 29912, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 3859, 5163, 280, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 3859, 512, 5594, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 8269, 3158, 2069, 29936, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 12, 12, 12, 20543, 2069, 769, 5163, 280, 29936, 12]\n","labels:\n","package 'Smartphone' {\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\timport OccurrenceFunctions::isDuring;\t\t\t\t\t\t\t\t\t\t\n","\tattribute def PowerOn;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\tattribute def PowerOff;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\tattribute def UnlockScreen;\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\tattribute def LockScreen;\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\tattribute def IncomingCall;\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\tattribute def EndCall;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\tattribute def StartApp;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\tattribute def CloseApp;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\tpart PowerManagement{\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\tstate PowerState{\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\tstate Off;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\tstate On;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\tentry action init;\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\ttransition init then Off;\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\ttransition\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\t\tfirst Off\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\t\taccept PowerOn\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\t\tthen On;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\ttransition\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\t\tfirst On\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\t\taccept PowerOff\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\t\tthen Off;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t}\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t}\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\tpart Screen{\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\tstate ScreenState{\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\tstate Locked;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\tstate Unlocked;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\tentry action init;\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\ttransition init then Locked;\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\ttransition\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\t\tfirst Locked\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\t\taccept UnlockScreen\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\t\tthen Unlocked;\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\ttransition\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\t\tfirst Unlocked\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\t\taccept LockScreen\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\t\tthen Locked;\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t}\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t}\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\tpart CallManager{\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\tstate CallState{\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\tstate Idle;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\tstate InCall;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\tentry action init;\t\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\t\ttransition init then Idle;\t\n","[INFO|configuration_utils.py:726] 2024-05-17 13:35:31,932 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/8f5f3a02ec472594e949c39f8e38c7be8d983bcd/config.json\n","[INFO|configuration_utils.py:726] 2024-05-17 13:35:32,037 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/8f5f3a02ec472594e949c39f8e38c7be8d983bcd/config.json\n","[INFO|configuration_utils.py:789] 2024-05-17 13:35:32,038 >> Model config Phi3Config {\n","  \"_name_or_path\": \"microsoft/Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"microsoft/Phi-3-mini-4k-instruct--configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-4k-instruct--modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.40.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","05/17/2024 13:35:32 - INFO - llamafactory.model.utils.quantization - Quantizing model to 4 bit.\n","[WARNING|logging.py:329] 2024-05-17 13:35:32,853 >> Unsloth: You passed in `microsoft/Phi-3-mini-4k-instruct` and `load_in_4bit = True`.\n","We shall load `unsloth/Phi-3-mini-4k-instruct-bnb-4bit` for 4x faster loading.\n","config.json: 100% 1.16k/1.16k [00:00<00:00, 7.82MB/s]\n","[INFO|configuration_utils.py:726] 2024-05-17 13:35:32,966 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--unsloth--Phi-3-mini-4k-instruct-bnb-4bit/snapshots/1d9acd8f0e086359470add802aae229331797163/config.json\n","[INFO|configuration_utils.py:789] 2024-05-17 13:35:32,967 >> Model config MistralConfig {\n","  \"_name_or_path\": \"unsloth/Phi-3-mini-4k-instruct-bnb-4bit\",\n","  \"architectures\": [\n","    \"MistralForCausalLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 1,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"mistral\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"pad_token_id\": 32000,\n","  \"quantization_config\": {\n","    \"_load_in_4bit\": true,\n","    \"_load_in_8bit\": false,\n","    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n","    \"bnb_4bit_quant_storage\": \"uint8\",\n","    \"bnb_4bit_quant_type\": \"nf4\",\n","    \"bnb_4bit_use_double_quant\": true,\n","    \"llm_int8_enable_fp32_cpu_offload\": false,\n","    \"llm_int8_has_fp16_weight\": false,\n","    \"llm_int8_skip_modules\": null,\n","    \"llm_int8_threshold\": 6.0,\n","    \"load_in_4bit\": true,\n","    \"load_in_8bit\": false,\n","    \"quant_method\": \"bitsandbytes\"\n","  },\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2048,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.40.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","==((====))==  Unsloth: Fast Mistral patching release 2024.5\n","   \\\\   /|    GPU: NVIDIA A100-SXM4-40GB. Max memory: 39.564 GB. Platform = Linux.\n","O^O/ \\_/ \\    Pytorch: 2.2.1+cu121. CUDA = 8.0. CUDA Toolkit = 12.1.\n","\\        /    Bfloat16 = TRUE. Xformers = 0.0.25. FA = False.\n"," \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n","[INFO|configuration_utils.py:726] 2024-05-17 13:35:33,015 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--unsloth--Phi-3-mini-4k-instruct-bnb-4bit/snapshots/1d9acd8f0e086359470add802aae229331797163/config.json\n","[INFO|configuration_utils.py:789] 2024-05-17 13:35:33,016 >> Model config MistralConfig {\n","  \"_name_or_path\": \"unsloth/Phi-3-mini-4k-instruct-bnb-4bit\",\n","  \"architectures\": [\n","    \"MistralForCausalLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 1,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"mistral\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"pad_token_id\": 32000,\n","  \"quantization_config\": {\n","    \"_load_in_4bit\": true,\n","    \"_load_in_8bit\": false,\n","    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n","    \"bnb_4bit_quant_storage\": \"uint8\",\n","    \"bnb_4bit_quant_type\": \"nf4\",\n","    \"bnb_4bit_use_double_quant\": true,\n","    \"llm_int8_enable_fp32_cpu_offload\": false,\n","    \"llm_int8_has_fp16_weight\": false,\n","    \"llm_int8_skip_modules\": null,\n","    \"llm_int8_threshold\": 6.0,\n","    \"load_in_4bit\": true,\n","    \"load_in_8bit\": false,\n","    \"quant_method\": \"bitsandbytes\"\n","  },\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2048,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.40.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","[INFO|configuration_utils.py:726] 2024-05-17 13:35:33,162 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--unsloth--Phi-3-mini-4k-instruct-bnb-4bit/snapshots/1d9acd8f0e086359470add802aae229331797163/config.json\n","[INFO|configuration_utils.py:789] 2024-05-17 13:35:33,163 >> Model config MistralConfig {\n","  \"_name_or_path\": \"unsloth/Phi-3-mini-4k-instruct-bnb-4bit\",\n","  \"architectures\": [\n","    \"MistralForCausalLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 1,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"mistral\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"pad_token_id\": 32000,\n","  \"quantization_config\": {\n","    \"_load_in_4bit\": true,\n","    \"_load_in_8bit\": false,\n","    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n","    \"bnb_4bit_quant_storage\": \"uint8\",\n","    \"bnb_4bit_quant_type\": \"nf4\",\n","    \"bnb_4bit_use_double_quant\": true,\n","    \"llm_int8_enable_fp32_cpu_offload\": false,\n","    \"llm_int8_has_fp16_weight\": false,\n","    \"llm_int8_skip_modules\": null,\n","    \"llm_int8_threshold\": 6.0,\n","    \"load_in_4bit\": true,\n","    \"load_in_8bit\": false,\n","    \"quant_method\": \"bitsandbytes\"\n","  },\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2048,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"float16\",\n","  \"transformers_version\": \"4.40.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","model.safetensors: 100% 2.26G/2.26G [00:08<00:00, 274MB/s]\n","[INFO|modeling_utils.py:3429] 2024-05-17 13:35:41,641 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--unsloth--Phi-3-mini-4k-instruct-bnb-4bit/snapshots/1d9acd8f0e086359470add802aae229331797163/model.safetensors\n","[INFO|modeling_utils.py:1494] 2024-05-17 13:35:41,687 >> Instantiating MistralForCausalLM model under default dtype torch.float16.\n","[INFO|configuration_utils.py:928] 2024-05-17 13:35:41,693 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 1,\n","  \"eos_token_id\": 32000,\n","  \"pad_token_id\": 32000\n","}\n","\n","[INFO|modeling_utils.py:4170] 2024-05-17 13:35:43,655 >> All model checkpoint weights were used when initializing MistralForCausalLM.\n","\n","[INFO|modeling_utils.py:4178] 2024-05-17 13:35:43,655 >> All the weights of MistralForCausalLM were initialized from the model checkpoint at unsloth/Phi-3-mini-4k-instruct-bnb-4bit.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use MistralForCausalLM for predictions without further training.\n","generation_config.json: 100% 140/140 [00:00<00:00, 1.15MB/s]\n","[INFO|configuration_utils.py:883] 2024-05-17 13:35:43,766 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--unsloth--Phi-3-mini-4k-instruct-bnb-4bit/snapshots/1d9acd8f0e086359470add802aae229331797163/generation_config.json\n","[INFO|configuration_utils.py:928] 2024-05-17 13:35:43,767 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 1,\n","  \"eos_token_id\": 32000,\n","  \"pad_token_id\": 32000\n","}\n","\n","tokenizer_config.json: 100% 3.17k/3.17k [00:00<00:00, 26.7MB/s]\n","tokenizer.model: 100% 500k/500k [00:00<00:00, 436MB/s]\n","added_tokens.json: 100% 293/293 [00:00<00:00, 3.03MB/s]\n","special_tokens_map.json: 100% 571/571 [00:00<00:00, 5.69MB/s]\n","tokenizer.json: 100% 1.84M/1.84M [00:00<00:00, 23.9MB/s]\n","[INFO|tokenization_utils_base.py:2087] 2024-05-17 13:35:44,594 >> loading file tokenizer.model from cache at huggingface_tokenizers_cache/models--unsloth--Phi-3-mini-4k-instruct-bnb-4bit/snapshots/1d9acd8f0e086359470add802aae229331797163/tokenizer.model\n","[INFO|tokenization_utils_base.py:2087] 2024-05-17 13:35:44,595 >> loading file added_tokens.json from cache at huggingface_tokenizers_cache/models--unsloth--Phi-3-mini-4k-instruct-bnb-4bit/snapshots/1d9acd8f0e086359470add802aae229331797163/added_tokens.json\n","[INFO|tokenization_utils_base.py:2087] 2024-05-17 13:35:44,595 >> loading file special_tokens_map.json from cache at huggingface_tokenizers_cache/models--unsloth--Phi-3-mini-4k-instruct-bnb-4bit/snapshots/1d9acd8f0e086359470add802aae229331797163/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2087] 2024-05-17 13:35:44,595 >> loading file tokenizer_config.json from cache at huggingface_tokenizers_cache/models--unsloth--Phi-3-mini-4k-instruct-bnb-4bit/snapshots/1d9acd8f0e086359470add802aae229331797163/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2087] 2024-05-17 13:35:44,595 >> loading file tokenizer.json from cache at huggingface_tokenizers_cache/models--unsloth--Phi-3-mini-4k-instruct-bnb-4bit/snapshots/1d9acd8f0e086359470add802aae229331797163/tokenizer.json\n","[WARNING|logging.py:314] 2024-05-17 13:35:44,676 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","[INFO|tokenization_utils_base.py:2087] 2024-05-17 13:35:44,727 >> loading file tokenizer.model from cache at huggingface_tokenizers_cache/models--unsloth--Phi-3-mini-4k-instruct-bnb-4bit/snapshots/1d9acd8f0e086359470add802aae229331797163/tokenizer.model\n","[INFO|tokenization_utils_base.py:2087] 2024-05-17 13:35:44,727 >> loading file tokenizer.json from cache at huggingface_tokenizers_cache/models--unsloth--Phi-3-mini-4k-instruct-bnb-4bit/snapshots/1d9acd8f0e086359470add802aae229331797163/tokenizer.json\n","[INFO|tokenization_utils_base.py:2087] 2024-05-17 13:35:44,727 >> loading file added_tokens.json from cache at huggingface_tokenizers_cache/models--unsloth--Phi-3-mini-4k-instruct-bnb-4bit/snapshots/1d9acd8f0e086359470add802aae229331797163/added_tokens.json\n","[INFO|tokenization_utils_base.py:2087] 2024-05-17 13:35:44,727 >> loading file special_tokens_map.json from cache at huggingface_tokenizers_cache/models--unsloth--Phi-3-mini-4k-instruct-bnb-4bit/snapshots/1d9acd8f0e086359470add802aae229331797163/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2087] 2024-05-17 13:35:44,727 >> loading file tokenizer_config.json from cache at huggingface_tokenizers_cache/models--unsloth--Phi-3-mini-4k-instruct-bnb-4bit/snapshots/1d9acd8f0e086359470add802aae229331797163/tokenizer_config.json\n","[WARNING|logging.py:314] 2024-05-17 13:35:44,786 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","05/17/2024 13:35:45 - INFO - llamafactory.model.utils.checkpointing - Gradient checkpointing enabled.\n","05/17/2024 13:35:45 - INFO - llamafactory.model.adapter - Upcasting trainable params to float32.\n","05/17/2024 13:35:45 - INFO - llamafactory.model.adapter - Fine-tuning method: LoRA\n","05/17/2024 13:35:45 - INFO - llamafactory.model.utils.misc - Found linear modules: v_proj,k_proj,down_proj,up_proj,gate_proj,q_proj,o_proj\n","[WARNING|logging.py:329] 2024-05-17 13:35:46,103 >> Unsloth 2024.5 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n","05/17/2024 13:35:46 - INFO - llamafactory.model.loader - trainable params: 14942208 || all params: 3836021760 || trainable%: 0.3895\n","[INFO|trainer.py:626] 2024-05-17 13:35:46,138 >> Using auto half precision backend\n","05/17/2024 13:35:46 - INFO - llamafactory.train.utils - Using LoRA+ optimizer with loraplus lr ratio 16.00.\n","[WARNING|logging.py:329] 2024-05-17 13:35:46,509 >> ==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n","   \\\\   /|    Num examples = 2,180 | Num Epochs = 5\n","O^O/ \\_/ \\    Batch size per device = 4 | Gradient Accumulation steps = 4\n","\\        /    Total batch size = 16 | Total steps = 680\n"," \"-____-\"     Number of trainable parameters = 14,942,208\n","{'loss': 0.529, 'grad_norm': 0.17927151918411255, 'learning_rate': 7.3529411764705884e-06, 'epoch': 0.07}\n","{'loss': 0.4055, 'grad_norm': 0.16543690860271454, 'learning_rate': 1.4705882352941177e-05, 'epoch': 0.15}\n","{'loss': 0.2493, 'grad_norm': 0.123043492436409, 'learning_rate': 2.2058823529411766e-05, 'epoch': 0.22}\n","{'loss': 0.1474, 'grad_norm': 0.11014725267887115, 'learning_rate': 2.9411764705882354e-05, 'epoch': 0.29}\n","{'loss': 0.1252, 'grad_norm': 0.0723407045006752, 'learning_rate': 3.6764705882352945e-05, 'epoch': 0.37}\n","{'loss': 0.1096, 'grad_norm': 0.05429458990693092, 'learning_rate': 4.411764705882353e-05, 'epoch': 0.44}\n","{'loss': 0.1029, 'grad_norm': 0.10908220708370209, 'learning_rate': 4.999868246217933e-05, 'epoch': 0.51}\n","{'loss': 0.0971, 'grad_norm': 0.05811941623687744, 'learning_rate': 4.995258321842611e-05, 'epoch': 0.59}\n","{'loss': 0.093, 'grad_norm': 0.055332206189632416, 'learning_rate': 4.984074589033044e-05, 'epoch': 0.66}\n","{'loss': 0.0932, 'grad_norm': 0.06539313495159149, 'learning_rate': 4.966346511559149e-05, 'epoch': 0.73}\n","{'loss': 0.0905, 'grad_norm': 0.07125844061374664, 'learning_rate': 4.942120794399002e-05, 'epoch': 0.81}\n","{'loss': 0.0868, 'grad_norm': 0.0517444834113121, 'learning_rate': 4.911461260693638e-05, 'epoch': 0.88}\n","{'loss': 0.0855, 'grad_norm': 0.07167840003967285, 'learning_rate': 4.874448683603695e-05, 'epoch': 0.95}\n","{'loss': 0.0855, 'grad_norm': 0.052687231451272964, 'learning_rate': 4.8311805735108894e-05, 'epoch': 1.03}\n","{'loss': 0.079, 'grad_norm': 0.06744056940078735, 'learning_rate': 4.7817709211249515e-05, 'epoch': 1.1}\n","{'loss': 0.0783, 'grad_norm': 0.05080832168459892, 'learning_rate': 4.726349897172791e-05, 'epoch': 1.17}\n","{'loss': 0.076, 'grad_norm': 0.053575001657009125, 'learning_rate': 4.665063509461097e-05, 'epoch': 1.25}\n","{'loss': 0.0784, 'grad_norm': 0.06616780906915665, 'learning_rate': 4.598073218215817e-05, 'epoch': 1.32}\n","{'loss': 0.0776, 'grad_norm': 0.06135636940598488, 'learning_rate': 4.525555510711934e-05, 'epoch': 1.39}\n","{'loss': 0.079, 'grad_norm': 0.10528408735990524, 'learning_rate': 4.447701436314176e-05, 'epoch': 1.47}\n","{'loss': 0.0746, 'grad_norm': 0.06095496565103531, 'learning_rate': 4.3647161031536085e-05, 'epoch': 1.54}\n","{'loss': 0.0761, 'grad_norm': 0.07047101855278015, 'learning_rate': 4.276818137766118e-05, 'epoch': 1.61}\n","{'loss': 0.0766, 'grad_norm': 0.05998371168971062, 'learning_rate': 4.184239109116393e-05, 'epoch': 1.69}\n","{'loss': 0.0728, 'grad_norm': 0.05860224366188049, 'learning_rate': 4.0872229185248075e-05, 'epoch': 1.76}\n","{'loss': 0.0772, 'grad_norm': 0.07709542661905289, 'learning_rate': 3.986025157104467e-05, 'epoch': 1.83}\n","{'loss': 0.0742, 'grad_norm': 0.06249867007136345, 'learning_rate': 3.880912432401265e-05, 'epoch': 1.91}\n","{'loss': 0.0704, 'grad_norm': 0.07946963608264923, 'learning_rate': 3.7721616660109125e-05, 'epoch': 1.98}\n","{'loss': 0.0611, 'grad_norm': 0.07169950753450394, 'learning_rate': 3.6600593640234086e-05, 'epoch': 2.06}\n","{'loss': 0.0602, 'grad_norm': 0.07508333772420883, 'learning_rate': 3.544900862216959e-05, 'epoch': 2.13}\n","{'loss': 0.0623, 'grad_norm': 0.07115747034549713, 'learning_rate': 3.426989547989902e-05, 'epoch': 2.2}\n","{'loss': 0.061, 'grad_norm': 0.12122476100921631, 'learning_rate': 3.3066360610804874e-05, 'epoch': 2.28}\n","{'loss': 0.0622, 'grad_norm': 0.05954838544130325, 'learning_rate': 3.1841574751802076e-05, 'epoch': 2.35}\n","{'loss': 0.0623, 'grad_norm': 0.05024479329586029, 'learning_rate': 3.059876462596758e-05, 'epoch': 2.42}\n","{'loss': 0.063, 'grad_norm': 0.05202709510922432, 'learning_rate': 2.9341204441673266e-05, 'epoch': 2.5}\n","{'loss': 0.0623, 'grad_norm': 0.07225686311721802, 'learning_rate': 2.8072207266617855e-05, 'epoch': 2.57}\n","{'loss': 0.0615, 'grad_norm': 0.06583009660243988, 'learning_rate': 2.679511629948319e-05, 'epoch': 2.64}\n","{'loss': 0.0592, 'grad_norm': 0.06412269175052643, 'learning_rate': 2.5513296062209763e-05, 'epoch': 2.72}\n","{'loss': 0.0611, 'grad_norm': 0.08951922506093979, 'learning_rate': 2.4230123536095748e-05, 'epoch': 2.79}\n","{'loss': 0.06, 'grad_norm': 0.05947292968630791, 'learning_rate': 2.2948979265071564e-05, 'epoch': 2.86}\n","{'loss': 0.0607, 'grad_norm': 0.06603178381919861, 'learning_rate': 2.1673238449588668e-05, 'epoch': 2.94}\n","{'loss': 0.0612, 'grad_norm': 0.059689849615097046, 'learning_rate': 2.0406262054585738e-05, 'epoch': 3.01}\n","{'loss': 0.0485, 'grad_norm': 0.08330952376127243, 'learning_rate': 1.9151387954958794e-05, 'epoch': 3.08}\n","{'loss': 0.0484, 'grad_norm': 0.09111787378787994, 'learning_rate': 1.791192214186223e-05, 'epoch': 3.16}\n","{'loss': 0.0483, 'grad_norm': 0.0778060257434845, 'learning_rate': 1.6691130013008514e-05, 'epoch': 3.23}\n","{'loss': 0.0482, 'grad_norm': 0.0767299085855484, 'learning_rate': 1.549222776991186e-05, 'epoch': 3.3}\n","{'loss': 0.047, 'grad_norm': 0.07214614003896713, 'learning_rate': 1.4318373944740484e-05, 'epoch': 3.38}\n","{'loss': 0.0488, 'grad_norm': 0.0811515748500824, 'learning_rate': 1.3172661079099752e-05, 'epoch': 3.45}\n","{'loss': 0.0472, 'grad_norm': 0.06238763779401779, 'learning_rate': 1.205810757666894e-05, 'epoch': 3.52}\n","{'loss': 0.0507, 'grad_norm': 0.0692637637257576, 'learning_rate': 1.097764975115576e-05, 'epoch': 3.6}\n","{'loss': 0.049, 'grad_norm': 0.06420005112886429, 'learning_rate': 9.934134090518593e-06, 'epoch': 3.67}\n","{'loss': 0.049, 'grad_norm': 0.05762230604887009, 'learning_rate': 8.930309757836517e-06, 'epoch': 3.74}\n","{'loss': 0.0477, 'grad_norm': 0.07587628811597824, 'learning_rate': 7.968821348583644e-06, 'epoch': 3.82}\n","{'loss': 0.0479, 'grad_norm': 0.07011479884386063, 'learning_rate': 7.0522019233889545e-06, 'epoch': 3.89}\n","{'loss': 0.0481, 'grad_norm': 0.06925549358129501, 'learning_rate': 6.182866334636889e-06, 'epoch': 3.96}\n","{'loss': 0.0416, 'grad_norm': 0.05421201139688492, 'learning_rate': 5.363104864490034e-06, 'epoch': 4.04}\n","{'loss': 0.0406, 'grad_norm': 0.06120169907808304, 'learning_rate': 4.5950771910944605e-06, 'epoch': 4.11}\n","{'loss': 0.0382, 'grad_norm': 0.0633104145526886, 'learning_rate': 3.880806698864087e-06, 'epoch': 4.18}\n","{'loss': 0.0409, 'grad_norm': 0.08253046125173569, 'learning_rate': 3.222175147833556e-06, 'epoch': 4.26}\n","{'loss': 0.0395, 'grad_norm': 0.07554561644792557, 'learning_rate': 2.6209177161234445e-06, 'epoch': 4.33}\n","{'loss': 0.04, 'grad_norm': 0.06566306948661804, 'learning_rate': 2.0786184285784297e-06, 'epoch': 4.4}\n","{'loss': 0.0379, 'grad_norm': 0.08962231129407883, 'learning_rate': 1.5967059836219044e-06, 'epoch': 4.48}\n","{'loss': 0.0394, 'grad_norm': 0.06829952448606491, 'learning_rate': 1.1764499893210878e-06, 'epoch': 4.55}\n","{'loss': 0.0398, 'grad_norm': 0.07079963386058807, 'learning_rate': 8.189576185789638e-07, 'epoch': 4.62}\n","{'loss': 0.0394, 'grad_norm': 0.0671505331993103, 'learning_rate': 5.25170692264887e-07, 'epoch': 4.7}\n","{'loss': 0.0391, 'grad_norm': 0.06825027614831924, 'learning_rate': 2.958631979685156e-07, 'epoch': 4.77}\n","{'loss': 0.0378, 'grad_norm': 0.0640692487359047, 'learning_rate': 1.3163925091384533e-07, 'epoch': 4.84}\n","{'loss': 0.0395, 'grad_norm': 0.07574713975191116, 'learning_rate': 3.293150240547549e-08, 'epoch': 4.92}\n","{'loss': 0.0399, 'grad_norm': 0.07215394824743271, 'learning_rate': 0.0, 'epoch': 4.99}\n","100% 680/680 [38:18<00:00,  3.37s/it][INFO|<string>:474] 2024-05-17 14:14:04,982 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","{'train_runtime': 2298.4727, 'train_samples_per_second': 4.742, 'train_steps_per_second': 0.296, 'train_loss': 0.0784020784584915, 'epoch': 4.99}\n","100% 680/680 [38:18<00:00,  3.38s/it]\n","[INFO|trainer.py:3305] 2024-05-17 14:14:04,984 >> Saving model checkpoint to phi_lora\n","[INFO|configuration_utils.py:726] 2024-05-17 14:14:05,237 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--unsloth--Phi-3-mini-4k-instruct-bnb-4bit/snapshots/1d9acd8f0e086359470add802aae229331797163/config.json\n","[INFO|configuration_utils.py:789] 2024-05-17 14:14:05,238 >> Model config MistralConfig {\n","  \"_name_or_path\": \"unsloth/Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"MistralForCausalLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 1,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"mistral\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"pad_token_id\": 32000,\n","  \"quantization_config\": {\n","    \"_load_in_4bit\": true,\n","    \"_load_in_8bit\": false,\n","    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n","    \"bnb_4bit_quant_storage\": \"uint8\",\n","    \"bnb_4bit_quant_type\": \"nf4\",\n","    \"bnb_4bit_use_double_quant\": true,\n","    \"llm_int8_enable_fp32_cpu_offload\": false,\n","    \"llm_int8_has_fp16_weight\": false,\n","    \"llm_int8_skip_modules\": null,\n","    \"llm_int8_threshold\": 6.0,\n","    \"load_in_4bit\": true,\n","    \"load_in_8bit\": false,\n","    \"quant_method\": \"bitsandbytes\"\n","  },\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2048,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.40.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","[INFO|tokenization_utils_base.py:2488] 2024-05-17 14:14:05,394 >> tokenizer config file saved in phi_lora/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2497] 2024-05-17 14:14:05,394 >> Special tokens file saved in phi_lora/special_tokens_map.json\n","***** train metrics *****\n","  epoch                    =      4.9908\n","  total_flos               = 232682591GF\n","  train_loss               =      0.0784\n","  train_runtime            =  0:38:18.47\n","  train_samples_per_second =       4.742\n","  train_steps_per_second   =       0.296\n","[INFO|modelcard.py:450] 2024-05-17 14:14:05,428 >> Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-42d18f957c4c>\u001b[0m in \u001b[0;36m<cell line: 41>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mlogin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'HF_WRITE_TOKEN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/LLaMA-Factory'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/userdata.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0;31m# thread-safe.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0m_userdata_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     resp = _message.blocking_request(\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;34m'GetSecret'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'key'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import json\n","\n","args = dict(\n","  stage=\"sft\",                        # do supervised fine-tuning\n","  do_train=True,\n","  model_name_or_path=hf_base_model_id, # model name specified in Configuration\n","  dataset=\"identity\",             # use identity dataset\n","  template=llamafactory_template_name,       # prompt template specified in Configuration\n","  finetuning_type=\"lora\",                   # use LoRA adapters to save memory\n","  lora_target=\"all\",                     # attach LoRA adapters to all linear layers\n","  output_dir=adapter_name,                  # the path to save LoRA adapters\n","  per_device_train_batch_size=4,               # the batch size\n","  gradient_accumulation_steps=4,               # the gradient accumulation steps\n","  lr_scheduler_type=\"cosine\",                 # use cosine learning rate scheduler\n","  logging_steps=10,                      # log every 10 steps\n","  warmup_ratio=0.1,                      # use warmup scheduler\n","  save_steps=1000,                      # save checkpoint every 1000 steps\n","  learning_rate=5e-5,                     # the learning rate\n","  num_train_epochs=epochs,                    # the epochs of training\n","  max_samples=2500,                      # use 500 examples in each dataset\n","  max_grad_norm=1.0,                     # clip gradient norm to 1.0\n","  quantization_bit=4,                     # use 4-bit QLoRA\n","  loraplus_lr_ratio=16.0,                   # use LoRA+ algorithm with lambda=16.0\n","  use_unsloth=True,                      # use UnslothAI's LoRA optimization for 2x faster training\n","  fp16=True,                         # use float16 mixed precision training\n","  overwrite_output_dir=True\n",")\n","\n","json.dump(args, open(\"train.json\", \"w\", encoding=\"utf-8\"), indent=2)\n","\n","%cd /content/LLaMA-Factory/\n","\n","!llamafactory-cli train train.json\n","\n","# Upload the data to Huggingface\n","# IMPORTANT: You need to set HF_WRITE_TOKEN to a write token of Huggingface for this to work!\n","from google.colab import userdata\n","from huggingface_hub import login\n","import json\n","\n","login(token=userdata.get('HF_WRITE_TOKEN'))\n","\n","%cd /content/LLaMA-Factory\n","args = dict(\n","  model_name_or_path=hf_base_model_id,             # the hugging face model id\n","  adapter_name_or_path=adapter_name,            # load the saved LoRA adapters\n","  template=llamafactory_template_name,          # same to the one in training\n","  finetuning_type=\"lora\",                  # same to the one in training\n","  export_dir=saved_merged_model_path,              # the path to save the merged model\n","  export_size=2,                       # the file shard size (in GB) of the merged model\n","  export_device=\"cpu\",                    # the device used in export, can be chosen from `cpu` and `cuda`\n","  export_hub_model_id=hf_finetuned_model_id      # the Hugging Face hub ID to upload model\n",")\n","\n","json.dump(args, open(\"merge_file.json\", \"w\", encoding=\"utf-8\"), indent=2)\n","!llamafactory-cli export merge_file.json\n","\n","# Upload the adapter to Google Drive\n","directory_to_zip = adapter_name  # Change this to your directory\n","zip_output_path = f'{adapter_name}.zip'  # Change this to your desired output zip file name\n","drive_zip_output_path = f'/content/drive/MyDrive/{adapter_name}.zip'  # Change this to your desired location on Google Drive\n","\n","!zip -r $zip_output_path $directory_to_zip\n","!mv $zip_output_path $drive_zip_output_path"]},{"cell_type":"markdown","metadata":{"id":"kTESHaFvbNTr"},"source":["### Login Huggingface"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3069,"status":"ok","timestamp":1715702960818,"user":{"displayName":"Bertil Muth","userId":"02558266373806387996"},"user_tz":-120},"id":"mcNcHcA4bf4Z","outputId":"236f6eb1-0f43-40b1-904e-50b413cfca32"},"outputs":[{"name":"stdout","output_type":"stream","text":["The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n","Token is valid (permission: write).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]}],"source":["# IMPORTANT: You need to set HF_WRITE_TOKEN to a write token of Huggingface for this to work!\n","from google.colab import userdata\n","from huggingface_hub import login\n","\n","login(token=userdata.get('HF_WRITE_TOKEN'))\n"]},{"cell_type":"markdown","metadata":{"id":"psBQveagZ2jN"},"source":["### Upload finetuned model to Huggingface"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":147823,"status":"ok","timestamp":1715958316094,"user":{"displayName":"Bertil Muth","userId":"02558266373806387996"},"user_tz":-120},"id":"IMojogHbaOZF","outputId":"8fb9ff95-ac0a-4bdf-f381-5b342df8c8f2"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/LLaMA-Factory\n","2024-05-17 15:02:53.718400: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-05-17 15:02:53.718449: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-05-17 15:02:53.720191: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-05-17 15:02:55.021357: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","[INFO|tokenization_utils_base.py:2087] 2024-05-17 15:02:58,847 >> loading file tokenizer.model from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/8f5f3a02ec472594e949c39f8e38c7be8d983bcd/tokenizer.model\n","[INFO|tokenization_utils_base.py:2087] 2024-05-17 15:02:58,847 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/8f5f3a02ec472594e949c39f8e38c7be8d983bcd/tokenizer.json\n","[INFO|tokenization_utils_base.py:2087] 2024-05-17 15:02:58,847 >> loading file added_tokens.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/8f5f3a02ec472594e949c39f8e38c7be8d983bcd/added_tokens.json\n","[INFO|tokenization_utils_base.py:2087] 2024-05-17 15:02:58,847 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/8f5f3a02ec472594e949c39f8e38c7be8d983bcd/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2087] 2024-05-17 15:02:58,847 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/8f5f3a02ec472594e949c39f8e38c7be8d983bcd/tokenizer_config.json\n","[WARNING|logging.py:314] 2024-05-17 15:02:58,919 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","05/17/2024 15:02:58 - INFO - llamafactory.data.template - Replace eos token: <|end|>\n","05/17/2024 15:02:58 - WARNING - llamafactory.data.template - New tokens have been added, make sure `resize_vocab` is True.\n","[INFO|configuration_utils.py:726] 2024-05-17 15:02:58,973 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/8f5f3a02ec472594e949c39f8e38c7be8d983bcd/config.json\n","[INFO|configuration_utils.py:726] 2024-05-17 15:02:59,080 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/8f5f3a02ec472594e949c39f8e38c7be8d983bcd/config.json\n","[INFO|configuration_utils.py:789] 2024-05-17 15:02:59,081 >> Model config Phi3Config {\n","  \"_name_or_path\": \"microsoft/Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"microsoft/Phi-3-mini-4k-instruct--configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-4k-instruct--modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.40.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","05/17/2024 15:02:59 - INFO - llamafactory.model.patcher - Using KV cache for faster generation.\n","`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n","Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n","[INFO|modeling_utils.py:3429] 2024-05-17 15:02:59,175 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/8f5f3a02ec472594e949c39f8e38c7be8d983bcd/model.safetensors.index.json\n","[INFO|modeling_utils.py:1494] 2024-05-17 15:02:59,177 >> Instantiating Phi3ForCausalLM model under default dtype torch.bfloat16.\n","[INFO|configuration_utils.py:928] 2024-05-17 15:02:59,178 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 1,\n","  \"eos_token_id\": 32000,\n","  \"pad_token_id\": 32000\n","}\n","\n","Loading checkpoint shards: 100% 2/2 [00:00<00:00,  3.32it/s]\n","[INFO|modeling_utils.py:4170] 2024-05-17 15:02:59,842 >> All model checkpoint weights were used when initializing Phi3ForCausalLM.\n","\n","[INFO|modeling_utils.py:4178] 2024-05-17 15:02:59,842 >> All the weights of Phi3ForCausalLM were initialized from the model checkpoint at microsoft/Phi-3-mini-4k-instruct.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use Phi3ForCausalLM for predictions without further training.\n","[INFO|configuration_utils.py:883] 2024-05-17 15:02:59,896 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/8f5f3a02ec472594e949c39f8e38c7be8d983bcd/generation_config.json\n","[INFO|configuration_utils.py:928] 2024-05-17 15:02:59,897 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 1,\n","  \"eos_token_id\": [\n","    32000,\n","    32001,\n","    32007\n","  ],\n","  \"pad_token_id\": 32000\n","}\n","\n","05/17/2024 15:02:59 - INFO - llamafactory.model.utils.attention - Using vanilla attention implementation.\n","05/17/2024 15:02:59 - INFO - llamafactory.model.adapter - Upcasting trainable params to float32.\n","05/17/2024 15:02:59 - INFO - llamafactory.model.adapter - Fine-tuning method: LoRA\n","05/17/2024 15:03:02 - INFO - llamafactory.model.adapter - Merged 1 adapter(s).\n","05/17/2024 15:03:02 - INFO - llamafactory.model.adapter - Loaded adapter(s): phi_lora\n","05/17/2024 15:03:02 - INFO - llamafactory.model.loader - all params: 3821079552\n","[INFO|configuration_utils.py:471] 2024-05-17 15:03:02,218 >> Configuration saved in phi_lora_merged/config.json\n","[INFO|configuration_utils.py:697] 2024-05-17 15:03:02,218 >> Configuration saved in phi_lora_merged/generation_config.json\n","[INFO|modeling_utils.py:2598] 2024-05-17 15:03:20,576 >> The model is bigger than the maximum size per checkpoint (2GB) and is going to be split in 4 checkpoint shards. You can find where each parameters has been saved in the index located at phi_lora_merged/model.safetensors.index.json.\n","[INFO|configuration_utils.py:471] 2024-05-17 15:03:20,701 >> Configuration saved in /tmp/tmp7we82phu/config.json\n","[INFO|configuration_utils.py:697] 2024-05-17 15:03:20,701 >> Configuration saved in /tmp/tmp7we82phu/generation_config.json\n","[INFO|modeling_utils.py:2598] 2024-05-17 15:03:42,735 >> The model is bigger than the maximum size per checkpoint (2GB) and is going to be split in 4 checkpoint shards. You can find where each parameters has been saved in the index located at /tmp/tmp7we82phu/model.safetensors.index.json.\n","[INFO|hub.py:757] 2024-05-17 15:04:04,418 >> Uploading the following files to bertilmuth/phi-3-mini-4k: model-00003-of-00004.safetensors,generation_config.json,config.json,model-00004-of-00004.safetensors,model.safetensors.index.json,README.md,modeling_phi3.py,model-00001-of-00004.safetensors,model-00002-of-00004.safetensors,configuration_phi3.py\n","model-00003-of-00004.safetensors:   0% 0.00/1.98G [00:00<?, ?B/s]\n","model-00004-of-00004.safetensors:   0% 0.00/1.76G [00:00<?, ?B/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:   0% 0.00/1.96G [00:00<?, ?B/s]\u001b[A\u001b[A\n","\n","\n","Upload 4 LFS files:   0% 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:   0% 0.00/1.94G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:   0% 16.4k/1.76G [00:00<6:05:50, 80.3kB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:   0% 16.4k/1.98G [00:00<7:12:22, 76.4kB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:   0% 16.4k/1.94G [00:00<6:55:38, 77.7kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:   0% 5.93M/1.76G [00:00<01:17, 22.6MB/s]  \u001b[A\n","\n","model-00003-of-00004.safetensors:   0% 4.82M/1.98G [00:00<01:55, 17.1MB/s]  \n","\n","\n","\n","model-00002-of-00004.safetensors:   0% 4.42M/1.94G [00:00<02:08, 15.1MB/s]  \u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:   0% 8.18M/1.98G [00:00<01:28, 22.3MB/s]\n","model-00004-of-00004.safetensors:   1% 10.7M/1.76G [00:00<01:01, 28.7MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:   0% 6.23M/1.94G [00:00<02:01, 15.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:   1% 11.3M/1.98G [00:00<01:20, 24.4MB/s]\n","model-00004-of-00004.safetensors:   1% 15.6M/1.76G [00:00<00:51, 33.8MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:   0% 8.00M/1.94G [00:00<02:01, 15.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:   1% 14.6M/1.98G [00:00<01:13, 26.6MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:   1% 10.8M/1.94G [00:00<01:48, 17.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:   1% 19.4M/1.76G [00:00<01:06, 26.3MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:   1% 17.5M/1.98G [00:00<01:29, 22.0MB/s]\n","model-00004-of-00004.safetensors:   1% 26.3M/1.76G [00:00<00:51, 33.9MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:   1% 22.2M/1.96G [00:00<01:12, 26.9MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:   1% 22.2M/1.98G [00:00<01:15, 26.1MB/s]\n","model-00004-of-00004.safetensors:   2% 30.7M/1.76G [00:01<00:49, 34.8MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:   1% 25.5M/1.98G [00:01<01:12, 27.0MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:   2% 30.4M/1.98G [00:01<01:03, 30.5MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:   1% 24.7M/1.94G [00:01<01:16, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:   2% 34.5M/1.76G [00:01<01:01, 28.2MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:   2% 29.6M/1.94G [00:01<01:02, 30.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:   2% 32.0M/1.96G [00:01<01:21, 23.5MB/s]\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:   2% 33.5M/1.98G [00:01<01:16, 25.6MB/s]\n","model-00004-of-00004.safetensors:   3% 45.5M/1.76G [00:01<00:44, 38.3MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:   2% 41.2M/1.98G [00:01<01:03, 30.8MB/s]\n","\n","model-00001-of-00004.safetensors:   2% 45.7M/1.96G [00:01<00:53, 35.5MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:   2% 32.8M/1.94G [00:01<01:32, 20.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:   2% 46.0M/1.98G [00:01<00:54, 35.2MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:   2% 38.3M/1.94G [00:01<01:17, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:   3% 55.2M/1.76G [00:01<00:53, 32.1MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:   3% 49.6M/1.96G [00:01<01:07, 28.1MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:   2% 42.2M/1.94G [00:01<01:10, 27.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:   3% 49.8M/1.98G [00:01<01:15, 25.4MB/s]\n","\n","model-00001-of-00004.safetensors:   3% 55.4M/1.96G [00:01<01:00, 31.4MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:   3% 52.8M/1.98G [00:02<01:17, 24.9MB/s]\n","\n","model-00001-of-00004.safetensors:   3% 59.0M/1.96G [00:02<00:59, 32.1MB/s]\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:   3% 58.1M/1.98G [00:02<01:02, 31.0MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:   3% 50.2M/1.94G [00:02<01:20, 23.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:   4% 71.6M/1.76G [00:02<00:53, 31.5MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:   3% 64.0M/1.96G [00:02<01:11, 26.6MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:   3% 54.5M/1.94G [00:02<01:11, 26.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:   3% 67.9M/1.96G [00:02<01:06, 28.3MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:   3% 59.3M/1.94G [00:02<01:01, 30.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:   3% 67.9M/1.98G [00:02<01:11, 26.7MB/s]\n","\n","model-00001-of-00004.safetensors:   4% 74.1M/1.96G [00:02<01:00, 31.2MB/s]\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:   4% 74.9M/1.98G [00:02<00:55, 34.4MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:   3% 64.0M/1.94G [00:02<01:18, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:   5% 84.8M/1.76G [00:02<01:00, 27.9MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:   4% 71.0M/1.94G [00:02<01:02, 29.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:   5% 90.0M/1.76G [00:02<00:54, 31.0MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:   4% 80.0M/1.98G [00:03<01:07, 28.0MB/s]\n","\n","model-00001-of-00004.safetensors:   4% 85.0M/1.96G [00:03<01:03, 29.5MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:   4% 83.9M/1.98G [00:03<01:06, 28.5MB/s]\n","\n","model-00001-of-00004.safetensors:   5% 89.5M/1.96G [00:03<00:58, 32.1MB/s]\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:   5% 90.8M/1.98G [00:03<00:53, 35.3MB/s]\n","\n","model-00001-of-00004.safetensors:   5% 94.8M/1.96G [00:03<00:53, 35.0MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:   4% 81.3M/1.94G [00:03<01:10, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:   5% 95.8M/1.98G [00:03<00:49, 37.8MB/s]\n","model-00004-of-00004.safetensors:   6% 106M/1.76G [00:03<00:46, 35.4MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:   5% 87.5M/1.94G [00:03<01:01, 30.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:   5% 98.7M/1.96G [00:03<01:06, 28.0MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:   6% 110M/1.76G [00:03<00:46, 35.3MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:   5% 94.0M/1.94G [00:03<00:54, 33.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:   5% 100M/1.98G [00:03<01:15, 24.8MB/s] \n","model-00004-of-00004.safetensors:   6% 114M/1.76G [00:03<01:00, 27.2MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:   5% 106M/1.98G [00:03<01:01, 30.5MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:   6% 111M/1.98G [00:03<00:54, 34.3MB/s]\n","model-00004-of-00004.safetensors:   7% 120M/1.76G [00:03<00:54, 30.3MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:   5% 101M/1.94G [00:03<01:04, 28.5MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:   6% 115M/1.96G [00:03<00:58, 31.4MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:   7% 125M/1.76G [00:04<00:49, 33.0MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:   6% 115M/1.98G [00:04<01:02, 29.8MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:   6% 119M/1.98G [00:04<01:02, 29.8MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:   6% 110M/1.94G [00:04<01:01, 29.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:   6% 123M/1.96G [00:04<01:00, 30.3MB/s]\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:   6% 123M/1.98G [00:04<01:01, 30.3MB/s]\n","model-00004-of-00004.safetensors:   7% 132M/1.76G [00:04<01:03, 25.8MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:   6% 113M/1.94G [00:04<01:19, 23.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:   7% 128M/1.96G [00:04<01:10, 26.1MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:   8% 139M/1.76G [00:04<00:49, 33.2MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:   6% 119M/1.94G [00:04<01:03, 28.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:   6% 128M/1.98G [00:04<01:12, 25.6MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:   7% 134M/1.98G [00:04<01:00, 30.4MB/s]\n","\n","model-00001-of-00004.safetensors:   7% 137M/1.96G [00:04<00:55, 32.7MB/s]\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:   7% 141M/1.96G [00:04<00:54, 33.3MB/s]\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:   7% 138M/1.98G [00:04<00:58, 31.4MB/s]\n","model-00003-of-00004.safetensors:   7% 143M/1.98G [00:04<00:53, 34.6MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:   7% 130M/1.94G [00:04<01:07, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:   9% 155M/1.76G [00:05<00:46, 34.3MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:   7% 145M/1.96G [00:05<01:15, 24.1MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:   7% 147M/1.98G [00:05<00:59, 30.7MB/s]\n","\n","model-00001-of-00004.safetensors:   8% 148M/1.96G [00:05<01:11, 25.3MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:   8% 150M/1.98G [00:05<01:01, 30.0MB/s]\n","\n","model-00001-of-00004.safetensors:   8% 153M/1.96G [00:05<00:58, 30.8MB/s]\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:   8% 154M/1.98G [00:05<01:02, 29.3MB/s]\n","\n","model-00001-of-00004.safetensors:   8% 158M/1.96G [00:05<00:52, 34.3MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:   8% 159M/1.98G [00:05<00:53, 34.3MB/s]\n","model-00004-of-00004.safetensors:   9% 164M/1.76G [00:05<00:57, 27.7MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:   8% 148M/1.94G [00:05<01:02, 28.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  10% 170M/1.76G [00:05<00:45, 34.7MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:   8% 163M/1.98G [00:05<01:03, 28.5MB/s]\n","model-00004-of-00004.safetensors:  10% 176M/1.76G [00:05<00:40, 38.9MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:   8% 162M/1.96G [00:05<01:15, 23.8MB/s]\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:   8% 168M/1.98G [00:05<01:03, 28.5MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:   8% 160M/1.94G [00:05<00:59, 29.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:   9% 171M/1.96G [00:05<00:58, 30.5MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  10% 180M/1.76G [00:06<00:56, 28.0MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:   9% 176M/1.98G [00:06<00:55, 32.5MB/s]\n","\n","model-00001-of-00004.safetensors:   9% 175M/1.96G [00:06<00:59, 29.9MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  10% 185M/1.76G [00:06<00:51, 30.5MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:   9% 167M/1.94G [00:06<00:57, 30.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:   9% 179M/1.98G [00:06<01:06, 27.3MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:   9% 174M/1.94G [00:06<00:49, 35.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:   9% 183M/1.98G [00:06<01:04, 28.0MB/s]\n","model-00004-of-00004.safetensors:  11% 194M/1.76G [00:06<00:53, 29.6MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:   9% 181M/1.96G [00:06<01:13, 24.1MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  10% 190M/1.98G [00:06<00:49, 36.3MB/s]\n","model-00004-of-00004.safetensors:  11% 200M/1.76G [00:06<00:48, 32.0MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  10% 187M/1.96G [00:06<01:05, 27.1MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:   9% 183M/1.94G [00:06<00:58, 29.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  12% 203M/1.76G [00:06<00:49, 31.8MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:  10% 194M/1.98G [00:06<01:03, 28.0MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:  10% 199M/1.98G [00:06<00:56, 31.4MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  10% 192M/1.94G [00:06<00:50, 34.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:  10% 202M/1.98G [00:06<00:57, 31.2MB/s]\n","model-00004-of-00004.safetensors:  12% 208M/1.76G [00:06<01:03, 24.5MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  10% 196M/1.94G [00:06<00:53, 32.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:  10% 208M/1.98G [00:07<00:49, 35.5MB/s]\n","model-00004-of-00004.safetensors:  12% 212M/1.76G [00:07<00:59, 26.0MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  10% 204M/1.96G [00:07<00:56, 31.2MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  10% 199M/1.94G [00:07<01:02, 27.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  12% 216M/1.76G [00:07<00:54, 28.6MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  11% 207M/1.96G [00:07<00:54, 32.2MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  11% 212M/1.98G [00:07<01:02, 28.5MB/s]\n","model-00004-of-00004.safetensors:  13% 221M/1.76G [00:07<00:45, 33.9MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:  11% 215M/1.98G [00:07<01:05, 27.2MB/s]\n","\n","model-00003-of-00004.safetensors:  11% 222M/1.98G [00:07<00:52, 33.8MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  11% 208M/1.94G [00:07<01:13, 23.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  13% 225M/1.76G [00:07<01:01, 24.8MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  11% 213M/1.94G [00:07<01:00, 28.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  13% 228M/1.76G [00:07<00:59, 25.8MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:  11% 225M/1.98G [00:07<01:04, 27.0MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  11% 218M/1.94G [00:07<00:54, 31.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  13% 234M/1.76G [00:07<00:49, 30.7MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:  12% 229M/1.98G [00:07<01:05, 27.0MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  12% 224M/1.94G [00:07<00:47, 35.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  12% 232M/1.98G [00:08<01:02, 28.2MB/s]\n","\n","model-00001-of-00004.safetensors:  12% 231M/1.96G [00:08<00:55, 30.9MB/s]\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  12% 237M/1.98G [00:08<00:53, 32.5MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  12% 228M/1.94G [00:08<01:05, 26.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  12% 238M/1.96G [00:08<00:48, 35.8MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  14% 247M/1.76G [00:08<00:50, 29.9MB/s]\u001b[A\n","model-00004-of-00004.safetensors:  14% 252M/1.76G [00:08<00:43, 34.7MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  12% 241M/1.98G [00:08<01:08, 25.4MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:  12% 247M/1.98G [00:08<00:55, 31.2MB/s]\n","model-00004-of-00004.safetensors:  15% 256M/1.76G [00:08<00:54, 27.6MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:  13% 255M/1.98G [00:08<00:43, 39.6MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  12% 240M/1.94G [00:08<01:05, 26.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  15% 263M/1.76G [00:08<00:42, 35.1MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  13% 246M/1.96G [00:08<01:11, 23.9MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  13% 246M/1.94G [00:08<00:52, 32.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  15% 267M/1.76G [00:08<00:41, 36.0MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  13% 251M/1.96G [00:08<01:01, 28.0MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  15% 271M/1.76G [00:08<00:40, 37.3MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  13% 250M/1.94G [00:08<00:53, 31.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  13% 256M/1.96G [00:08<00:56, 30.1MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  16% 275M/1.76G [00:09<00:42, 35.3MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  13% 259M/1.96G [00:09<00:59, 28.4MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  16% 284M/1.76G [00:09<00:30, 48.9MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  13% 264M/1.96G [00:09<00:52, 32.1MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  13% 256M/1.94G [00:09<01:06, 25.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  14% 270M/1.96G [00:09<00:42, 39.9MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  14% 263M/1.94G [00:09<00:50, 33.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  16% 290M/1.76G [00:09<00:45, 32.6MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  13% 267M/1.98G [00:09<01:25, 20.0MB/s]\n","\n","model-00001-of-00004.safetensors:  14% 275M/1.96G [00:09<01:12, 23.1MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  14% 272M/1.94G [00:09<01:00, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  17% 306M/1.76G [00:09<00:40, 35.7MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  14% 283M/1.96G [00:09<00:51, 32.4MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  14% 281M/1.94G [00:09<00:48, 34.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  14% 272M/1.98G [00:09<01:27, 19.5MB/s]\n","model-00004-of-00004.safetensors:  18% 316M/1.76G [00:10<00:39, 37.0MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  15% 288M/1.94G [00:10<00:46, 35.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:  14% 278M/1.98G [00:10<01:15, 22.7MB/s]\n","model-00003-of-00004.safetensors:  14% 283M/1.98G [00:10<01:04, 26.3MB/s]\n","\n","model-00001-of-00004.safetensors:  15% 295M/1.96G [00:10<00:51, 32.4MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  15% 292M/1.94G [00:10<00:55, 29.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  15% 303M/1.96G [00:10<00:45, 36.2MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  18% 324M/1.76G [00:10<00:52, 27.5MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  15% 295M/1.94G [00:10<00:59, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  19% 331M/1.76G [00:10<00:43, 33.1MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  15% 288M/1.98G [00:10<01:20, 21.0MB/s]\n","\n","model-00003-of-00004.safetensors:  15% 294M/1.98G [00:10<01:08, 24.5MB/s]\n","\n","model-00003-of-00004.safetensors:  15% 300M/1.98G [00:10<00:54, 30.6MB/s]\n","model-00004-of-00004.safetensors:  19% 336M/1.76G [00:10<00:54, 26.3MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  16% 318M/1.96G [00:10<00:44, 36.8MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  19% 343M/1.76G [00:10<00:43, 32.8MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:  15% 304M/1.98G [00:11<01:11, 23.6MB/s]\n","\n","model-00003-of-00004.safetensors:  16% 313M/1.98G [00:11<00:51, 32.5MB/s]\n","model-00004-of-00004.safetensors:  20% 352M/1.76G [00:11<00:48, 29.0MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  17% 330M/1.98G [00:11<00:39, 41.9MB/s]\n","model-00004-of-00004.safetensors:  21% 373M/1.76G [00:11<00:35, 38.8MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  16% 305M/1.94G [00:11<02:31, 10.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  22% 381M/1.76G [00:11<00:30, 46.0MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  16% 310M/1.94G [00:11<02:01, 13.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:  17% 336M/1.98G [00:11<00:51, 32.0MB/s]\n","\n","model-00003-of-00004.safetensors:  17% 342M/1.98G [00:12<00:46, 35.4MB/s]\n","model-00004-of-00004.safetensors:  22% 387M/1.76G [00:12<00:37, 36.5MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:  18% 349M/1.98G [00:12<00:41, 39.0MB/s]\n","model-00004-of-00004.safetensors:  22% 392M/1.76G [00:12<00:38, 36.0MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  17% 320M/1.94G [00:12<01:30, 17.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  18% 354M/1.96G [00:12<01:00, 26.7MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  22% 397M/1.76G [00:12<00:37, 36.2MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  18% 353M/1.98G [00:12<00:49, 32.8MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  17% 331M/1.94G [00:12<01:05, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:  18% 362M/1.98G [00:12<00:45, 35.9MB/s]\n","model-00004-of-00004.safetensors:  23% 401M/1.76G [00:12<00:49, 27.6MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  19% 365M/1.96G [00:12<00:52, 30.6MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  17% 336M/1.94G [00:12<01:02, 25.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  18% 367M/1.98G [00:12<00:48, 33.3MB/s]\n","model-00004-of-00004.safetensors:  23% 409M/1.76G [00:12<00:41, 32.3MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  19% 368M/1.96G [00:12<01:06, 24.0MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  19% 370M/1.98G [00:12<00:50, 31.8MB/s]\n","\n","model-00003-of-00004.safetensors:  19% 374M/1.98G [00:13<00:51, 31.3MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  18% 343M/1.94G [00:13<01:08, 23.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  24% 416M/1.76G [00:13<00:41, 32.2MB/s]\u001b[A\n","model-00004-of-00004.safetensors:  24% 421M/1.76G [00:13<00:37, 36.2MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  19% 380M/1.96G [00:13<00:50, 31.5MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  19% 379M/1.98G [00:13<00:53, 30.1MB/s]\n","model-00004-of-00004.safetensors:  24% 425M/1.76G [00:13<00:38, 34.5MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  19% 382M/1.98G [00:13<00:53, 30.1MB/s]\n","model-00004-of-00004.safetensors:  24% 429M/1.76G [00:13<00:39, 33.7MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  20% 384M/1.96G [00:13<01:04, 24.3MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  19% 385M/1.98G [00:13<01:03, 25.3MB/s]\n","model-00004-of-00004.safetensors:  25% 433M/1.76G [00:13<00:42, 31.7MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  20% 394M/1.96G [00:13<00:42, 37.1MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  25% 438M/1.76G [00:13<00:37, 35.7MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  20% 391M/1.98G [00:13<00:54, 29.1MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:  20% 395M/1.98G [00:13<00:54, 29.4MB/s]\n","model-00004-of-00004.safetensors:  25% 443M/1.76G [00:13<00:40, 32.5MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:  20% 398M/1.98G [00:13<00:55, 28.8MB/s]\n","model-00004-of-00004.safetensors:  25% 446M/1.76G [00:13<00:40, 32.5MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  19% 369M/1.94G [00:14<01:13, 21.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:  20% 401M/1.98G [00:14<01:09, 22.7MB/s]\n","model-00004-of-00004.safetensors:  26% 450M/1.76G [00:14<00:48, 27.1MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  19% 378M/1.94G [00:14<00:46, 33.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  21% 408M/1.96G [00:14<00:55, 27.7MB/s]\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  20% 405M/1.98G [00:14<00:59, 26.4MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  20% 382M/1.94G [00:14<00:45, 33.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  21% 411M/1.96G [00:14<00:54, 28.2MB/s]\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  21% 408M/1.98G [00:14<00:59, 26.5MB/s]\n","\n","model-00001-of-00004.safetensors:  21% 415M/1.96G [00:14<00:53, 28.6MB/s]\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  21% 412M/1.98G [00:14<00:57, 27.3MB/s]\n","\n","model-00001-of-00004.safetensors:  21% 418M/1.96G [00:14<01:03, 24.4MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  20% 386M/1.94G [00:14<01:05, 23.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  21% 416M/1.98G [00:14<01:10, 22.4MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  20% 393M/1.94G [00:14<00:50, 30.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  22% 425M/1.96G [00:14<00:45, 33.3MB/s]\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  21% 421M/1.98G [00:14<00:57, 27.3MB/s]\n","\n","model-00001-of-00004.safetensors:  22% 429M/1.96G [00:14<00:45, 33.3MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  20% 397M/1.94G [00:14<00:51, 30.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  21% 425M/1.98G [00:14<00:56, 27.8MB/s]\n","model-00003-of-00004.safetensors:  22% 428M/1.98G [00:15<00:53, 28.8MB/s]\n","\n","model-00001-of-00004.safetensors:  22% 433M/1.96G [00:15<01:05, 23.4MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  21% 401M/1.94G [00:15<01:13, 20.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  27% 480M/1.76G [00:15<00:51, 25.1MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:  22% 432M/1.98G [00:15<01:05, 23.5MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:  22% 436M/1.98G [00:15<01:02, 24.7MB/s]\n","model-00004-of-00004.safetensors:  28% 487M/1.76G [00:15<00:43, 29.4MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  21% 411M/1.94G [00:15<00:54, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:  22% 442M/1.98G [00:15<00:52, 29.6MB/s]\n","model-00004-of-00004.safetensors:  28% 494M/1.76G [00:15<00:37, 33.9MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:  22% 445M/1.98G [00:15<00:50, 30.1MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  21% 416M/1.94G [00:15<01:04, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:  23% 448M/1.98G [00:15<00:54, 28.1MB/s]\n","model-00004-of-00004.safetensors:  28% 497M/1.76G [00:15<00:48, 26.2MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  22% 424M/1.94G [00:15<00:48, 31.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  28% 501M/1.76G [00:15<00:45, 27.9MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  23% 455M/1.98G [00:15<00:47, 32.1MB/s]\n","model-00004-of-00004.safetensors:  29% 505M/1.76G [00:16<00:41, 30.0MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:  23% 460M/1.98G [00:16<00:41, 36.8MB/s]\n","\n","model-00001-of-00004.safetensors:  24% 468M/1.96G [00:16<00:51, 28.9MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  29% 510M/1.76G [00:16<00:43, 28.7MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  22% 432M/1.94G [00:16<00:58, 25.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  24% 473M/1.96G [00:16<00:45, 32.9MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  23% 438M/1.94G [00:16<00:46, 32.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:  23% 464M/1.98G [00:16<01:01, 24.6MB/s]\n","model-00004-of-00004.safetensors:  29% 513M/1.76G [00:16<00:52, 23.8MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  23% 443M/1.94G [00:16<00:41, 36.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  24% 471M/1.98G [00:16<00:51, 29.5MB/s]\n","\n","model-00003-of-00004.safetensors:  24% 477M/1.98G [00:16<00:43, 34.9MB/s]\n","model-00004-of-00004.safetensors:  30% 523M/1.76G [00:16<00:40, 30.3MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  23% 448M/1.94G [00:16<00:49, 30.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  30% 527M/1.76G [00:16<00:39, 31.7MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  23% 452M/1.94G [00:16<00:47, 31.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  25% 487M/1.96G [00:16<00:56, 26.1MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  24% 481M/1.98G [00:16<00:58, 25.6MB/s]\n","\n","model-00001-of-00004.safetensors:  25% 494M/1.96G [00:16<00:45, 32.4MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  24% 462M/1.94G [00:16<00:37, 38.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  25% 487M/1.98G [00:17<00:51, 29.1MB/s]\n","model-00004-of-00004.safetensors:  30% 535M/1.76G [00:17<00:44, 27.5MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:  25% 494M/1.98G [00:17<00:41, 35.9MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  24% 467M/1.94G [00:17<00:54, 27.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  31% 542M/1.76G [00:17<00:37, 32.7MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  26% 503M/1.96G [00:17<00:49, 29.2MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  25% 498M/1.98G [00:17<00:50, 29.3MB/s]\n","\n","model-00001-of-00004.safetensors:  26% 509M/1.96G [00:17<00:44, 32.8MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  31% 545M/1.76G [00:17<00:45, 27.0MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  25% 504M/1.98G [00:17<00:47, 31.2MB/s]\n","model-00004-of-00004.safetensors:  31% 550M/1.76G [00:17<00:41, 29.3MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  25% 479M/1.94G [00:17<00:48, 30.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:  26% 509M/1.98G [00:17<00:44, 33.0MB/s]\n","model-00004-of-00004.safetensors:  31% 555M/1.76G [00:17<00:39, 30.2MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  26% 518M/1.96G [00:17<00:45, 31.6MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  25% 482M/1.94G [00:17<00:58, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  32% 560M/1.76G [00:17<00:35, 33.6MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  27% 523M/1.96G [00:17<00:42, 33.4MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  26% 512M/1.98G [00:18<01:00, 24.4MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  25% 492M/1.94G [00:18<00:44, 32.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  26% 519M/1.98G [00:18<00:48, 30.3MB/s]\n","\n","model-00003-of-00004.safetensors:  26% 525M/1.98G [00:18<00:41, 35.2MB/s]\n","model-00004-of-00004.safetensors:  32% 567M/1.76G [00:18<00:44, 27.0MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  26% 496M/1.94G [00:18<00:55, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  32% 571M/1.76G [00:18<00:41, 28.9MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  27% 535M/1.96G [00:18<00:47, 29.9MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  26% 500M/1.94G [00:18<00:51, 28.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  27% 529M/1.98G [00:18<00:52, 27.4MB/s]\n","\n","model-00001-of-00004.safetensors:  28% 540M/1.96G [00:18<00:42, 33.6MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  26% 505M/1.94G [00:18<00:42, 33.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  27% 535M/1.98G [00:18<00:47, 30.2MB/s]\n","model-00003-of-00004.safetensors:  27% 541M/1.98G [00:18<00:41, 34.4MB/s]\n","\n","model-00001-of-00004.safetensors:  28% 544M/1.96G [00:18<00:54, 26.1MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  33% 582M/1.76G [00:18<00:43, 27.1MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  28% 550M/1.96G [00:18<00:44, 31.5MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  33% 585M/1.76G [00:18<00:42, 27.8MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  26% 513M/1.94G [00:18<00:57, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  33% 590M/1.76G [00:19<00:37, 31.5MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:  27% 545M/1.98G [00:19<00:53, 27.0MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:  28% 550M/1.98G [00:19<00:46, 30.6MB/s]\n","\n","model-00001-of-00004.safetensors:  29% 559M/1.96G [00:19<00:41, 33.5MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  27% 523M/1.94G [00:19<00:46, 30.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  28% 555M/1.98G [00:19<00:44, 32.1MB/s]\n","\n","model-00001-of-00004.safetensors:  29% 563M/1.96G [00:19<00:44, 31.7MB/s]\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  29% 567M/1.96G [00:19<00:43, 31.7MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  27% 528M/1.94G [00:19<00:52, 27.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  34% 600M/1.76G [00:19<00:40, 28.7MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  28% 534M/1.94G [00:19<00:42, 32.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  34% 604M/1.76G [00:19<00:37, 30.6MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:  29% 566M/1.98G [00:19<00:46, 30.5MB/s]\n","\n","model-00001-of-00004.safetensors:  29% 576M/1.96G [00:19<00:43, 31.9MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  29% 570M/1.98G [00:19<00:44, 31.8MB/s]\n","model-00004-of-00004.safetensors:  34% 608M/1.76G [00:19<00:52, 22.0MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  30% 579M/1.96G [00:19<00:50, 27.3MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  28% 544M/1.94G [00:19<00:52, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  35% 615M/1.76G [00:19<00:39, 28.9MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:  29% 576M/1.98G [00:20<00:50, 27.9MB/s]\n","model-00004-of-00004.safetensors:  35% 620M/1.76G [00:20<00:35, 32.6MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  28% 551M/1.94G [00:20<00:43, 32.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:  29% 580M/1.98G [00:20<00:48, 28.9MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:  29% 584M/1.98G [00:20<00:44, 31.6MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:  30% 591M/1.98G [00:20<00:35, 39.0MB/s]\n","model-00004-of-00004.safetensors:  35% 624M/1.76G [00:20<00:49, 22.9MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  30% 593M/1.96G [00:20<00:59, 23.0MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  29% 564M/1.94G [00:20<00:43, 31.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  31% 600M/1.96G [00:20<00:42, 32.3MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  36% 633M/1.76G [00:20<00:35, 31.7MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  30% 595M/1.98G [00:20<00:47, 29.0MB/s]\n","\n","model-00001-of-00004.safetensors:  31% 605M/1.96G [00:20<00:40, 33.2MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  36% 637M/1.76G [00:20<00:34, 32.9MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  30% 599M/1.98G [00:20<00:52, 26.2MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  30% 576M/1.94G [00:20<00:41, 32.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  31% 609M/1.96G [00:20<00:49, 27.4MB/s]\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  31% 605M/1.98G [00:20<00:42, 32.3MB/s]\n","\n","model-00001-of-00004.safetensors:  31% 615M/1.96G [00:21<00:42, 31.3MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  30% 579M/1.94G [00:21<00:48, 28.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  37% 647M/1.76G [00:21<00:37, 29.8MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  30% 582M/1.94G [00:21<00:48, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  32% 620M/1.96G [00:21<00:39, 33.9MB/s]\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  31% 614M/1.98G [00:21<00:46, 29.5MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:  31% 619M/1.98G [00:21<00:43, 31.2MB/s]\n","\n","model-00001-of-00004.safetensors:  32% 624M/1.96G [00:21<00:54, 24.4MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  37% 656M/1.76G [00:21<00:44, 24.7MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  31% 592M/1.94G [00:21<00:52, 25.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  32% 631M/1.96G [00:21<00:44, 29.9MB/s]\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  31% 624M/1.98G [00:21<00:49, 27.4MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  31% 599M/1.94G [00:21<00:44, 30.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  38% 669M/1.76G [00:21<00:32, 33.2MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:  32% 628M/1.98G [00:21<00:47, 28.5MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:  32% 633M/1.98G [00:21<00:40, 32.9MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:  32% 638M/1.98G [00:22<00:37, 36.2MB/s]\n","\n","model-00001-of-00004.safetensors:  33% 641M/1.96G [00:22<00:54, 24.3MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  38% 672M/1.76G [00:22<00:45, 23.9MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  31% 609M/1.94G [00:22<00:51, 25.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  33% 648M/1.96G [00:22<00:40, 32.2MB/s]\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  32% 642M/1.98G [00:22<00:45, 29.3MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  32% 615M/1.94G [00:22<00:39, 33.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  33% 653M/1.96G [00:22<00:36, 35.8MB/s]\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  33% 646M/1.98G [00:22<00:45, 29.3MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:  33% 649M/1.98G [00:22<00:45, 29.5MB/s]\n","\n","model-00001-of-00004.safetensors:  34% 657M/1.96G [00:22<00:51, 25.4MB/s]\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  33% 654M/1.98G [00:22<00:38, 34.1MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  32% 624M/1.94G [00:22<00:49, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  39% 695M/1.76G [00:22<00:33, 31.6MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  34% 663M/1.96G [00:22<00:44, 29.4MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  33% 657M/1.98G [00:22<00:48, 27.2MB/s]\n","model-00004-of-00004.safetensors:  40% 701M/1.76G [00:22<00:30, 34.7MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:  33% 661M/1.98G [00:22<00:44, 29.4MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:  34% 665M/1.98G [00:22<00:43, 30.5MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  33% 639M/1.94G [00:23<00:37, 34.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:  34% 671M/1.98G [00:23<00:37, 35.3MB/s]\n","model-00004-of-00004.safetensors:  40% 705M/1.76G [00:23<00:42, 24.8MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  35% 679M/1.96G [00:23<00:41, 31.0MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  40% 711M/1.76G [00:23<00:34, 30.6MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  33% 643M/1.94G [00:23<00:44, 29.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  35% 684M/1.96G [00:23<00:37, 33.6MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  41% 716M/1.76G [00:23<00:31, 33.7MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  34% 675M/1.98G [00:23<00:58, 22.3MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:  34% 678M/1.98G [00:23<00:54, 23.9MB/s]\n","\n","model-00001-of-00004.safetensors:  35% 688M/1.96G [00:23<00:48, 26.4MB/s]\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  35% 685M/1.98G [00:23<00:40, 32.3MB/s]\n","\n","model-00001-of-00004.safetensors:  35% 695M/1.96G [00:23<00:38, 33.1MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  34% 656M/1.94G [00:23<00:51, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  41% 727M/1.76G [00:23<00:34, 30.4MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  36% 701M/1.96G [00:23<00:35, 35.9MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  34% 662M/1.94G [00:23<00:43, 29.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  35% 689M/1.98G [00:23<00:51, 24.9MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:  35% 694M/1.98G [00:24<00:43, 29.4MB/s]\n","\n","model-00001-of-00004.safetensors:  36% 705M/1.96G [00:24<00:47, 26.1MB/s]\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  35% 699M/1.98G [00:24<00:38, 33.5MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  35% 672M/1.94G [00:24<00:46, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  36% 711M/1.96G [00:24<00:41, 29.9MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  42% 744M/1.76G [00:24<00:32, 31.5MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  35% 676M/1.94G [00:24<00:42, 29.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  37% 715M/1.96G [00:24<00:40, 30.9MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  42% 748M/1.76G [00:24<00:30, 33.4MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  35% 681M/1.94G [00:24<00:38, 32.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:  36% 710M/1.98G [00:24<00:43, 29.4MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  35% 686M/1.94G [00:24<00:37, 33.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:  36% 717M/1.98G [00:24<00:34, 36.8MB/s]\n","model-00004-of-00004.safetensors:  43% 752M/1.76G [00:24<00:42, 24.1MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  36% 690M/1.94G [00:24<00:41, 30.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  37% 728M/1.96G [00:24<00:39, 30.8MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  36% 694M/1.94G [00:24<00:39, 31.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  37% 731M/1.96G [00:24<00:38, 31.8MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  43% 759M/1.76G [00:24<00:35, 28.7MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  36% 721M/1.98G [00:25<00:48, 26.1MB/s]\n","\n","model-00001-of-00004.safetensors:  38% 736M/1.96G [00:25<00:36, 33.1MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  37% 725M/1.98G [00:25<00:44, 28.0MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:  37% 731M/1.98G [00:25<00:37, 33.3MB/s]\n","\n","model-00001-of-00004.safetensors:  38% 740M/1.96G [00:25<00:46, 26.0MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  44% 768M/1.76G [00:25<00:38, 25.6MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  36% 706M/1.94G [00:25<00:42, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  38% 744M/1.96G [00:25<00:43, 27.8MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  37% 709M/1.94G [00:25<00:42, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  44% 775M/1.76G [00:25<00:33, 29.8MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:  37% 736M/1.98G [00:25<00:46, 26.6MB/s]\n","model-00004-of-00004.safetensors:  44% 781M/1.76G [00:25<00:28, 35.0MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  37% 741M/1.98G [00:25<00:40, 30.6MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:  38% 746M/1.98G [00:25<00:36, 33.5MB/s]\n","\n","model-00001-of-00004.safetensors:  38% 752M/1.96G [00:25<00:55, 21.8MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  45% 785M/1.76G [00:25<00:39, 24.9MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  37% 722M/1.94G [00:25<00:47, 25.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  39% 760M/1.96G [00:25<00:37, 32.0MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  37% 726M/1.94G [00:25<00:40, 29.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  45% 791M/1.76G [00:25<00:34, 28.4MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:  38% 752M/1.98G [00:26<00:46, 26.7MB/s]\n","model-00004-of-00004.safetensors:  45% 795M/1.76G [00:26<00:30, 31.6MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  38% 730M/1.94G [00:26<00:40, 29.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:  38% 756M/1.98G [00:26<00:45, 26.9MB/s]\n","model-00004-of-00004.safetensors:  45% 800M/1.76G [00:26<00:29, 33.0MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  38% 760M/1.98G [00:26<00:42, 29.1MB/s]\n","\n","model-00003-of-00004.safetensors:  39% 765M/1.98G [00:26<00:37, 32.3MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  38% 739M/1.94G [00:26<00:43, 27.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  46% 803M/1.76G [00:26<00:36, 26.0MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  40% 782M/1.96G [00:26<00:29, 39.8MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  46% 807M/1.76G [00:26<00:36, 26.5MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  39% 769M/1.98G [00:26<00:46, 26.3MB/s]\n","model-00004-of-00004.safetensors:  46% 811M/1.76G [00:26<00:32, 29.0MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  39% 775M/1.98G [00:26<00:39, 30.7MB/s]\n","model-00004-of-00004.safetensors:  46% 816M/1.76G [00:26<00:39, 24.3MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  39% 754M/1.94G [00:26<00:44, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  47% 825M/1.76G [00:27<00:25, 37.4MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  40% 784M/1.98G [00:27<00:38, 31.3MB/s]\n","\n","model-00001-of-00004.safetensors:  40% 786M/1.96G [00:27<01:04, 18.2MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  40% 789M/1.98G [00:27<00:34, 34.4MB/s]\n","\n","model-00001-of-00004.safetensors:  40% 790M/1.96G [00:27<00:58, 19.9MB/s]\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  40% 793M/1.98G [00:27<00:34, 34.6MB/s]\n","\n","model-00003-of-00004.safetensors:  40% 797M/1.98G [00:27<00:33, 34.9MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  40% 769M/1.94G [00:27<00:42, 27.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  41% 798M/1.96G [00:27<00:44, 25.9MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  47% 835M/1.76G [00:27<00:32, 28.5MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  40% 801M/1.98G [00:27<00:38, 30.3MB/s]\n","model-00004-of-00004.safetensors:  48% 839M/1.76G [00:27<00:32, 28.8MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  41% 802M/1.96G [00:27<00:48, 23.9MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  40% 781M/1.94G [00:27<00:32, 36.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  48% 845M/1.76G [00:27<00:27, 33.5MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:  41% 807M/1.98G [00:27<00:37, 30.9MB/s]\n","\n","model-00003-of-00004.safetensors:  41% 811M/1.98G [00:27<00:37, 31.1MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  41% 785M/1.94G [00:27<00:43, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  42% 814M/1.96G [00:27<00:38, 29.8MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  48% 849M/1.76G [00:28<00:40, 22.6MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  41% 816M/1.98G [00:28<00:44, 26.5MB/s]\n","model-00004-of-00004.safetensors:  49% 856M/1.76G [00:28<00:30, 29.8MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  42% 817M/1.96G [00:28<00:46, 24.8MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  41% 798M/1.94G [00:28<00:29, 38.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  42% 822M/1.96G [00:28<00:40, 28.2MB/s]\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  42% 829M/1.98G [00:28<00:31, 36.1MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  41% 803M/1.94G [00:28<00:38, 29.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  42% 827M/1.96G [00:28<00:39, 29.0MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  42% 807M/1.94G [00:28<00:36, 31.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  42% 831M/1.96G [00:28<00:34, 32.9MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  42% 833M/1.98G [00:28<00:41, 27.7MB/s]\n","\n","model-00003-of-00004.safetensors:  43% 845M/1.98G [00:28<00:26, 42.9MB/s]\n","model-00004-of-00004.safetensors:  49% 864M/1.76G [00:28<00:50, 17.8MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  43% 839M/1.96G [00:28<00:38, 28.9MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  49% 870M/1.76G [00:28<00:40, 22.0MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  42% 816M/1.94G [00:28<00:46, 24.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  43% 846M/1.96G [00:29<00:30, 35.9MB/s]\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  43% 850M/1.98G [00:29<00:35, 32.0MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  42% 822M/1.94G [00:29<00:39, 28.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  43% 856M/1.98G [00:29<00:33, 33.7MB/s]\n","model-00004-of-00004.safetensors:  50% 881M/1.76G [00:29<00:33, 26.6MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:  43% 861M/1.98G [00:29<00:30, 36.5MB/s]\n","model-00004-of-00004.safetensors:  50% 885M/1.76G [00:29<00:29, 29.6MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  44% 853M/1.96G [00:29<00:38, 28.4MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  50% 889M/1.76G [00:29<00:28, 30.5MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  44% 857M/1.96G [00:29<00:39, 28.2MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  43% 832M/1.94G [00:29<00:43, 25.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  44% 865M/1.98G [00:29<00:38, 29.2MB/s]\n","\n","model-00001-of-00004.safetensors:  44% 862M/1.96G [00:29<00:34, 32.2MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  44% 869M/1.98G [00:29<00:38, 29.0MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:  44% 875M/1.98G [00:29<00:31, 35.1MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  44% 847M/1.94G [00:29<00:31, 34.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  44% 865M/1.96G [00:29<00:45, 24.1MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  51% 899M/1.76G [00:29<00:37, 23.2MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  45% 872M/1.96G [00:29<00:36, 30.2MB/s]\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  44% 880M/1.98G [00:30<00:37, 29.4MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  44% 851M/1.94G [00:30<00:38, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:  45% 885M/1.98G [00:30<00:33, 32.5MB/s]\n","model-00004-of-00004.safetensors:  52% 910M/1.76G [00:30<00:29, 29.4MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  45% 890M/1.98G [00:30<00:33, 33.0MB/s]\n","\n","model-00001-of-00004.safetensors:  45% 883M/1.96G [00:30<00:35, 30.2MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  44% 860M/1.94G [00:30<00:33, 32.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  45% 895M/1.98G [00:30<00:30, 36.1MB/s]\n","model-00004-of-00004.safetensors:  52% 917M/1.76G [00:30<00:29, 28.3MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:  45% 899M/1.98G [00:30<00:33, 31.9MB/s]\n","\n","model-00001-of-00004.safetensors:  46% 893M/1.96G [00:30<00:30, 34.5MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  52% 922M/1.76G [00:30<00:26, 31.6MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  46% 902M/1.98G [00:30<00:33, 32.0MB/s]\n","model-00004-of-00004.safetensors:  53% 928M/1.76G [00:30<00:22, 36.7MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  45% 869M/1.94G [00:30<00:38, 28.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  46% 906M/1.98G [00:30<00:36, 29.2MB/s]\n","\n","model-00001-of-00004.safetensors:  46% 897M/1.96G [00:30<00:41, 25.3MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  53% 932M/1.76G [00:30<00:28, 29.3MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  45% 879M/1.94G [00:30<00:29, 36.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  46% 903M/1.96G [00:31<00:38, 27.3MB/s]\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  46% 912M/1.98G [00:31<00:41, 25.8MB/s]\n","\n","model-00001-of-00004.safetensors:  46% 910M/1.96G [00:31<00:31, 33.7MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  46% 883M/1.94G [00:31<00:36, 28.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  53% 942M/1.76G [00:31<00:26, 31.5MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  46% 919M/1.98G [00:31<00:35, 29.7MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:  47% 926M/1.98G [00:31<00:30, 34.4MB/s]\n","\n","model-00001-of-00004.safetensors:  47% 914M/1.96G [00:31<00:40, 25.5MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  54% 945M/1.76G [00:31<00:32, 25.0MB/s]\u001b[A\n","model-00004-of-00004.safetensors:  54% 948M/1.76G [00:31<00:30, 26.5MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:  47% 930M/1.98G [00:31<00:37, 28.4MB/s]\n","model-00004-of-00004.safetensors:  54% 955M/1.76G [00:31<00:24, 33.0MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  46% 896M/1.94G [00:31<00:42, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  47% 926M/1.96G [00:31<00:29, 34.4MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  54% 960M/1.76G [00:31<00:22, 36.4MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  47% 935M/1.98G [00:31<00:36, 28.8MB/s]\n","\n","model-00001-of-00004.safetensors:  47% 930M/1.96G [00:31<00:34, 30.2MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  47% 940M/1.98G [00:31<00:32, 32.3MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  47% 912M/1.94G [00:32<00:28, 35.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  48% 935M/1.96G [00:32<00:33, 30.9MB/s]\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:  48% 944M/1.98G [00:32<00:40, 25.5MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  47% 916M/1.94G [00:32<00:34, 29.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  48% 957M/1.98G [00:32<00:24, 41.7MB/s]\n","\n","model-00001-of-00004.safetensors:  48% 948M/1.96G [00:32<00:27, 36.3MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  47% 919M/1.94G [00:32<00:33, 30.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  55% 967M/1.76G [00:32<00:42, 18.6MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  48% 923M/1.94G [00:32<00:33, 29.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  49% 952M/1.96G [00:32<00:31, 31.5MB/s]\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  49% 961M/1.98G [00:32<00:32, 31.4MB/s]\n","\n","model-00001-of-00004.safetensors:  49% 956M/1.96G [00:32<00:29, 33.8MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  55% 976M/1.76G [00:32<00:33, 23.6MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  49% 974M/1.98G [00:32<00:26, 37.5MB/s]\n","\n","model-00001-of-00004.safetensors:  49% 960M/1.96G [00:32<00:41, 24.1MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  48% 936M/1.94G [00:32<00:31, 31.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  55% 979M/1.76G [00:32<00:37, 20.9MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  49% 967M/1.96G [00:33<00:32, 30.6MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  49% 940M/1.94G [00:33<00:31, 32.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  49% 978M/1.98G [00:33<00:31, 32.2MB/s]\n","\n","model-00003-of-00004.safetensors:  50% 982M/1.98G [00:33<00:30, 32.4MB/s]\n","model-00004-of-00004.safetensors:  56% 990M/1.76G [00:33<00:27, 28.4MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  50% 976M/1.96G [00:33<00:28, 34.9MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  50% 986M/1.98G [00:33<00:31, 31.9MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  49% 952M/1.94G [00:33<00:30, 32.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  56% 993M/1.76G [00:33<00:33, 23.3MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:  50% 992M/1.98G [00:33<00:33, 29.9MB/s]\n","model-00004-of-00004.safetensors:  57% 999M/1.76G [00:33<00:27, 28.1MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  49% 958M/1.94G [00:33<00:27, 35.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:  50% 996M/1.98G [00:33<00:33, 29.7MB/s]\n","model-00003-of-00004.safetensors:  51% 1.00G/1.98G [00:33<00:28, 34.0MB/s]\n","model-00004-of-00004.safetensors:  57% 1.01G/1.76G [00:33<00:23, 31.9MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  51% 991M/1.96G [00:33<00:31, 31.1MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  51% 1.01G/1.98G [00:33<00:26, 36.2MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  50% 967M/1.94G [00:34<00:32, 30.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  51% 995M/1.96G [00:34<00:34, 27.7MB/s]\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  51% 1.01G/1.98G [00:34<00:31, 31.1MB/s]\n","\n","model-00001-of-00004.safetensors:  51% 1.00G/1.96G [00:34<00:28, 34.0MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  51% 1.01G/1.98G [00:34<00:30, 31.4MB/s]\n","\n","model-00001-of-00004.safetensors:  51% 1.01G/1.96G [00:34<00:28, 33.9MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  58% 1.01G/1.76G [00:34<00:31, 23.6MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  51% 1.02G/1.98G [00:34<00:30, 31.2MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:  52% 1.02G/1.98G [00:34<00:30, 31.4MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  51% 985M/1.94G [00:34<00:30, 30.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  52% 1.01G/1.96G [00:34<00:40, 23.7MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  58% 1.02G/1.76G [00:34<00:30, 24.0MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  52% 1.03G/1.98G [00:34<00:34, 27.6MB/s]\n","\n","model-00003-of-00004.safetensors:  52% 1.03G/1.98G [00:34<00:34, 27.9MB/s]\n","\n","model-00001-of-00004.safetensors:  52% 1.02G/1.96G [00:34<00:30, 30.8MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  58% 1.03G/1.76G [00:34<00:25, 28.5MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  52% 1.02G/1.96G [00:34<00:27, 33.6MB/s]\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  52% 1.03G/1.98G [00:34<00:29, 32.3MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  51% 996M/1.94G [00:34<00:33, 28.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  52% 1.04G/1.98G [00:35<00:29, 31.5MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  52% 1.00G/1.94G [00:35<00:31, 29.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  52% 1.03G/1.96G [00:35<00:36, 25.4MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  52% 1.01G/1.94G [00:35<00:25, 36.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  53% 1.04G/1.98G [00:35<00:35, 26.7MB/s]\n","\n","model-00003-of-00004.safetensors:  53% 1.05G/1.98G [00:35<00:30, 30.8MB/s]\n","model-00004-of-00004.safetensors:  59% 1.05G/1.76G [00:35<00:25, 27.9MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  52% 1.01G/1.94G [00:35<00:28, 32.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  53% 1.04G/1.96G [00:35<00:30, 30.3MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  52% 1.01G/1.94G [00:35<00:28, 32.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  53% 1.05G/1.98G [00:35<00:32, 29.0MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  53% 1.02G/1.94G [00:35<00:28, 32.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  53% 1.05G/1.98G [00:35<00:31, 29.1MB/s]\n","\n","model-00001-of-00004.safetensors:  53% 1.04G/1.96G [00:35<00:39, 23.0MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  53% 1.02G/1.94G [00:35<00:27, 32.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:  53% 1.06G/1.98G [00:35<00:38, 24.0MB/s]\n","\n","model-00001-of-00004.safetensors:  54% 1.06G/1.96G [00:35<00:22, 40.7MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  54% 1.06G/1.98G [00:35<00:28, 32.4MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:  54% 1.07G/1.98G [00:36<00:23, 38.2MB/s]\n","model-00004-of-00004.safetensors:  60% 1.06G/1.76G [00:36<00:44, 15.7MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  54% 1.06G/1.96G [00:36<00:27, 33.0MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  54% 1.07G/1.98G [00:36<00:26, 34.2MB/s]\n","\n","model-00001-of-00004.safetensors:  54% 1.07G/1.96G [00:36<00:24, 36.0MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  60% 1.06G/1.76G [00:36<00:41, 16.9MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  54% 1.04G/1.94G [00:36<00:29, 30.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  54% 1.08G/1.98G [00:36<00:27, 33.3MB/s]\n","\n","model-00001-of-00004.safetensors:  55% 1.07G/1.96G [00:36<00:25, 35.3MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  54% 1.05G/1.94G [00:36<00:28, 30.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  55% 1.09G/1.98G [00:36<00:25, 35.5MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  54% 1.05G/1.94G [00:36<00:28, 31.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  55% 1.07G/1.96G [00:36<00:31, 28.1MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  61% 1.07G/1.76G [00:36<00:35, 19.6MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  55% 1.08G/1.96G [00:36<00:31, 28.0MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  61% 1.08G/1.76G [00:36<00:22, 30.4MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  54% 1.06G/1.94G [00:36<00:31, 28.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:  55% 1.09G/1.98G [00:36<00:36, 24.3MB/s]\n","model-00004-of-00004.safetensors:  62% 1.09G/1.76G [00:36<00:20, 33.3MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  55% 1.09G/1.98G [00:37<00:39, 22.6MB/s]\n","\n","model-00001-of-00004.safetensors:  56% 1.09G/1.96G [00:37<00:29, 29.6MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  55% 1.07G/1.94G [00:37<00:23, 36.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  56% 1.10G/1.98G [00:37<00:31, 27.9MB/s]\n","model-00004-of-00004.safetensors:  62% 1.09G/1.76G [00:37<00:23, 28.5MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:  56% 1.10G/1.98G [00:37<00:31, 28.2MB/s]\n","\n","model-00001-of-00004.safetensors:  56% 1.10G/1.96G [00:37<00:24, 34.8MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  55% 1.07G/1.94G [00:37<00:30, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  56% 1.11G/1.98G [00:37<00:35, 24.7MB/s]\n","model-00004-of-00004.safetensors:  63% 1.10G/1.76G [00:37<00:19, 33.9MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  56% 1.08G/1.94G [00:37<00:27, 31.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  56% 1.10G/1.96G [00:37<00:32, 26.7MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  56% 1.12G/1.98G [00:37<00:28, 30.7MB/s]\n","model-00004-of-00004.safetensors:  63% 1.11G/1.76G [00:37<00:25, 25.5MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  57% 1.11G/1.96G [00:37<00:26, 31.7MB/s]\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  57% 1.12G/1.96G [00:37<00:23, 35.5MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  63% 1.11G/1.76G [00:37<00:25, 25.6MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  57% 1.12G/1.98G [00:37<00:36, 23.6MB/s]\n","model-00004-of-00004.safetensors:  63% 1.12G/1.76G [00:38<00:21, 30.5MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  57% 1.13G/1.98G [00:38<00:27, 30.6MB/s]\n","model-00004-of-00004.safetensors:  63% 1.12G/1.76G [00:38<00:20, 31.2MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  57% 1.10G/1.94G [00:38<00:24, 33.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:  57% 1.13G/1.98G [00:38<00:26, 32.0MB/s]\n","model-00003-of-00004.safetensors:  57% 1.14G/1.98G [00:38<00:23, 35.8MB/s]\n","model-00004-of-00004.safetensors:  64% 1.13G/1.76G [00:38<00:21, 29.7MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  58% 1.13G/1.96G [00:38<00:28, 28.8MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  57% 1.10G/1.94G [00:38<00:31, 26.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  58% 1.14G/1.98G [00:38<00:28, 29.2MB/s]\n","\n","model-00001-of-00004.safetensors:  58% 1.14G/1.96G [00:38<00:25, 32.6MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  57% 1.11G/1.94G [00:38<00:26, 30.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  58% 1.14G/1.98G [00:38<00:28, 29.4MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:  58% 1.15G/1.98G [00:38<00:27, 30.0MB/s]\n","model-00004-of-00004.safetensors:  65% 1.14G/1.76G [00:38<00:22, 27.5MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  58% 1.12G/1.94G [00:38<00:28, 28.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  65% 1.15G/1.76G [00:38<00:18, 34.0MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  58% 1.14G/1.96G [00:38<00:37, 22.0MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  58% 1.13G/1.94G [00:39<00:22, 36.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  58% 1.14G/1.96G [00:39<00:35, 22.9MB/s]\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  58% 1.16G/1.98G [00:39<00:27, 30.3MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  58% 1.13G/1.94G [00:39<00:22, 35.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  59% 1.15G/1.96G [00:39<00:32, 24.9MB/s]\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  59% 1.16G/1.98G [00:39<00:24, 33.3MB/s]\n","model-00004-of-00004.safetensors:  66% 1.16G/1.76G [00:39<00:17, 33.6MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:  59% 1.17G/1.98G [00:39<00:24, 32.9MB/s]\n","model-00004-of-00004.safetensors:  66% 1.16G/1.76G [00:39<00:19, 31.4MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  59% 1.14G/1.94G [00:39<00:30, 26.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  59% 1.15G/1.96G [00:39<00:30, 26.1MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  59% 1.17G/1.98G [00:39<00:31, 26.1MB/s]\n","\n","model-00001-of-00004.safetensors:  59% 1.16G/1.96G [00:39<00:29, 27.1MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  59% 1.15G/1.94G [00:39<00:24, 32.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  66% 1.17G/1.76G [00:39<00:22, 26.3MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:  59% 1.18G/1.98G [00:39<00:26, 30.0MB/s]\n","model-00004-of-00004.safetensors:  66% 1.17G/1.76G [00:39<00:20, 29.2MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:  59% 1.18G/1.98G [00:39<00:27, 29.3MB/s]\n","model-00003-of-00004.safetensors:  60% 1.18G/1.98G [00:39<00:23, 33.6MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  59% 1.15G/1.94G [00:39<00:31, 25.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  67% 1.18G/1.76G [00:40<00:15, 36.9MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  60% 1.17G/1.96G [00:40<00:32, 24.3MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  60% 1.16G/1.94G [00:40<00:24, 32.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  60% 1.18G/1.96G [00:40<00:27, 28.6MB/s]\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  60% 1.19G/1.98G [00:40<00:32, 24.2MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  60% 1.17G/1.94G [00:40<00:20, 37.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  60% 1.18G/1.96G [00:40<00:22, 33.9MB/s]\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  60% 1.19G/1.98G [00:40<00:35, 22.3MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  60% 1.17G/1.94G [00:40<00:25, 30.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  68% 1.20G/1.76G [00:40<00:15, 36.9MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:  60% 1.20G/1.98G [00:40<00:28, 28.0MB/s]\n","\n","model-00003-of-00004.safetensors:  61% 1.20G/1.98G [00:40<00:27, 28.2MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  61% 1.18G/1.94G [00:40<00:26, 29.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  68% 1.20G/1.76G [00:40<00:18, 30.6MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:  61% 1.20G/1.98G [00:40<00:31, 25.0MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  61% 1.18G/1.94G [00:40<00:22, 33.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  61% 1.21G/1.98G [00:40<00:30, 25.2MB/s]\n","model-00003-of-00004.safetensors:  61% 1.21G/1.98G [00:41<00:26, 28.9MB/s]\n","\n","model-00001-of-00004.safetensors:  61% 1.20G/1.96G [00:41<00:30, 25.0MB/s]\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  62% 1.21G/1.96G [00:41<00:22, 33.3MB/s]\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  61% 1.22G/1.98G [00:41<00:26, 29.3MB/s]\n","\n","model-00001-of-00004.safetensors:  62% 1.22G/1.96G [00:41<00:17, 43.5MB/s]\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  62% 1.22G/1.98G [00:41<00:21, 35.4MB/s]\n","model-00003-of-00004.safetensors:  62% 1.23G/1.98G [00:41<00:18, 41.5MB/s]\n","\n","model-00001-of-00004.safetensors:  62% 1.22G/1.96G [00:41<00:21, 33.7MB/s]\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  63% 1.23G/1.96G [00:41<00:16, 44.3MB/s]\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  62% 1.23G/1.98G [00:41<00:22, 32.7MB/s]\n","model-00003-of-00004.safetensors:  63% 1.24G/1.98G [00:41<00:18, 39.7MB/s]\n","model-00003-of-00004.safetensors:  63% 1.25G/1.98G [00:41<00:17, 42.2MB/s]\n","\n","model-00001-of-00004.safetensors:  63% 1.24G/1.96G [00:41<00:22, 32.7MB/s]\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  64% 1.25G/1.96G [00:42<00:16, 44.3MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  61% 1.19G/1.94G [00:42<01:09, 10.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  63% 1.25G/1.98G [00:42<00:20, 36.2MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  61% 1.19G/1.94G [00:42<01:04, 11.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  63% 1.25G/1.98G [00:42<00:20, 35.6MB/s]\n","model-00003-of-00004.safetensors:  64% 1.26G/1.98G [00:42<00:18, 39.0MB/s]\n","\n","model-00001-of-00004.safetensors:  64% 1.25G/1.96G [00:42<00:20, 34.6MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  61% 1.19G/1.94G [00:42<01:00, 12.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  62% 1.20G/1.94G [00:42<00:49, 15.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  64% 1.26G/1.96G [00:42<00:20, 33.4MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  72% 1.27G/1.76G [00:42<00:15, 31.4MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:  64% 1.26G/1.98G [00:42<00:26, 26.8MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  62% 1.20G/1.94G [00:42<00:45, 16.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  64% 1.27G/1.98G [00:42<00:21, 32.9MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  62% 1.21G/1.94G [00:42<00:30, 23.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  72% 1.28G/1.76G [00:42<00:14, 34.0MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:  64% 1.28G/1.98G [00:42<00:20, 34.1MB/s]\n","\n","model-00001-of-00004.safetensors:  65% 1.27G/1.96G [00:42<00:21, 32.1MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  62% 1.21G/1.94G [00:42<00:30, 23.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  73% 1.28G/1.76G [00:43<00:17, 28.0MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  65% 1.28G/1.96G [00:43<00:21, 31.6MB/s]\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  65% 1.28G/1.98G [00:43<00:28, 24.5MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  63% 1.22G/1.94G [00:43<00:34, 20.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  65% 1.29G/1.98G [00:43<00:23, 29.9MB/s]\n","\n","model-00001-of-00004.safetensors:  65% 1.28G/1.96G [00:43<00:26, 25.7MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  63% 1.22G/1.94G [00:43<00:26, 27.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  65% 1.29G/1.98G [00:43<00:20, 32.9MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  63% 1.23G/1.94G [00:43<00:23, 29.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  74% 1.30G/1.76G [00:43<00:13, 33.4MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  66% 1.29G/1.96G [00:43<00:22, 29.2MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  64% 1.23G/1.94G [00:43<00:22, 31.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  74% 1.31G/1.76G [00:43<00:13, 33.5MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:  66% 1.30G/1.98G [00:43<00:22, 30.1MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  64% 1.24G/1.94G [00:43<00:24, 28.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  74% 1.31G/1.76G [00:43<00:14, 30.7MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  66% 1.30G/1.98G [00:43<00:22, 30.7MB/s]\n","\n","model-00001-of-00004.safetensors:  66% 1.30G/1.96G [00:43<00:26, 25.2MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  66% 1.31G/1.98G [00:44<00:20, 33.5MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  64% 1.25G/1.94G [00:44<00:19, 35.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  74% 1.31G/1.76G [00:44<00:21, 21.1MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  67% 1.30G/1.96G [00:44<00:21, 30.1MB/s]\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  67% 1.31G/1.96G [00:44<00:18, 34.5MB/s]\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  66% 1.31G/1.98G [00:44<00:23, 28.9MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  65% 1.25G/1.94G [00:44<00:22, 30.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  75% 1.32G/1.76G [00:44<00:13, 32.6MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  67% 1.32G/1.98G [00:44<00:23, 27.9MB/s]\n","\n","model-00003-of-00004.safetensors:  67% 1.33G/1.98G [00:44<00:19, 33.4MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  65% 1.26G/1.94G [00:44<00:23, 29.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  75% 1.33G/1.76G [00:44<00:18, 24.0MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  67% 1.32G/1.96G [00:44<00:21, 30.2MB/s]\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  68% 1.32G/1.96G [00:44<00:18, 34.0MB/s]\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  67% 1.33G/1.98G [00:44<00:25, 25.1MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  65% 1.26G/1.94G [00:44<00:29, 23.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  67% 1.34G/1.98G [00:44<00:21, 30.4MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:  68% 1.34G/1.98G [00:45<00:19, 32.6MB/s]\n","\n","model-00001-of-00004.safetensors:  68% 1.33G/1.96G [00:45<00:25, 24.8MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  66% 1.27G/1.94G [00:45<00:21, 31.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  76% 1.34G/1.76G [00:45<00:15, 27.9MB/s]\u001b[A\n","model-00004-of-00004.safetensors:  76% 1.35G/1.76G [00:45<00:14, 28.9MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  68% 1.34G/1.96G [00:45<00:22, 28.3MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  77% 1.35G/1.76G [00:45<00:11, 34.8MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  69% 1.34G/1.96G [00:45<00:18, 33.4MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  68% 1.34G/1.98G [00:45<00:31, 20.1MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  66% 1.29G/1.94G [00:45<00:18, 35.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  69% 1.35G/1.96G [00:45<00:21, 29.1MB/s]\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  68% 1.35G/1.98G [00:45<00:23, 26.8MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  67% 1.29G/1.94G [00:45<00:16, 39.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  68% 1.35G/1.98G [00:45<00:22, 28.0MB/s]\n","\n","model-00001-of-00004.safetensors:  69% 1.35G/1.96G [00:45<00:20, 29.8MB/s]\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  69% 1.36G/1.98G [00:45<00:21, 29.6MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  67% 1.30G/1.94G [00:45<00:18, 35.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  69% 1.36G/1.96G [00:45<00:17, 34.7MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  78% 1.37G/1.76G [00:45<00:10, 37.4MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  69% 1.36G/1.98G [00:46<00:24, 24.8MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  68% 1.31G/1.94G [00:46<00:18, 34.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:  69% 1.37G/1.98G [00:46<00:21, 28.3MB/s]\n","model-00004-of-00004.safetensors:  78% 1.38G/1.76G [00:46<00:14, 26.4MB/s]\u001b[A\n","model-00004-of-00004.safetensors:  78% 1.38G/1.76G [00:46<00:12, 30.6MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:  69% 1.37G/1.98G [00:46<00:18, 33.0MB/s]\n","\n","model-00001-of-00004.safetensors:  70% 1.37G/1.96G [00:46<00:18, 32.5MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  79% 1.39G/1.76G [00:46<00:12, 30.6MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  70% 1.38G/1.98G [00:46<00:24, 25.1MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  68% 1.32G/1.94G [00:46<00:22, 27.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  70% 1.38G/1.98G [00:46<00:18, 32.5MB/s]\n","\n","model-00001-of-00004.safetensors:  70% 1.38G/1.96G [00:46<00:22, 25.4MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  68% 1.33G/1.94G [00:46<00:19, 32.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:  70% 1.39G/1.98G [00:46<00:18, 32.1MB/s]\n","model-00004-of-00004.safetensors:  79% 1.40G/1.76G [00:46<00:11, 31.8MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  71% 1.38G/1.96G [00:46<00:20, 28.6MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  80% 1.40G/1.76G [00:46<00:11, 32.5MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  69% 1.33G/1.94G [00:46<00:23, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:  70% 1.39G/1.98G [00:47<00:25, 23.3MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  69% 1.33G/1.94G [00:47<00:20, 29.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  71% 1.40G/1.98G [00:47<00:18, 31.2MB/s]\n","\n","model-00001-of-00004.safetensors:  71% 1.39G/1.96G [00:47<00:21, 26.2MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  71% 1.40G/1.98G [00:47<00:17, 33.8MB/s]\n","\n","model-00001-of-00004.safetensors:  71% 1.40G/1.96G [00:47<00:18, 30.4MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  80% 1.42G/1.76G [00:47<00:11, 30.1MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  72% 1.40G/1.96G [00:47<00:17, 31.1MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  81% 1.42G/1.76G [00:47<00:10, 34.2MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  72% 1.41G/1.96G [00:47<00:16, 32.6MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  69% 1.35G/1.94G [00:47<00:28, 20.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  81% 1.42G/1.76G [00:47<00:11, 28.8MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  72% 1.41G/1.96G [00:47<00:19, 28.1MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  81% 1.43G/1.76G [00:47<00:08, 36.9MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  71% 1.41G/1.98G [00:47<00:31, 18.2MB/s]\n","\n","model-00001-of-00004.safetensors:  72% 1.42G/1.96G [00:47<00:17, 31.3MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  81% 1.44G/1.76G [00:47<00:08, 37.9MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  70% 1.36G/1.94G [00:47<00:18, 30.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:  71% 1.41G/1.98G [00:48<00:28, 20.3MB/s]\n","\n","model-00003-of-00004.safetensors:  72% 1.42G/1.98G [00:48<00:20, 26.7MB/s]\n","model-00004-of-00004.safetensors:  82% 1.44G/1.76G [00:48<00:11, 28.3MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  70% 1.36G/1.94G [00:48<00:21, 26.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  73% 1.43G/1.96G [00:48<00:16, 31.5MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  71% 1.37G/1.94G [00:48<00:19, 28.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  82% 1.45G/1.76G [00:48<00:09, 32.8MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  71% 1.37G/1.94G [00:48<00:19, 29.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  73% 1.43G/1.96G [00:48<00:18, 29.2MB/s]\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  72% 1.42G/1.98G [00:48<00:25, 21.7MB/s]\n","\n","model-00003-of-00004.safetensors:  72% 1.43G/1.98G [00:48<00:23, 23.8MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:  72% 1.43G/1.98G [00:48<00:18, 29.7MB/s]\n","model-00004-of-00004.safetensors:  83% 1.46G/1.76G [00:48<00:12, 25.1MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  71% 1.38G/1.94G [00:48<00:16, 33.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  74% 1.44G/1.96G [00:48<00:21, 23.8MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  83% 1.46G/1.76G [00:48<00:09, 30.3MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  74% 1.45G/1.96G [00:48<00:17, 29.9MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  73% 1.44G/1.98G [00:48<00:21, 25.7MB/s]\n","model-00003-of-00004.safetensors:  73% 1.45G/1.98G [00:49<00:17, 30.1MB/s]\n","\n","model-00001-of-00004.safetensors:  74% 1.45G/1.96G [00:49<00:17, 29.5MB/s]\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:  73% 1.45G/1.98G [00:49<00:16, 32.1MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  72% 1.39G/1.94G [00:49<00:22, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  83% 1.47G/1.76G [00:49<00:10, 26.7MB/s]\u001b[A\n","model-00004-of-00004.safetensors:  84% 1.48G/1.76G [00:49<00:08, 32.4MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  75% 1.46G/1.96G [00:49<00:16, 30.7MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  72% 1.40G/1.94G [00:49<00:18, 29.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  73% 1.46G/1.98G [00:49<00:19, 27.3MB/s]\n","model-00004-of-00004.safetensors:  84% 1.48G/1.76G [00:49<00:08, 33.3MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:  74% 1.46G/1.98G [00:49<00:17, 29.3MB/s]\n","model-00004-of-00004.safetensors:  84% 1.49G/1.76G [00:49<00:08, 32.5MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:  74% 1.47G/1.98G [00:49<00:13, 37.0MB/s]\n","model-00004-of-00004.safetensors:  85% 1.49G/1.76G [00:49<00:10, 26.4MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  73% 1.41G/1.94G [00:49<00:24, 21.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  85% 1.50G/1.76G [00:49<00:07, 35.9MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  75% 1.47G/1.96G [00:49<00:20, 23.3MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  73% 1.42G/1.94G [00:49<00:17, 29.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  73% 1.42G/1.94G [00:50<00:15, 33.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  74% 1.47G/1.98G [00:50<00:19, 26.5MB/s]\n","\n","model-00001-of-00004.safetensors:  76% 1.48G/1.96G [00:50<00:16, 29.1MB/s]\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:  75% 1.48G/1.98G [00:50<00:18, 26.6MB/s]\n","model-00004-of-00004.safetensors:  86% 1.51G/1.76G [00:50<00:08, 29.6MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  75% 1.48G/1.98G [00:50<00:15, 32.6MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  74% 1.43G/1.94G [00:50<00:16, 30.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  86% 1.51G/1.76G [00:50<00:07, 32.1MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  76% 1.49G/1.96G [00:50<00:18, 24.8MB/s]\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  75% 1.49G/1.98G [00:50<00:18, 27.0MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  74% 1.43G/1.94G [00:50<00:16, 30.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:  75% 1.49G/1.98G [00:50<00:15, 31.1MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  74% 1.44G/1.94G [00:50<00:16, 30.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:  76% 1.50G/1.98G [00:50<00:15, 32.0MB/s]\n","model-00004-of-00004.safetensors:  86% 1.52G/1.76G [00:50<00:09, 25.4MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  74% 1.44G/1.94G [00:50<00:19, 25.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  87% 1.53G/1.76G [00:50<00:07, 30.1MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  77% 1.50G/1.96G [00:51<00:17, 26.6MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  75% 1.45G/1.94G [00:51<00:15, 31.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  87% 1.53G/1.76G [00:51<00:07, 31.3MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  76% 1.50G/1.98G [00:51<00:18, 25.2MB/s]\n","\n","model-00003-of-00004.safetensors:  76% 1.51G/1.98G [00:51<00:15, 30.1MB/s]\n","\n","model-00001-of-00004.safetensors:  77% 1.51G/1.96G [00:51<00:14, 30.9MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  87% 1.54G/1.76G [00:51<00:08, 27.0MB/s]\u001b[A\n","model-00004-of-00004.safetensors:  87% 1.54G/1.76G [00:51<00:06, 31.9MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  77% 1.52G/1.98G [00:51<00:14, 31.6MB/s]\n","model-00004-of-00004.safetensors:  88% 1.55G/1.76G [00:51<00:06, 33.7MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  78% 1.52G/1.96G [00:51<00:16, 25.8MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  76% 1.46G/1.94G [00:51<00:15, 30.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  78% 1.53G/1.96G [00:51<00:13, 31.2MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  77% 1.52G/1.98G [00:51<00:17, 26.0MB/s]\n","\n","model-00001-of-00004.safetensors:  78% 1.53G/1.96G [00:51<00:13, 32.2MB/s]\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  77% 1.53G/1.98G [00:51<00:15, 29.9MB/s]\n","model-00003-of-00004.safetensors:  77% 1.53G/1.98G [00:51<00:13, 32.9MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  76% 1.47G/1.94G [00:51<00:19, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  78% 1.54G/1.96G [00:52<00:15, 27.2MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  89% 1.56G/1.76G [00:52<00:05, 34.5MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  76% 1.48G/1.94G [00:52<00:14, 31.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  89% 1.57G/1.76G [00:52<00:05, 35.6MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  79% 1.54G/1.96G [00:52<00:13, 31.0MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  78% 1.54G/1.98G [00:52<00:18, 24.6MB/s]\n","\n","model-00001-of-00004.safetensors:  79% 1.55G/1.96G [00:52<00:12, 34.0MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  77% 1.49G/1.94G [00:52<00:13, 33.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  78% 1.54G/1.98G [00:52<00:14, 30.3MB/s]\n","\n","model-00001-of-00004.safetensors:  79% 1.55G/1.96G [00:52<00:11, 34.1MB/s]\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  78% 1.55G/1.98G [00:52<00:12, 34.0MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  77% 1.49G/1.94G [00:52<00:18, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  90% 1.58G/1.76G [00:52<00:05, 32.9MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  78% 1.55G/1.98G [00:52<00:17, 24.2MB/s]\n","model-00003-of-00004.safetensors:  79% 1.57G/1.98G [00:52<00:09, 42.6MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  78% 1.50G/1.94G [00:52<00:13, 31.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  90% 1.59G/1.76G [00:53<00:05, 34.0MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  79% 1.55G/1.96G [00:53<00:23, 17.2MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  78% 1.51G/1.94G [00:53<00:12, 35.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  80% 1.56G/1.96G [00:53<00:21, 18.2MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  91% 1.60G/1.76G [00:53<00:04, 34.0MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  78% 1.52G/1.94G [00:53<00:11, 38.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  80% 1.56G/1.96G [00:53<00:19, 20.8MB/s]\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  79% 1.57G/1.98G [00:53<00:16, 25.3MB/s]\n","model-00004-of-00004.safetensors:  91% 1.61G/1.76G [00:53<00:03, 44.9MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:  80% 1.58G/1.98G [00:53<00:13, 29.5MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  78% 1.52G/1.94G [00:53<00:16, 25.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  80% 1.57G/1.96G [00:53<00:12, 29.6MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  79% 1.53G/1.94G [00:53<00:12, 31.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  80% 1.58G/1.98G [00:53<00:13, 29.8MB/s]\n","\n","model-00001-of-00004.safetensors:  81% 1.58G/1.96G [00:53<00:13, 28.7MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  92% 1.62G/1.76G [00:53<00:03, 38.0MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  79% 1.53G/1.94G [00:53<00:13, 29.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  81% 1.58G/1.96G [00:53<00:12, 29.2MB/s]\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  80% 1.59G/1.98G [00:53<00:15, 25.0MB/s]\n","model-00004-of-00004.safetensors:  92% 1.63G/1.76G [00:54<00:03, 36.1MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  80% 1.59G/1.98G [00:54<00:13, 28.9MB/s]\n","\n","model-00001-of-00004.safetensors:  81% 1.59G/1.96G [00:54<00:15, 24.1MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  81% 1.60G/1.98G [00:54<00:12, 32.1MB/s]\n","\n","model-00001-of-00004.safetensors:  81% 1.59G/1.96G [00:54<00:12, 28.9MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  93% 1.63G/1.76G [00:54<00:04, 32.2MB/s]\u001b[A\n","model-00004-of-00004.safetensors:  93% 1.64G/1.76G [00:54<00:03, 32.8MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  80% 1.55G/1.94G [00:54<00:12, 31.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  81% 1.59G/1.96G [00:54<00:12, 28.3MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  93% 1.64G/1.76G [00:54<00:03, 33.5MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  80% 1.55G/1.94G [00:54<00:12, 32.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:  81% 1.60G/1.98G [00:54<00:16, 22.5MB/s]\n","model-00003-of-00004.safetensors:  81% 1.61G/1.98G [00:54<00:12, 30.3MB/s]\n","\n","model-00001-of-00004.safetensors:  82% 1.60G/1.96G [00:54<00:16, 21.9MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  94% 1.65G/1.76G [00:54<00:03, 30.3MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  80% 1.55G/1.94G [00:54<00:17, 21.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  82% 1.61G/1.96G [00:54<00:10, 32.0MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  94% 1.66G/1.76G [00:54<00:03, 31.1MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  82% 1.62G/1.98G [00:54<00:11, 31.0MB/s]\n","\n","model-00003-of-00004.safetensors:  82% 1.62G/1.98G [00:55<00:11, 32.1MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  81% 1.56G/1.94G [00:55<00:13, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  82% 1.62G/1.98G [00:55<00:10, 33.4MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:  82% 1.63G/1.98G [00:55<00:09, 37.9MB/s]\n","model-00004-of-00004.safetensors:  94% 1.67G/1.76G [00:55<00:03, 26.0MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  81% 1.57G/1.94G [00:55<00:16, 22.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  95% 1.68G/1.76G [00:55<00:01, 45.8MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  83% 1.62G/1.96G [00:55<00:18, 18.2MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  82% 1.63G/1.98G [00:55<00:12, 28.5MB/s]\n","\n","model-00001-of-00004.safetensors:  83% 1.62G/1.96G [00:55<00:15, 21.7MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  83% 1.64G/1.98G [00:55<00:11, 30.6MB/s]\n","model-00004-of-00004.safetensors:  95% 1.68G/1.76G [00:55<00:02, 35.1MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:  83% 1.64G/1.98G [00:55<00:10, 31.1MB/s]\n","model-00004-of-00004.safetensors:  96% 1.69G/1.76G [00:55<00:02, 36.9MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:  83% 1.65G/1.98G [00:55<00:10, 32.3MB/s]\n","model-00004-of-00004.safetensors:  96% 1.69G/1.76G [00:55<00:01, 37.6MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  82% 1.59G/1.94G [00:55<00:13, 25.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  83% 1.65G/1.98G [00:56<00:11, 28.4MB/s]\n","\n","model-00001-of-00004.safetensors:  83% 1.63G/1.96G [00:56<00:13, 23.2MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  84% 1.65G/1.98G [00:56<00:10, 30.9MB/s]\n","\n","model-00001-of-00004.safetensors:  84% 1.64G/1.96G [00:56<00:11, 26.8MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  96% 1.70G/1.76G [00:56<00:02, 27.7MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  84% 1.66G/1.98G [00:56<00:10, 31.5MB/s]\n","\n","model-00001-of-00004.safetensors:  84% 1.64G/1.96G [00:56<00:10, 28.6MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  83% 1.60G/1.94G [00:56<00:13, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  97% 1.71G/1.76G [00:56<00:01, 30.0MB/s]\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  84% 1.66G/1.98G [00:56<00:12, 24.6MB/s]\n","\n","model-00001-of-00004.safetensors:  84% 1.65G/1.96G [00:56<00:13, 22.5MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  84% 1.67G/1.98G [00:56<00:09, 31.1MB/s]\n","model-00004-of-00004.safetensors:  97% 1.71G/1.76G [00:56<00:02, 24.8MB/s]\u001b[A\n","\n","model-00001-of-00004.safetensors:  85% 1.66G/1.96G [00:56<00:10, 29.2MB/s]\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  97% 1.72G/1.76G [00:56<00:01, 29.4MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:  85% 1.68G/1.98G [00:56<00:08, 34.2MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  83% 1.62G/1.94G [00:56<00:12, 25.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  98% 1.72G/1.76G [00:56<00:01, 31.9MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  84% 1.62G/1.94G [00:57<00:10, 29.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:  85% 1.68G/1.98G [00:57<00:11, 27.1MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  84% 1.63G/1.94G [00:57<00:08, 34.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  98% 1.73G/1.76G [00:57<00:01, 27.8MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:  85% 1.69G/1.98G [00:57<00:10, 28.7MB/s]\n","model-00004-of-00004.safetensors:  98% 1.73G/1.76G [00:57<00:00, 32.8MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:  85% 1.69G/1.98G [00:57<00:10, 28.8MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  84% 1.63G/1.94G [00:57<00:09, 30.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  99% 1.74G/1.76G [00:57<00:00, 32.8MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  85% 1.64G/1.94G [00:57<00:09, 31.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors:  99% 1.74G/1.76G [00:57<00:00, 33.4MB/s]\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  85% 1.64G/1.94G [00:57<00:09, 32.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  86% 1.68G/1.96G [00:57<00:11, 23.3MB/s]\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  86% 1.70G/1.98G [00:57<00:13, 21.2MB/s]\n","\n","model-00001-of-00004.safetensors:  86% 1.69G/1.96G [00:57<00:07, 34.6MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  85% 1.65G/1.94G [00:57<00:09, 29.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  86% 1.70G/1.98G [00:57<00:09, 29.1MB/s]\n","\n","model-00001-of-00004.safetensors:  87% 1.69G/1.96G [00:57<00:07, 33.9MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  85% 1.65G/1.94G [00:57<00:08, 31.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  86% 1.71G/1.98G [00:58<00:09, 27.6MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  85% 1.66G/1.94G [00:58<00:08, 32.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00003-of-00004.safetensors:  86% 1.71G/1.98G [00:58<00:09, 29.3MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  86% 1.66G/1.94G [00:58<00:08, 34.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model-00004-of-00004.safetensors: 100% 1.76G/1.76G [00:58<00:00, 30.3MB/s]\u001b[A\n","\n","model-00003-of-00004.safetensors:  87% 1.72G/1.98G [00:58<00:10, 24.7MB/s]\n","\n","\n","\n","model-00004-of-00004.safetensors: 100% 1.76G/1.76G [00:58<00:00, 30.2MB/s]\n","\n","\n","model-00003-of-00004.safetensors:  87% 1.72G/1.98G [00:58<00:09, 28.2MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  86% 1.67G/1.94G [00:58<00:08, 31.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:  87% 1.73G/1.98G [00:58<00:08, 31.9MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  87% 1.68G/1.94G [00:58<00:06, 38.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:  87% 1.73G/1.98G [00:58<00:10, 24.7MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  87% 1.68G/1.94G [00:58<00:08, 30.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  88% 1.74G/1.98G [00:59<00:06, 35.4MB/s]\n","\n","model-00003-of-00004.safetensors:  88% 1.74G/1.98G [00:59<00:06, 38.3MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  87% 1.69G/1.94G [00:59<00:06, 38.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:  88% 1.75G/1.98G [00:59<00:07, 32.6MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  88% 1.70G/1.94G [00:59<00:07, 33.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  88% 1.70G/1.94G [00:59<00:06, 38.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:  89% 1.76G/1.98G [00:59<00:05, 40.6MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  88% 1.71G/1.94G [00:59<00:05, 38.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:  89% 1.76G/1.98G [00:59<00:07, 30.3MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:  89% 1.77G/1.98G [00:59<00:05, 41.2MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  89% 1.72G/1.94G [00:59<00:05, 39.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:  90% 1.78G/1.98G [00:59<00:04, 44.6MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  89% 1.73G/1.94G [00:59<00:05, 41.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:  90% 1.78G/1.98G [01:00<00:05, 36.8MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:  90% 1.79G/1.98G [01:00<00:04, 45.6MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  90% 1.74G/1.94G [01:00<00:05, 38.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:  91% 1.80G/1.98G [01:00<00:04, 39.6MB/s]\n","\n","model-00003-of-00004.safetensors:  91% 1.80G/1.98G [01:00<00:04, 41.5MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  90% 1.74G/1.94G [01:00<00:06, 29.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  92% 1.82G/1.98G [01:00<00:03, 52.6MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  91% 1.76G/1.94G [01:00<00:04, 41.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  92% 1.79G/1.96G [01:01<00:06, 25.6MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  91% 1.77G/1.94G [01:01<00:03, 48.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:  92% 1.83G/1.98G [01:01<00:03, 41.8MB/s]\n","\n","model-00003-of-00004.safetensors:  93% 1.83G/1.98G [01:01<00:03, 44.0MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  92% 1.78G/1.94G [01:01<00:04, 35.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  92% 1.81G/1.96G [01:01<00:04, 31.9MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  93% 1.84G/1.98G [01:01<00:03, 36.2MB/s]\n","\n","model-00003-of-00004.safetensors:  93% 1.85G/1.98G [01:01<00:03, 41.5MB/s]\n","\n","model-00001-of-00004.safetensors:  93% 1.82G/1.96G [01:01<00:03, 39.5MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  93% 1.80G/1.94G [01:01<00:03, 37.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  93% 1.83G/1.96G [01:01<00:03, 34.6MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  93% 1.81G/1.94G [01:01<00:02, 45.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  94% 1.83G/1.96G [01:02<00:03, 39.8MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  94% 1.86G/1.98G [01:02<00:04, 30.8MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:  94% 1.86G/1.98G [01:02<00:03, 37.8MB/s]\n","\n","model-00001-of-00004.safetensors:  94% 1.84G/1.96G [01:02<00:04, 27.4MB/s]\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:  94% 1.87G/1.98G [01:02<00:03, 32.8MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:  95% 1.89G/1.98G [01:02<00:01, 49.3MB/s]\n","\n","model-00001-of-00004.safetensors:  95% 1.86G/1.96G [01:02<00:02, 37.0MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  95% 1.83G/1.94G [01:02<00:02, 35.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:  96% 1.90G/1.98G [01:03<00:01, 42.8MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  95% 1.84G/1.94G [01:03<00:03, 31.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  96% 1.87G/1.96G [01:03<00:02, 37.0MB/s]\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  96% 1.88G/1.96G [01:03<00:02, 38.6MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  95% 1.85G/1.94G [01:03<00:02, 36.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  96% 1.88G/1.96G [01:03<00:01, 45.6MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  96% 1.86G/1.94G [01:03<00:01, 44.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  96% 1.86G/1.94G [01:03<00:01, 39.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  96% 1.89G/1.96G [01:03<00:02, 31.0MB/s]\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  97% 1.90G/1.96G [01:03<00:01, 48.2MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  97% 1.87G/1.94G [01:03<00:02, 32.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  97% 1.91G/1.96G [01:03<00:01, 41.1MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  97% 1.88G/1.94G [01:03<00:01, 39.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:  96% 1.90G/1.98G [01:04<00:04, 15.8MB/s]\n","\n","\n","\n","model-00003-of-00004.safetensors:  97% 1.91G/1.98G [01:04<00:03, 21.6MB/s]\n","\n","model-00001-of-00004.safetensors:  98% 1.92G/1.96G [01:04<00:01, 36.1MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors:  98% 1.89G/1.94G [01:04<00:01, 36.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:  97% 1.92G/1.98G [01:04<00:02, 24.2MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  98% 1.90G/1.94G [01:04<00:00, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00003-of-00004.safetensors:  98% 1.93G/1.98G [01:04<00:01, 33.7MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  98% 1.91G/1.94G [01:04<00:00, 34.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors:  99% 1.94G/1.96G [01:04<00:00, 32.9MB/s]\u001b[A\u001b[A\n","\n","\n","\n","model-00003-of-00004.safetensors:  98% 1.94G/1.98G [01:04<00:01, 33.8MB/s]\n","\n","model-00003-of-00004.safetensors:  98% 1.94G/1.98G [01:04<00:01, 34.5MB/s]\n","\n","model-00003-of-00004.safetensors:  98% 1.95G/1.98G [01:05<00:00, 39.1MB/s]\n","\n","\n","\n","model-00002-of-00004.safetensors:  99% 1.92G/1.94G [01:05<00:00, 37.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","model-00002-of-00004.safetensors: 100% 1.93G/1.94G [01:05<00:00, 47.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","model-00001-of-00004.safetensors: 100% 1.96G/1.96G [01:05<00:00, 30.0MB/s]\n","model-00002-of-00004.safetensors: 100% 1.94G/1.94G [01:05<00:00, 29.5MB/s]\n","model-00003-of-00004.safetensors: 100% 1.98G/1.98G [01:05<00:00, 30.1MB/s]\n","\n","\n","\n","Upload 4 LFS files: 100% 4/4 [01:06<00:00, 16.56s/it]\n","[INFO|tokenization_utils_base.py:2488] 2024-05-17 15:05:13,253 >> tokenizer config file saved in phi_lora_merged/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2497] 2024-05-17 15:05:13,254 >> Special tokens file saved in phi_lora_merged/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2488] 2024-05-17 15:05:13,396 >> tokenizer config file saved in /tmp/tmpup4brx2t/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2497] 2024-05-17 15:05:13,396 >> Special tokens file saved in /tmp/tmpup4brx2t/special_tokens_map.json\n","[INFO|hub.py:757] 2024-05-17 15:05:13,431 >> Uploading the following files to bertilmuth/phi-3-mini-4k: tokenizer_config.json,special_tokens_map.json,tokenizer.json,README.md,added_tokens.json,tokenizer.model\n"]}],"source":["import json\n","\n","%cd /content/LLaMA-Factory\n","args = dict(\n","  model_name_or_path=hf_base_model_id,             # the hugging face model id\n","  adapter_name_or_path=adapter_name,            # load the saved LoRA adapters\n","  template=llamafactory_template_name,          # same to the one in training\n","  finetuning_type=\"lora\",                  # same to the one in training\n","  export_dir=saved_merged_model_path,              # the path to save the merged model\n","  export_size=2,                       # the file shard size (in GB) of the merged model\n","  export_device=\"cpu\",                    # the device used in export, can be chosen from `cpu` and `cuda`\n","  export_hub_model_id=hf_finetuned_model_id      # the Hugging Face hub ID to upload model\n",")\n","\n","json.dump(args, open(\"merge_file.json\", \"w\", encoding=\"utf-8\"), indent=2)\n","!llamafactory-cli export merge_file.json"]},{"cell_type":"markdown","metadata":{"id":"Xql1l-4PLfNI"},"source":["### Zip the adapters and upload them to Google Drive"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"PpR9v-LyLjqF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715958373732,"user_tz":-120,"elapsed":3887,"user":{"displayName":"Bertil Muth","userId":"02558266373806387996"}},"outputId":"82af775e-62c3-4a34-beb8-0934fad84cec"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/LLaMA-Factory\n","  adding: phi_lora/ (stored 0%)\n","  adding: phi_lora/adapter_config.json (deflated 53%)\n","  adding: phi_lora/tokenizer_config.json (deflated 82%)\n","  adding: phi_lora/special_tokens_map.json (deflated 78%)\n","  adding: phi_lora/tokenizer.json (deflated 74%)\n","  adding: phi_lora/trainer_state.json (deflated 77%)\n","  adding: phi_lora/all_results.json (deflated 37%)\n","  adding: phi_lora/train_results.json (deflated 37%)\n","  adding: phi_lora/adapter_model.safetensors (deflated 8%)\n","  adding: phi_lora/training_args.bin (deflated 51%)\n","  adding: phi_lora/README.md (deflated 47%)\n","  adding: phi_lora/trainer_log.jsonl (deflated 82%)\n","  adding: phi_lora/added_tokens.json (deflated 62%)\n","  adding: phi_lora/runs/ (stored 0%)\n","  adding: phi_lora/runs/May17_13-35-26_a18b2cc96999/ (stored 0%)\n","  adding: phi_lora/runs/May17_13-35-26_a18b2cc96999/events.out.tfevents.1715952946.a18b2cc96999.106210.0 (deflated 66%)\n","  adding: phi_lora/tokenizer.model (deflated 55%)\n"]}],"source":["%cd /content/LLaMA-Factory\n","directory_to_zip = adapter_name  # Change this to your directory\n","zip_output_path = f'{adapter_name}.zip'  # Change this to your desired output zip file name\n","drive_zip_output_path = f'/content/drive/MyDrive/{adapter_name}.zip'  # Change this to your desired location on Google Drive\n","\n","!zip -r $zip_output_path $directory_to_zip\n","!mv $zip_output_path $drive_zip_output_path\n"]},{"cell_type":"markdown","metadata":{"id":"TaJ8kgJ6SXLL"},"source":["### Infer 100 different SysML v2 models"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"d0zWn87qSb3R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715962876541,"user_tz":-120,"elapsed":119003,"user":{"displayName":"Bertil Muth","userId":"02558266373806387996"}},"outputId":"d9fc8933-f8b6-4ecd-8814-4f090a326b7e"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["/content/LLaMA-Factory\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","[INFO|tokenization_utils_base.py:2087] 2024-05-17 15:07:26,330 >> loading file tokenizer.model from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/8f5f3a02ec472594e949c39f8e38c7be8d983bcd/tokenizer.model\n","[INFO|tokenization_utils_base.py:2087] 2024-05-17 15:07:26,331 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/8f5f3a02ec472594e949c39f8e38c7be8d983bcd/tokenizer.json\n","[INFO|tokenization_utils_base.py:2087] 2024-05-17 15:07:26,332 >> loading file added_tokens.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/8f5f3a02ec472594e949c39f8e38c7be8d983bcd/added_tokens.json\n","[INFO|tokenization_utils_base.py:2087] 2024-05-17 15:07:26,333 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/8f5f3a02ec472594e949c39f8e38c7be8d983bcd/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2087] 2024-05-17 15:07:26,334 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/8f5f3a02ec472594e949c39f8e38c7be8d983bcd/tokenizer_config.json\n","[WARNING|logging.py:314] 2024-05-17 15:07:26,405 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["05/17/2024 15:07:26 - INFO - llamafactory.data.template - Replace eos token: <|end|>\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["INFO:llamafactory.data.template:Replace eos token: <|end|>\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["05/17/2024 15:07:26 - WARNING - llamafactory.data.template - New tokens have been added, make sure `resize_vocab` is True.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:llamafactory.data.template:New tokens have been added, make sure `resize_vocab` is True.\n","[INFO|configuration_utils.py:726] 2024-05-17 15:07:26,463 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/8f5f3a02ec472594e949c39f8e38c7be8d983bcd/config.json\n","[INFO|configuration_utils.py:726] 2024-05-17 15:07:26,588 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/8f5f3a02ec472594e949c39f8e38c7be8d983bcd/config.json\n","[INFO|configuration_utils.py:789] 2024-05-17 15:07:26,590 >> Model config Phi3Config {\n","  \"_name_or_path\": \"microsoft/Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"microsoft/Phi-3-mini-4k-instruct--configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-4k-instruct--modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.40.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["05/17/2024 15:07:26 - INFO - llamafactory.model.utils.quantization - Quantizing model to 4 bit.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["INFO:llamafactory.model.utils.quantization:Quantizing model to 4 bit.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["05/17/2024 15:07:26 - INFO - llamafactory.model.patcher - Using KV cache for faster generation.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["INFO:llamafactory.model.patcher:Using KV cache for faster generation.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["05/17/2024 15:07:26 - INFO - llamafactory.model.adapter - Upcasting trainable params to float32.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["INFO:llamafactory.model.adapter:Upcasting trainable params to float32.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["05/17/2024 15:07:26 - INFO - llamafactory.model.adapter - Fine-tuning method: LoRA\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["INFO:llamafactory.model.adapter:Fine-tuning method: LoRA\n","[INFO|configuration_utils.py:726] 2024-05-17 15:07:27,133 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--unsloth--Phi-3-mini-4k-instruct-bnb-4bit/snapshots/1d9acd8f0e086359470add802aae229331797163/config.json\n","[INFO|configuration_utils.py:789] 2024-05-17 15:07:27,136 >> Model config MistralConfig {\n","  \"_name_or_path\": \"unsloth/Phi-3-mini-4k-instruct-bnb-4bit\",\n","  \"architectures\": [\n","    \"MistralForCausalLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 1,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"mistral\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"pad_token_id\": 32000,\n","  \"quantization_config\": {\n","    \"_load_in_4bit\": true,\n","    \"_load_in_8bit\": false,\n","    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n","    \"bnb_4bit_quant_storage\": \"uint8\",\n","    \"bnb_4bit_quant_type\": \"nf4\",\n","    \"bnb_4bit_use_double_quant\": true,\n","    \"llm_int8_enable_fp32_cpu_offload\": false,\n","    \"llm_int8_has_fp16_weight\": false,\n","    \"llm_int8_skip_modules\": null,\n","    \"llm_int8_threshold\": 6.0,\n","    \"load_in_4bit\": true,\n","    \"load_in_8bit\": false,\n","    \"quant_method\": \"bitsandbytes\"\n","  },\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2048,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.40.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","[INFO|configuration_utils.py:726] 2024-05-17 15:07:27,188 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--unsloth--Phi-3-mini-4k-instruct-bnb-4bit/snapshots/1d9acd8f0e086359470add802aae229331797163/config.json\n","[INFO|configuration_utils.py:789] 2024-05-17 15:07:27,190 >> Model config MistralConfig {\n","  \"_name_or_path\": \"unsloth/Phi-3-mini-4k-instruct-bnb-4bit\",\n","  \"architectures\": [\n","    \"MistralForCausalLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 1,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"mistral\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"pad_token_id\": 32000,\n","  \"quantization_config\": {\n","    \"_load_in_4bit\": true,\n","    \"_load_in_8bit\": false,\n","    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n","    \"bnb_4bit_quant_storage\": \"uint8\",\n","    \"bnb_4bit_quant_type\": \"nf4\",\n","    \"bnb_4bit_use_double_quant\": true,\n","    \"llm_int8_enable_fp32_cpu_offload\": false,\n","    \"llm_int8_has_fp16_weight\": false,\n","    \"llm_int8_skip_modules\": null,\n","    \"llm_int8_threshold\": 6.0,\n","    \"load_in_4bit\": true,\n","    \"load_in_8bit\": false,\n","    \"quant_method\": \"bitsandbytes\"\n","  },\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2048,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.40.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","[INFO|configuration_utils.py:726] 2024-05-17 15:07:27,248 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--unsloth--Phi-3-mini-4k-instruct-bnb-4bit/snapshots/1d9acd8f0e086359470add802aae229331797163/config.json\n","[INFO|configuration_utils.py:789] 2024-05-17 15:07:27,250 >> Model config MistralConfig {\n","  \"_name_or_path\": \"unsloth/Phi-3-mini-4k-instruct-bnb-4bit\",\n","  \"architectures\": [\n","    \"MistralForCausalLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 1,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"mistral\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"pad_token_id\": 32000,\n","  \"quantization_config\": {\n","    \"_load_in_4bit\": true,\n","    \"_load_in_8bit\": false,\n","    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n","    \"bnb_4bit_quant_storage\": \"uint8\",\n","    \"bnb_4bit_quant_type\": \"nf4\",\n","    \"bnb_4bit_use_double_quant\": true,\n","    \"llm_int8_enable_fp32_cpu_offload\": false,\n","    \"llm_int8_has_fp16_weight\": false,\n","    \"llm_int8_skip_modules\": null,\n","    \"llm_int8_threshold\": 6.0,\n","    \"load_in_4bit\": true,\n","    \"load_in_8bit\": false,\n","    \"quant_method\": \"bitsandbytes\"\n","  },\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2048,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.40.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","[INFO|modeling_utils.py:3429] 2024-05-17 15:07:27,287 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--unsloth--Phi-3-mini-4k-instruct-bnb-4bit/snapshots/1d9acd8f0e086359470add802aae229331797163/model.safetensors\n","[INFO|modeling_utils.py:1494] 2024-05-17 15:07:27,332 >> Instantiating MistralForCausalLM model under default dtype torch.bfloat16.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["==((====))==  Unsloth: Fast Mistral patching release 2024.5\n","   \\\\   /|    GPU: NVIDIA A100-SXM4-40GB. Max memory: 39.564 GB. Platform = Linux.\n","O^O/ \\_/ \\    Pytorch: 2.2.1+cu121. CUDA = 8.0. CUDA Toolkit = 12.1.\n","\\        /    Bfloat16 = TRUE. Xformers = 0.0.25. FA = False.\n"," \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["[INFO|configuration_utils.py:928] 2024-05-17 15:07:27,338 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 1,\n","  \"eos_token_id\": 32000,\n","  \"pad_token_id\": 32000\n","}\n","\n","[INFO|modeling_utils.py:4170] 2024-05-17 15:07:29,302 >> All model checkpoint weights were used when initializing MistralForCausalLM.\n","\n","[INFO|modeling_utils.py:4178] 2024-05-17 15:07:29,304 >> All the weights of MistralForCausalLM were initialized from the model checkpoint at unsloth/Phi-3-mini-4k-instruct-bnb-4bit.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use MistralForCausalLM for predictions without further training.\n","[INFO|configuration_utils.py:883] 2024-05-17 15:07:29,366 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--unsloth--Phi-3-mini-4k-instruct-bnb-4bit/snapshots/1d9acd8f0e086359470add802aae229331797163/generation_config.json\n","[INFO|configuration_utils.py:928] 2024-05-17 15:07:29,367 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 1,\n","  \"eos_token_id\": 32000,\n","  \"pad_token_id\": 32000\n","}\n","\n","[INFO|tokenization_utils_base.py:2085] 2024-05-17 15:07:29,618 >> loading file tokenizer.model\n","[INFO|tokenization_utils_base.py:2085] 2024-05-17 15:07:29,619 >> loading file added_tokens.json\n","[INFO|tokenization_utils_base.py:2085] 2024-05-17 15:07:29,620 >> loading file special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2085] 2024-05-17 15:07:29,620 >> loading file tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2085] 2024-05-17 15:07:29,621 >> loading file tokenizer.json\n","[WARNING|logging.py:314] 2024-05-17 15:07:29,688 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","[INFO|tokenization_utils_base.py:2085] 2024-05-17 15:07:29,690 >> loading file tokenizer.model\n","[INFO|tokenization_utils_base.py:2085] 2024-05-17 15:07:29,691 >> loading file tokenizer.json\n","[INFO|tokenization_utils_base.py:2085] 2024-05-17 15:07:29,692 >> loading file added_tokens.json\n","[INFO|tokenization_utils_base.py:2085] 2024-05-17 15:07:29,693 >> loading file special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2085] 2024-05-17 15:07:29,694 >> loading file tokenizer_config.json\n","[WARNING|logging.py:314] 2024-05-17 15:07:29,758 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","[WARNING|logging.py:329] 2024-05-17 15:07:31,211 >> Unsloth 2024.5 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["05/17/2024 15:07:31 - INFO - llamafactory.model.adapter - Loaded adapter(s): phi_lora\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["INFO:llamafactory.model.adapter:Loaded adapter(s): phi_lora\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["05/17/2024 15:07:31 - INFO - llamafactory.model.loader - all params: 3836021760\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["INFO:llamafactory.model.loader:all params: 3836021760\n"]},{"output_type":"stream","name":"stdout","text":["Created sysml v2 model no. 1\n","Created sysml v2 model no. 2\n","Created sysml v2 model no. 3\n","Created sysml v2 model no. 4\n","Created sysml v2 model no. 5\n","Created sysml v2 model no. 6\n","Created sysml v2 model no. 7\n","Created sysml v2 model no. 8\n","Created sysml v2 model no. 9\n","Created sysml v2 model no. 10\n","Created sysml v2 model no. 11\n","Created sysml v2 model no. 12\n","Created sysml v2 model no. 13\n","Created sysml v2 model no. 14\n","Created sysml v2 model no. 15\n","Created sysml v2 model no. 16\n","Created sysml v2 model no. 17\n","Created sysml v2 model no. 18\n","Created sysml v2 model no. 19\n","Created sysml v2 model no. 20\n","Created sysml v2 model no. 21\n","Created sysml v2 model no. 22\n","Created sysml v2 model no. 23\n","Created sysml v2 model no. 24\n","Created sysml v2 model no. 25\n","Created sysml v2 model no. 26\n","Created sysml v2 model no. 27\n","Created sysml v2 model no. 28\n","Created sysml v2 model no. 29\n","Created sysml v2 model no. 30\n","Created sysml v2 model no. 31\n","Created sysml v2 model no. 32\n","Created sysml v2 model no. 33\n","Created sysml v2 model no. 34\n","Created sysml v2 model no. 35\n","Created sysml v2 model no. 36\n","Created sysml v2 model no. 37\n","Created sysml v2 model no. 38\n","Created sysml v2 model no. 39\n","Created sysml v2 model no. 40\n","Created sysml v2 model no. 41\n","Created sysml v2 model no. 42\n","Created sysml v2 model no. 43\n","Created sysml v2 model no. 44\n","Created sysml v2 model no. 45\n","Created sysml v2 model no. 46\n","Created sysml v2 model no. 47\n","Created sysml v2 model no. 48\n","Created sysml v2 model no. 49\n","Created sysml v2 model no. 50\n","Created sysml v2 model no. 51\n","Created sysml v2 model no. 52\n","Created sysml v2 model no. 53\n","Created sysml v2 model no. 54\n","Created sysml v2 model no. 55\n","Created sysml v2 model no. 56\n","Created sysml v2 model no. 57\n","Created sysml v2 model no. 58\n","Created sysml v2 model no. 59\n","Created sysml v2 model no. 60\n","Created sysml v2 model no. 61\n","Created sysml v2 model no. 62\n","Created sysml v2 model no. 63\n","Created sysml v2 model no. 64\n","Created sysml v2 model no. 65\n","Created sysml v2 model no. 66\n","Created sysml v2 model no. 67\n","Created sysml v2 model no. 68\n","Created sysml v2 model no. 69\n","Created sysml v2 model no. 70\n","Created sysml v2 model no. 71\n","Created sysml v2 model no. 72\n","Created sysml v2 model no. 73\n","Created sysml v2 model no. 74\n","Created sysml v2 model no. 75\n","Created sysml v2 model no. 76\n","Created sysml v2 model no. 77\n","Created sysml v2 model no. 78\n","Created sysml v2 model no. 79\n","Created sysml v2 model no. 80\n","Created sysml v2 model no. 81\n","Created sysml v2 model no. 82\n","Created sysml v2 model no. 83\n","Created sysml v2 model no. 84\n","Created sysml v2 model no. 85\n","Created sysml v2 model no. 86\n","Created sysml v2 model no. 87\n","Created sysml v2 model no. 88\n","Created sysml v2 model no. 89\n","Created sysml v2 model no. 90\n","Created sysml v2 model no. 91\n","Created sysml v2 model no. 92\n","Created sysml v2 model no. 93\n","Created sysml v2 model no. 94\n","Created sysml v2 model no. 95\n","Created sysml v2 model no. 96\n","Created sysml v2 model no. 97\n","Created sysml v2 model no. 98\n","Created sysml v2 model no. 99\n","Created sysml v2 model no. 100\n","Created sysml v2 model no. 101\n","Created sysml v2 model no. 102\n","Created sysml v2 model no. 103\n","Created sysml v2 model no. 104\n","Created sysml v2 model no. 105\n","Created sysml v2 model no. 106\n","Created sysml v2 model no. 107\n","Created sysml v2 model no. 108\n","Created sysml v2 model no. 109\n","Created sysml v2 model no. 110\n","Created sysml v2 model no. 111\n","Created sysml v2 model no. 112\n","  adding: 100systems_sysml/ (stored 0%)\n","  adding: 100systems_sysml/Zero-Emission Vehicle Charging Network.sysml (deflated 75%)\n","  adding: 100systems_sysml/Xenobiotic Detection System.sysml (deflated 74%)\n","  adding: 100systems_sysml/Vaccine Research and Development Platform.sysml (deflated 76%)\n","  adding: 100systems_sysml/Kinematic Analysis Software.sysml (deflated 71%)\n","  adding: 100systems_sysml/Therapeutic Virtual Reality Environment.sysml (deflated 75%)\n","  adding: 100systems_sysml/Waste-to-Energy Conversion System.sysml (deflated 78%)\n","  adding: 100systems_sysml/Intelligent Drug Discovery System.sysml (deflated 77%)\n","  adding: 100systems_sysml/High Efficiency Photovoltaic System.sysml (deflated 71%)\n","  adding: 100systems_sysml/Journalistic Integrity Verification System.sysml (deflated 75%)\n","  adding: 100systems_sysml/Voice-Activated Home Assistant.sysml (deflated 75%)\n","  adding: 100systems_sysml/Fintech Blockchain Platform.sysml (deflated 74%)\n","  adding: 100systems_sysml/Automated Tax Compliance System.sysml (deflated 74%)\n","  adding: 100systems_sysml/Urban Air Mobility System.sysml (deflated 76%)\n","  adding: 100systems_sysml/Zettabyte File System.sysml (deflated 76%)\n","  adding: 100systems_sysml/Youth Mental Health Service Platform.sysml (deflated 77%)\n","  adding: 100systems_sysml/Genomic Data Analysis System.sysml (deflated 76%)\n","  adding: 100systems_sysml/Industrial Internet of Things Platform.sysml (deflated 73%)\n","  adding: 100systems_sysml/Biometric Authentication System.sysml (deflated 81%)\n","  adding: 100systems_sysml/Journalist's Digital Research Assistant.sysml (deflated 79%)\n","  adding: 100systems_sysml/Telehealth Service Platform.sysml (deflated 79%)\n","  adding: 100systems_sysml/Microbial Fuel Cell System.sysml (deflated 76%)\n","  adding: 100systems_sysml/Knowledge Graph-Based Recommendation System.sysml (deflated 74%)\n","  adding: 100systems_sysml/Knowledge Discovery in Databases System.sysml (deflated 80%)\n","  adding: 100systems_sysml/Elderly Care Robotic System.sysml (deflated 77%)\n","  adding: 100systems_sysml/Thermal Energy Storage System.sysml (deflated 71%)\n","  adding: 100systems_sysml/Multiphysics Simulation Software.sysml (deflated 83%)\n","  adding: 100systems_sysml/Vertical Farming Climate Control System.sysml (deflated 79%)\n","  adding: 100systems_sysml/Crowdsourced Weather Prediction Platform.sysml (deflated 76%)\n","  adding: 100systems_sysml/Extended Reality Collaboration Platform.sysml (deflated 74%)\n","  adding: 100systems_sysml/Junk Data Cleanup Software.sysml (deflated 74%)\n","  adding: 100systems_sysml/Augmented Reality Shopping Assistant.sysml (deflated 80%)\n","  adding: 100systems_sysml/High-Altitude Pseudo-Satellite System.sysml (deflated 76%)\n","  adding: 100systems_sysml/Fog Computing Network.sysml (deflated 72%)\n","  adding: 100systems_sysml/Neural Network Training Platform.sysml (deflated 75%)\n","  adding: 100systems_sysml/Fusion Energy Control System.sysml (deflated 78%)\n","  adding: 100systems_sysml/Quantum Annealing Solver.sysml (deflated 77%)\n","  adding: 100systems_sysml/Tidal Power Generation System.sysml (deflated 76%)\n","  adding: 100systems_sysml/Quantum Dot Display Manufacturing System.sysml (deflated 75%)\n","  adding: 100systems_sysml/Smart Grid Control System.sysml (deflated 75%)\n","  adding: 100systems_sysml/Laser Communication System.sysml (deflated 78%)\n","  adding: 100systems_sysml/Space Habitat Life Support System.sysml (deflated 76%)\n","  adding: 100systems_sysml/Biodegradable Material Processing System.sysml (deflated 78%)\n","  adding: 100systems_sysml/Automated Legal Reasoning System.sysml (deflated 79%)\n","  adding: 100systems_sysml/Distributed Autonomous Organization Management.sysml (deflated 71%)\n","  adding: 100systems_sysml/Smart Agriculture System.sysml (deflated 76%)\n","  adding: 100systems_sysml/Environmental Impact Assessment Tool.sysml (deflated 77%)\n","  adding: 100systems_sysml/Wind Farm Optimization System.sysml (deflated 79%)\n","  adding: 100systems_sysml/Nanostructured Material Development Kit.sysml (deflated 76%)\n","  adding: 100systems_sysml/Youth Sports Management Platform.sysml (deflated 77%)\n","  adding: 100systems_sysml/Plasma Waste Recycling System.sysml (deflated 75%)\n","  adding: 100systems_sysml/Language Learning Companion Bot.sysml (deflated 78%)\n","  adding: 100systems_sysml/Nutrient Recycling System.sysml (deflated 80%)\n","  adding: 100systems_sysml/Volumetric 3D Printing System.sysml (deflated 76%)\n","  adding: 100systems_sysml/Distributed Cloud Storage System.sysml (deflated 73%)\n","  adding: 100systems_sysml/Kinetic Energy Recovery System.sysml (deflated 74%)\n","  adding: 100systems_sysml/Youth Digital Inclusion Program.sysml (deflated 74%)\n","  adding: 100systems_sysml/Resilient Infrastructure Design Software.sysml (deflated 74%)\n","  adding: 100systems_sysml/Deep Sea Exploration System.sysml (deflated 73%)\n","  adding: 100systems_sysml/Personalized Learning Environment.sysml (deflated 76%)\n","  adding: 100systems_sysml/Ocean Current Energy Conversion System.sysml (deflated 75%)\n","  adding: 100systems_sysml/Facial Recognition Security System.sysml (deflated 77%)\n","  adding: 100systems_sysml/Ocean Acidification Monitoring System.sysml (deflated 71%)\n","  adding: 100systems_sysml/Offshore Aquaculture System.sysml (deflated 79%)\n","  adding: 100systems_sysml/Wildlife Monitoring System.sysml (deflated 77%)\n","  adding: 100systems_sysml/Hyperloop Transport System.sysml (deflated 74%)\n","  adding: 100systems_sysml/Zero-Knowledge Proof System.sysml (deflated 72%)\n","  adding: 100systems_sysml/Blockchain-based Voting System.sysml (deflated 77%)\n","  adding: 100systems_sysml/Renewable Energy Microgrid.sysml (deflated 80%)\n","  adding: 100systems_sysml/Rapid Prototyping Machine.sysml (deflated 71%)\n","  adding: 100systems_sysml/Quantum Sensor Network.sysml (deflated 73%)\n","  adding: 100systems_sysml/Remote Sensing Satellite System.sysml (deflated 76%)\n","  adding: 100systems_sysml/Gene Editing CRISPR Control System.sysml (deflated 77%)\n","  adding: 100systems_sysml/Wearable Translator Device.sysml (deflated 80%)\n","  adding: 100systems_sysml/Exascale Computing System.sysml (deflated 75%)\n","  adding: 100systems_sysml/Nano-Medicine Delivery System.sysml (deflated 69%)\n","  adding: 100systems_sysml/Drone-based Delivery System.sysml (deflated 75%)\n","  adding: 100systems_sysml/Self-Healing Material System.sysml (deflated 73%)\n","  adding: 100systems_sysml/Pervasive Computing System.sysml (deflated 78%)\n","  adding: 100systems_sysml/Wearable Health Monitoring System.sysml (deflated 73%)\n","  adding: 100systems_sysml/Haptic Feedback Virtual Reality System.sysml (deflated 79%)\n","  adding: 100systems_sysml/Urban Traffic Control System.sysml (deflated 77%)\n","  adding: 100systems_sysml/Quantum Computing Simulation System.sysml (deflated 71%)\n","  adding: 100systems_sysml/Cognitive Behavioral Therapy Application.sysml (deflated 76%)\n","  adding: 100systems_sysml/Space Junk Tracking System.sysml (deflated 73%)\n","  adding: 100systems_sysml/Ultra-High Definition Holographic Display.sysml (deflated 73%)\n","  adding: 100systems_sysml/Invasive Species Management Tool.sysml (deflated 73%)\n","  adding: 100systems_sysml/Jail Management System.sysml (deflated 75%)\n","  adding: 100systems_sysml/Intelligent Transportation Coordination System.sysml (deflated 78%)\n","  adding: 100systems_sysml/Molecular Manufacturing System.sysml (deflated 73%)\n","  adding: 100systems_sysml/Youth Entrepreneurship Support Platform.sysml (deflated 76%)\n","  adding: 100systems_sysml/X-ray Crystallography Data Analysis Software.sysml (deflated 78%)\n","  adding: 100systems_sysml/Underground Transportation System.sysml (deflated 74%)\n","  adding: 100systems_sysml/Emergency Response Coordination System.sysml (deflated 79%)\n","  adding: 100systems_sysml/Exoplanet Discovery System.sysml (deflated 76%)\n","  adding: 100systems_sysml/Green Building Management System.sysml (deflated 75%)\n","  adding: 100systems_sysml/Quantum Key Distribution System.sysml (deflated 71%)\n","  adding: 100systems_sysml/Synthetic Biology Engineering Platform.sysml (deflated 76%)\n","  adding: 100systems_sysml/Blockchain-based Supply Chain Verification.sysml (deflated 79%)\n","  adding: 100systems_sysml/Liquid Metal Battery System.sysml (deflated 72%)\n","  adding: 100systems_sysml/Automated Contract Enforcement System.sysml (deflated 74%)\n","  adding: 100systems_sysml/Organ-on-a-Chip Testing Platform.sysml (deflated 73%)\n","  adding: 100systems_sysml/Smart Contract Audit Platform.sysml (deflated 75%)\n","  adding: 100systems_sysml/Digital Twin for Industrial Automation.sysml (deflated 74%)\n","  adding: 100systems_sysml/Cryptographic Currency Exchange.sysml (deflated 77%)\n","  adding: 100systems_sysml/Carbon Capture and Storage System.sysml (deflated 73%)\n","  adding: 100systems_sysml/Precision Agriculture Decision Support System.sysml (deflated 80%)\n","  adding: 100systems_sysml/Graphene Production Facility.sysml (deflated 73%)\n","  adding: 100systems_sysml/Unmanned Combat Aerial Vehicle System.sysml (deflated 80%)\n","  adding: 100systems_sysml/Municipal Waste Sorting System.sysml (deflated 68%)\n","  adding: 100systems_sysml/Underwater Communication System.sysml (deflated 73%)\n","  adding: 100systems_sysml/Zero-Trust Network Architecture.sysml (deflated 81%)\n","  adding: 100systems_sysml/Low Earth Orbit Satellite Internet System.sysml (deflated 72%)\n"]}],"source":["import os\n","from llamafactory.chat import ChatModel\n","from llamafactory.extras.misc import torch_gc\n","\n","# Change directory to where LLaMA-Factory is located\n","%cd /content/LLaMA-Factory/\n","\n","technical_systems = [\n","    \"Underwater Communication System\",\n","    \"Smart Grid Control System\",\n","    \"Quantum Key Distribution System\",\n","    \"Space Habitat Life Support System\",\n","    \"Deep Sea Exploration System\",\n","    \"Smart Agriculture System\",\n","    \"Urban Traffic Control System\",\n","    \"Wildlife Monitoring System\",\n","    \"Automated Legal Reasoning System\",\n","    \"Blockchain-based Voting System\",\n","    \"Cryptographic Currency Exchange\",\n","    \"Distributed Cloud Storage System\",\n","    \"Elderly Care Robotic System\",\n","    \"Facial Recognition Security System\",\n","    \"Gene Editing CRISPR Control System\",\n","    \"Haptic Feedback Virtual Reality System\",\n","    \"Intelligent Transportation Coordination System\",\n","    \"Jail Management System\",\n","    \"Kinetic Energy Recovery System\",\n","    \"Laser Communication System\",\n","    \"Municipal Waste Sorting System\",\n","    \"Nano-Medicine Delivery System\",\n","    \"Ocean Current Energy Conversion System\",\n","    \"Pervasive Computing System\",\n","    \"Quantum Computing Simulation System\",\n","    \"Remote Sensing Satellite System\",\n","    \"Synthetic Biology Engineering Platform\",\n","    \"Thermal Energy Storage System\",\n","    \"Unmanned Combat Aerial Vehicle System\",\n","    \"Volumetric 3D Printing System\",\n","    \"Wearable Health Monitoring System\",\n","    \"Exoplanet Discovery System\",\n","    \"Youth Sports Management Platform\",\n","    \"Zero-Emission Vehicle Charging Network\",\n","    \"Automated Tax Compliance System\",\n","    \"Biometric Authentication System\",\n","    \"Crowdsourced Weather Prediction Platform\",\n","    \"Drone-based Delivery System\",\n","    \"Emergency Response Coordination System\",\n","    \"Fintech Blockchain Platform\",\n","    \"Green Building Management System\",\n","    \"High-Altitude Pseudo-Satellite System\",\n","    \"Intelligent Drug Discovery System\",\n","    \"Junk Data Cleanup Software\",\n","    \"Knowledge Discovery in Databases System\",\n","    \"Low Earth Orbit Satellite Internet System\",\n","    \"Molecular Manufacturing System\",\n","    \"Neural Network Training Platform\",\n","    \"Ocean Acidification Monitoring System\",\n","    \"Precision Agriculture Decision Support System\",\n","    \"Quantum Sensor Network\",\n","    \"Renewable Energy Microgrid\",\n","    \"Space Junk Tracking System\",\n","    \"Telehealth Service Platform\",\n","    \"Underground Transportation System\",\n","    \"Vaccine Research and Development Platform\",\n","    \"Wind Farm Optimization System\",\n","    \"Xenobiotic Detection System\",\n","    \"Youth Mental Health Service Platform\",\n","    \"Zero-Knowledge Proof System\",\n","    \"Automated Contract Enforcement System\",\n","    \"Biodegradable Material Processing System\",\n","    \"Carbon Capture and Storage System\",\n","    \"Digital Twin for Industrial Automation\",\n","    \"Exascale Computing System\",\n","    \"Fusion Energy Control System\",\n","    \"Genomic Data Analysis System\",\n","    \"Hyperloop Transport System\",\n","    \"Industrial Internet of Things Platform\",\n","    \"Journalist's Digital Research Assistant\",\n","    \"Knowledge Graph-Based Recommendation System\",\n","    \"Liquid Metal Battery System\",\n","    \"Microbial Fuel Cell System\",\n","    \"Nanostructured Material Development Kit\",\n","    \"Offshore Aquaculture System\",\n","    \"Personalized Learning Environment\",\n","    \"Quantum Dot Display Manufacturing System\",\n","    \"Rapid Prototyping Machine\",\n","    \"Self-Healing Material System\",\n","    \"Tidal Power Generation System\",\n","    \"Urban Air Mobility System\",\n","    \"Vertical Farming Climate Control System\",\n","    \"Wearable Translator Device\",\n","    \"Extended Reality Collaboration Platform\",\n","    \"Youth Digital Inclusion Program\",\n","    \"Zettabyte File System\",\n","    \"Augmented Reality Shopping Assistant\",\n","    \"Blockchain-based Supply Chain Verification\",\n","    \"Cognitive Behavioral Therapy Application\",\n","    \"Distributed Autonomous Organization Management\",\n","    \"Environmental Impact Assessment Tool\",\n","    \"Fog Computing Network\",\n","    \"Graphene Production Facility\",\n","    \"High Efficiency Photovoltaic System\",\n","    \"Invasive Species Management Tool\",\n","    \"Journalistic Integrity Verification System\",\n","    \"Kinematic Analysis Software\",\n","    \"Language Learning Companion Bot\",\n","    \"Multiphysics Simulation Software\",\n","    \"Nutrient Recycling System\",\n","    \"Organ-on-a-Chip Testing Platform\",\n","    \"Plasma Waste Recycling System\",\n","    \"Quantum Annealing Solver\",\n","    \"Resilient Infrastructure Design Software\",\n","    \"Smart Contract Audit Platform\",\n","    \"Therapeutic Virtual Reality Environment\",\n","    \"Ultra-High Definition Holographic Display\",\n","    \"Voice-Activated Home Assistant\",\n","    \"Waste-to-Energy Conversion System\",\n","    \"X-ray Crystallography Data Analysis Software\",\n","    \"Youth Entrepreneurship Support Platform\",\n","    \"Zero-Trust Network Architecture\"\n","]\n","\n","# Setup chat model arguments\n","args = dict(\n","  model_name_or_path=hf_base_model_id,\n","  adapter_name_or_path=adapter_name,      # load the saved LoRA adapters\n","  template=llamafactory_template_name,                     # same to the one in training\n","  finetuning_type=\"lora\",                  # same to the one in training\n","  quantization_bit=4,                    # load 4-bit quantized model\n","  use_unsloth=True,                     # don't use UnslothAI's LoRA optimization for 2x faster generation\n",")\n","\n","# Initialize the chat model\n","chat_model = ChatModel(args)\n","\n","# Ensure the sysml_files directory exists\n","output_dir = '100systems_sysml'\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# Iterate over the technical system names\n","n = 0\n","for technical_system in technical_systems:\n","    query = \"Create a model for \" + technical_system\n","    messages = [{\"role\": \"user\", \"content\": query}]\n","\n","    response = \"\"\n","    for new_text in chat_model.stream_chat(messages):\n","        response += new_text\n","\n","    # Write the response to a file\n","    file_path = os.path.join(output_dir, f\"{technical_system}.sysml\")\n","    with open(file_path, 'w') as file:\n","        file.write(response)\n","    n+=1\n","    print(\"Created sysml v2 model no. \" + str(n) )\n","\n","# Free up memory\n","torch_gc()\n","\n","# Upload to Google Drive\n","directory_to_zip = output_dir  # Change this to your directory\n","zip_output_path = f'{output_dir}.zip'  # Change this to your desired output zip file name\n","drive_zip_output_path = f'/content/drive/MyDrive/{output_dir}.zip'  # Change this to your desired location on Google Drive\n","\n","!zip -r $zip_output_path $directory_to_zip\n","!mv $zip_output_path $drive_zip_output_path\n"]},{"cell_type":"markdown","source":["### Infer 100 system models (AUTOSAR)"],"metadata":{"id":"_X3mSfPfHQID"}},{"cell_type":"code","source":["# Setup chat model arguments\n","args = dict(\n","  model_name_or_path=hf_base_model_id,\n","  adapter_name_or_path=adapter_name,      # load the saved LoRA adapters\n","  template=llamafactory_template_name,                     # same to the one in training\n","  finetuning_type=\"lora\",                  # same to the one in training\n","  quantization_bit=4,                    # load 4-bit quantized model\n","  use_unsloth=False,                     # don't use UnslothAI's LoRA optimization for 2x faster generation\n",")\n","\n","# Initialize the chat model\n","chat_model = ChatModel(args)\n","\n","# Ensure the sysml_files directory exists\n","output_dir = \"100systems_AUTOSAR_sysml\"\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# Iterate over the technical system names\n","query = \"\"\"\n","You create a model with these parts: Front Light Manager, Ignition, Light Switch, Low Beam Light. Each part contains at least one statemachine.\n","The Front Light Manager shall evaluate the Ignition Key position.\n","The Front Light Manager shall read the LS switch position\n","The Front Light Manager shall evaluate the LS switch status.\n","Only if the LS switch status changes from OFF to ON the Front Light Manager shall create a switch event (ON).\n","If the LS switch status changes from ON to OFF the Front Light Manager shall create a switch event (OFF).\n","The Front Light Manager shall activate the low beam light, if the Ignition Key position is ON and a light switch event is detected\n","The Front Light Manager shall deactivate the low beam light if the Ignition Key position is OFF or a switch event (OFF) is detected.\n","\"\"\"\n","messages = [{\"role\": \"user\", \"content\": query}]\n","\n","for i in range(100):\n","    response = \"\"\n","    for new_text in chat_model.stream_chat(messages):\n","      response += new_text\n","\n","    # Write the response to a file\n","    file_path = os.path.join(output_dir, f\"AUTOSAR_{i}.sysml\")\n","    with open(file_path, 'w') as file:\n","        file.write(response)\n","\n","# Free up memory\n","torch_gc()\n","\n","# Upload to Google Drive\n","directory_to_zip = output_dir  # Change this to your directory\n","zip_output_path = f'{output_dir}.zip'  # Change this to your desired output zip file name\n","drive_zip_output_path = f'/content/drive/MyDrive/{output_dir}.zip'  # Change this to your desired location on Google Drive\n","\n","!zip -r $zip_output_path $directory_to_zip\n","!mv $zip_output_path $drive_zip_output_path"],"metadata":{"id":"A8dWgXmCKhre"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Unzip the adapter from Google Drive"],"metadata":{"id":"NkdbvaEIImGH"}},{"cell_type":"code","source":["# Paths\n","zip_file_path = f'/content/drive/MyDrive/{adapter_name}.zip'  # Path to the zip file\n","unzip_output_path = f'/content/LLaMA-Factory'  # Path to extract the zip file contents\n","\n","# Unzip the file\n","!unzip $zip_file_path -d $unzip_output_path"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ielP1NXQIozA","executionInfo":{"status":"ok","timestamp":1715942746552,"user_tz":-120,"elapsed":18787,"user":{"displayName":"Bertil Muth","userId":"02558266373806387996"}},"outputId":"8ba27efb-5139-40b0-e0db-32fbbfa4a193"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  /content/drive/MyDrive/phi_lora.zip\n","replace /content/LLaMA-Factory/phi_lora/checkpoint-1000/adapter_config.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-1000/adapter_config.json  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-1000/tokenizer_config.json  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-1000/special_tokens_map.json  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-1000/optimizer.pt  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-1000/tokenizer.json  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-1000/trainer_state.json  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-1000/adapter_model.safetensors  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-1000/scheduler.pt  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-1000/training_args.bin  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-1000/README.md  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-1000/rng_state.pth  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-1000/added_tokens.json  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-1000/tokenizer.model  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-2000/adapter_config.json  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-2000/tokenizer_config.json  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-2000/special_tokens_map.json  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-2000/optimizer.pt  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-2000/tokenizer.json  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-2000/trainer_state.json  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-2000/adapter_model.safetensors  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-2000/scheduler.pt  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-2000/training_args.bin  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-2000/README.md  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-2000/rng_state.pth  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-2000/added_tokens.json  \n","  inflating: /content/LLaMA-Factory/phi_lora/checkpoint-2000/tokenizer.model  \n","  inflating: /content/LLaMA-Factory/phi_lora/adapter_config.json  \n","  inflating: /content/LLaMA-Factory/phi_lora/tokenizer_config.json  \n","  inflating: /content/LLaMA-Factory/phi_lora/special_tokens_map.json  \n","  inflating: /content/LLaMA-Factory/phi_lora/tokenizer.json  \n","  inflating: /content/LLaMA-Factory/phi_lora/trainer_state.json  \n","  inflating: /content/LLaMA-Factory/phi_lora/all_results.json  \n","  inflating: /content/LLaMA-Factory/phi_lora/train_results.json  \n","  inflating: /content/LLaMA-Factory/phi_lora/adapter_model.safetensors  \n","  inflating: /content/LLaMA-Factory/phi_lora/training_args.bin  \n","  inflating: /content/LLaMA-Factory/phi_lora/README.md  \n","  inflating: /content/LLaMA-Factory/phi_lora/trainer_log.jsonl  \n","  inflating: /content/LLaMA-Factory/phi_lora/added_tokens.json  \n","  inflating: /content/LLaMA-Factory/phi_lora/runs/May17_06-49-05_a18b2cc96999/events.out.tfevents.1715928551.a18b2cc96999.3779.0  \n","  inflating: /content/LLaMA-Factory/phi_lora/runs/May17_06-46-43_a18b2cc96999/events.out.tfevents.1715928446.a18b2cc96999.3047.0  \n","  inflating: /content/LLaMA-Factory/phi_lora/tokenizer.model  \n"]}]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["kTESHaFvbNTr"],"gpuType":"A100","machine_shape":"hm","provenance":[{"file_id":"1eRTPn37ltBbYsISy9Aw2NuI2Aq5CQrD9","timestamp":1715161074742}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}